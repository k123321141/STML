{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/eBRPvWB.png)\n",
    "\n",
    "# Practical PyTorch: Translation with a Sequence to Sequence Network and Attention\n",
    "\n",
    "In this project we will be teaching a neural network to translate from French to English.\n",
    "\n",
    "```\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "> il est en train de peindre un tableau .\n",
    "= he is painting a picture .\n",
    "< he is painting a picture .\n",
    "\n",
    "> pourquoi ne pas essayer ce vin delicieux ?\n",
    "= why not try that delicious wine ?\n",
    "< why not try that delicious wine ?\n",
    "\n",
    "> elle n est pas poete mais romanciere .\n",
    "= she is not a poet but a novelist .\n",
    "< she not not a poet but a novelist .\n",
    "\n",
    "> vous etes trop maigre .\n",
    "= you re too skinny .\n",
    "< you re all alone .\n",
    "```\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the [sequence to sequence network](http://arxiv.org/abs/1409.3215), in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a single vector, and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "To improve upon this model we'll use an [attention mechanism](https://arxiv.org/abs/1409.0473), which lets the decoder learn to focus over a specific range of the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sequence to Sequence model\n",
    "\n",
    "A [Sequence to Sequence network](http://arxiv.org/abs/1409.3215), or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two separate RNNs called the **encoder** and **decoder**. The encoder reads an input sequence one item at a time, and outputs a vector at each step. The final output of the encoder is kept as the **context** vector. The decoder uses this context vector to produce a sequence of outputs one step at a time.\n",
    "\n",
    "![](https://i.imgur.com/tVtHhNp.png)\n",
    "\n",
    "When using a single RNN, there is a one-to-one relationship between inputs and outputs. We would quickly run into problems with different sequence orders and lengths that are common during translation. Consider the simple sentence \"Je ne suis pas le chat noir\" &rarr; \"I am not the black cat\". Many of the words have a pretty direct translation, like \"chat\" &rarr; \"cat\". However the differing grammars cause words to be in different orders, e.g. \"chat noir\" and \"black cat\". There is also the \"ne ... pas\" &rarr; \"not\" construction that makes the two sentences have different lengths.\n",
    "\n",
    "With the seq2seq model, by encoding many inputs into one vector, and decoding from one vector into many outputs, we are freed from the constraints of sequence order and length. The encoded sequence is represented by a single vector, a single point in some N dimensional space of sequences. In an ideal case, this point can be considered the \"meaning\" of the sequence.\n",
    "\n",
    "This idea can be extended beyond sequences. Image captioning tasks take an [image as input, and output a description](https://arxiv.org/abs/1411.4555) of the image (img2seq). Some image generation tasks take a [description as input and output a generated image](https://arxiv.org/abs/1511.02793) (seq2img). These models can be referred to more generally as \"encoder decoder\" networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Attention Mechanism\n",
    "\n",
    "The fixed-length vector carries the burden of encoding the the entire \"meaning\" of the input sequence, no matter how long that may be. With all the variance in language, this is a very hard problem. Imagine two nearly identical sentences, twenty words long, with only one word different. Both the encoders and decoders must be nuanced enough to represent that change as a very slightly different point in space.\n",
    "\n",
    "The **attention mechanism** [introduced by Bahdanau et al.](https://arxiv.org/abs/1409.0473) addresses this by giving the decoder a way to \"pay attention\" to parts of the input, rather than relying on a single vector. For every step the decoder can select a different part of the input sentence to consider.\n",
    "\n",
    "![](https://i.imgur.com/5y6SCvU.png)\n",
    "\n",
    "Attention is calculated with another feedforward layer in the decoder. This layer will use the current input and hidden state to create a new vector, which is the same size as the input sequence (in practice, a fixed maximum length). This vector is processed through softmax to create *attention weights*, which are multiplied by the encoders' outputs to create a new context vector, which is then used to predict the next output.\n",
    "\n",
    "![](https://i.imgur.com/K1qMPxs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "You will need [PyTorch](http://pytorch.org/) to build and train the models, and [matplotlib](https://matplotlib.org/) for plotting training and visualizing attention outputs later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will also define a constant to decide whether to use the GPU (with CUDA specifically) or the CPU. **If you don't have a GPU, set this to `False`**. Later when we create tensors, this variable will be used to decide whether we keep them on CPU or move them to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data files\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs.\n",
    "\n",
    "[This question on Open Data Stack Exchange](http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages) pointed me to the open translation site http://tatoeba.org/ which has downloads available at http://tatoeba.org/eng/downloads - and better yet, someone did the extra work of splitting language pairs into individual text files here: http://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so download `fra-eng.zip`, extract the text file in there, and rename it to `data/eng-fra.txt` before continuing (for some reason the zipfile is named backwards). The file is a tab separated list of translation pairs:\n",
    "\n",
    "```\n",
    "I am cold.    J'ai froid.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Lang` which has word &rarr; index (`word2index`) and index &rarr; word (`index2word`) dictionaries, as well as a count of each word `word2count` to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "MAX_VOCAB_DIM = 50000\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.default_vocab = {0: \"<SOS>\", 1: \"<EOS>\", 2:'<UNK>'}\n",
    "        self.index2word = self.default_vocab.copy()\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    def trim_vocab(self, max_vocab_dim):\n",
    "        start_idx = len(self.default_vocab)\n",
    "        kv = np.array([(k,v) for k,v in self.word2count.items() if k not in self.default_vocab])\n",
    "        sorted_count_idx = np.flip(np.argsort(np.array(kv[:,1], dtype=np.int32)), axis=0)\n",
    "        self.index2word = self.default_vocab.copy()\n",
    "        self.word2index = {v:k for k,v in self.index2word.items()}\n",
    "        i = start_idx\n",
    "        \n",
    "        for word in np.array(kv[:,0])[sorted_count_idx[:max_vocab_dim-len(self.default_vocab)]]:\n",
    "            self.index2word[i] = word\n",
    "            self.word2index[word] = i\n",
    "            i += 1\n",
    "        self.n_words = len(self.index2word)\n",
    "        self.word2count = {k:v for k,v in self.word2count.items() if k in self.word2index}\n",
    "            \n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and decoding files\n",
    "\n",
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "# def unicode_to_ascii(s):\n",
    "#     return ''.join(\n",
    "#         c for c in unicodedata.normalize('NFD', s)\n",
    "#         if unicodedata.category(c) != 'Mn'\n",
    "#     )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "#     s = unicode_to_ascii(s.lower().strip())\n",
    "    s = s.strip()\n",
    "#     print s,'start'\n",
    "    s = re.sub(u\"([.!?])\", u\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(u\"[^\\u4e00-\\u9fffa-zA-Z.!?0-9]+\", r\" \", s)\n",
    "#     print s,'end'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English &rarr; Other Language, so if we want to translate from Other Language &rarr; English I added the `reverse` flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('../data/%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s.decode('utf8')) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering sentences\n",
    "\n",
    "Since there are a *lot* of example sentences and we want to train something quickly, we'll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (accounting for apostrophes being removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 60\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(good_prefixes)\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "* Read text file and split into lines, split lines into pairs\n",
    "* Normalize text, filter by length and content\n",
    "* Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 651339 sentence pairs\n",
      "Trimmed to 651293 sentence pairs\n",
      "Indexing words...\n",
      "[u'SOS \\u6211 \\u7684 \\u5fc3 \\u4f60 \\u8be5 \\u77e5\\u9053 \\u5f88 \\u4e45 EOS v m r v m v r uj a NOP ao NOE 9 NOR', u'SOS \\u6709 \\u4e00\\u5929 \\u6211 \\u8981 \\u5927\\u58f0 \\u5ba3\\u5e03 \\u6211 \\u7684 \\u9a84\\u50b2 EOS']\n",
      "SOS 才 不 轻易 泄露 了 心情 EOS d v y NOP i NOE 3 NOR\n",
      "SOS 仅仅 傻笑 而已 EOS\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)\n",
    "# input_lang, output_lang, pairs = prepare_data('eng', 'cmn', True)\n",
    "input_lang, output_lang, pairs = prepare_data('r1', 'r2', True)\n",
    "input_lang.trim_vocab(MAX_VOCAB_DIM)\n",
    "output_lang.trim_vocab(MAX_VOCAB_DIM)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))\n",
    "a,b = random.choice(pairs)\n",
    "print a\n",
    "print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning training data into Tensors/Variables\n",
    "\n",
    "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a Tensor, where each word is replaced with the index (from the Lang indexes made earlier). While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)\n",
    "\n",
    "A Tensor is a multi-dimensional array of numbers, defined with some type e.g. FloatTensor or LongTensor. In this case we'll be using LongTensor to represent an array of integer indexes.\n",
    "\n",
    "Trainable PyTorch modules take Variables as input, rather than plain Tensors. A Variable is basically a Tensor that is able to keep track of the graph state, which is what makes autograd (automatic calculation of backwards gradients) possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_token for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init postional matrix with length : 200 \n",
      "torch.Size([1, 13, 128])\n",
      "923648\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "def scaled_dot_attention(Q, K, V, mask):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    assert len(Q.size()) == 3 and len(K.size()) == 3 and len(V.size()) == 3\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).cuda()\n",
    "    out = torch.matmul(Q,K.permute(0,2,1)) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out.masked_fill_(mask, -float('inf'))\n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "\n",
    "def positional_encoding(d_model, pos):\n",
    "    assert d_model % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,d_model], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, p_drop, d_ff, use_mask, use_cuda=True, posi_cache_length=200):\n",
    "        super(Transformer, self).__init__()\n",
    "#         for construct cache positional encoding matrix.\n",
    "        self.d_model = dm\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h, p_drop, d_ff)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h, p_drop, d_ff, use_mask)\n",
    "        self.emb_drop = nn.Dropout(p_drop)\n",
    "        self.init_pos_mat(posi_cache_length)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "    \n",
    "    #         encoder\n",
    "        batch, K_len, d = K.size()\n",
    "#         pos matrix will fit the batch size\n",
    "#         without pos.repeat() is faster\n",
    "        try:\n",
    "            K = K + self.get_pos_mat(K_len)\n",
    "        except RuntimeError, e:\n",
    "            if e.message == 'TensorIterator expected type torch.cuda.FloatTensor but got torch.FloatTensor':\n",
    "                if K.is_cuda != self.get_pos_mat(K_len).is_cuda:\n",
    "                    print('Make sure cache positional matrix is same type of tensor with input, both cuda tensor or not.\\nBy setting argument use_cuda=True to set cache positional encoding matrix as a cuda tensor.')\n",
    "            raise\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        batch, Q_len, d = Q.size()\n",
    "        \n",
    "        try:\n",
    "            Q = Q + self.get_pos_mat(Q_len)\n",
    "        except RuntimeError, e:\n",
    "            if e.message == 'TensorIterator expected type torch.cuda.FloatTensor but got torch.FloatTensor':\n",
    "                if Q.is_cuda != self.get_pos_mat(K_len).is_cuda:\n",
    "                    print('Make sure cache positional matrix is same type of tensor with input, both cuda tensor or not.\\nBy setting argument use_cuda=True to set cache positional encoding matrix as a cuda tensor.')\n",
    "            raise\n",
    "        \n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        return de_out\n",
    "    \n",
    "#     To speed up the positional encoding by construct an cache matrix. \n",
    "    def init_pos_mat(self, cache_length):\n",
    "        print('init postional matrix with length : %d ' % cache_length)\n",
    "        self.positional_matrix = torch.cat([positional_encoding(self.d_model, i) for i in range(0,cache_length)], dim=0)\n",
    "        self.positional_matrix.requires_grad = False\n",
    "        if self.use_cuda:\n",
    "            self.positional_matrix = self.positional_matrix.cuda()\n",
    "            \n",
    "        \n",
    "    def get_pos_mat(self, length):\n",
    "        if length > self.positional_matrix.shape[0]:\n",
    "            print('input sequence length reach positional matrix maximum length. %d ' % length)\n",
    "            ret = torch.cat([positional_encoding(self.d_model, i) for i in range(length)], dim=0)\n",
    "            ret.requires_grad = False\n",
    "            print('Increase positional matrix maximum length. %d ' % length)\n",
    "            self.positional_matrix = ret\n",
    "            if self.use_cuda:\n",
    "                self.positional_matrix = self.positional_matrix.cuda()\n",
    "            return ret\n",
    "        else:\n",
    "            return self.positional_matrix[:length]\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, p_drop, d_ff):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h, p_drop, d_ff) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K         \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h, p_drop, d_ff):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.att_drop = nn.Dropout(p_drop)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(dm, d_ff)\n",
    "        self.linear_drop = nn.Dropout(p_drop)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K, mask=None)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(attention_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "    \n",
    "        return linear_out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, p_drop, d_ff, use_mask):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h, p_drop, d_ff, use_mask) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h, p_drop, d_ff, use_mask):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.use_mask = use_mask\n",
    "        \n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_att_drop = nn.Dropout(p_drop)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_att_drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(dm, d_ff)\n",
    "        self.linear_drop = nn.Dropout(p_drop)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out):\n",
    "        if self.use_mask:\n",
    "            batch, Q_len, d = Q.size()\n",
    "            mask = self.mask_matrix(batch, Q_len)\n",
    "        else:\n",
    "            mask = None\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask=mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = Q_attention_out\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out, mask=None)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = QK_attention_out\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = linear_out\n",
    "        return out\n",
    "    def mask_matrix(self, batch, Q_len):\n",
    "#         ByteTensor\n",
    "        mask = torch.zeros([1, Q_len, Q_len], dtype=torch.uint8, requires_grad=False)\n",
    "        for i in range(Q_len):\n",
    "            mask[0,i,i+1:] = 1\n",
    "        return mask.repeat(batch,1, 1).cuda()\n",
    "\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "        \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        bat,seq_len,d = x.size()\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# Transformer paper baseline hyper-parameters\n",
    "\n",
    "    \n",
    "bat = 1\n",
    "STACKED_NUM = 2\n",
    "DK=DV=D_MODEL=128\n",
    "P_DROP=0.1\n",
    "D_FF = D_MODEL*4\n",
    "H=1\n",
    "Q = torch.rand([bat, 13, D_MODEL]).cuda()\n",
    "K = torch.rand([bat, 19, D_MODEL]).cuda()\n",
    "net = Transformer(STACKED_NUM, DK, DV, D_MODEL, H, P_DROP, D_FF, use_mask=True, use_cuda=True).cuda()\n",
    "o = net(Q, K)\n",
    "print(o.size())\n",
    "\n",
    "# Q = torch.rand([bat, 47, D_MODEL]).cuda()\n",
    "# K = torch.rand([bat, 88, D_MODEL]).cuda()\n",
    "# o = net(Q, K)\n",
    "# print(o.size())\n",
    "# # # print o\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, d_model, n_layers, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        STACKED_NUM = n_layers\n",
    "        DK=DV=D_MODEL=d_model\n",
    "        P_DROP=0.1\n",
    "        D_FF = D_MODEL*4\n",
    "        H=1\n",
    "        self.transformer = Transformer(STACKED_NUM, DK, DV, D_MODEL, H, P_DROP, D_FF, use_mask=True, use_cuda=True).cuda()\n",
    "        self.in_emb = nn.Embedding(input_size, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.in_emb(Q)\n",
    "        K = self.in_emb(K)\n",
    "        out = self.transformer(Q, K)\n",
    "        out = self.out_linear(out)\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the models\n",
    "\n",
    "To make sure the Encoder and Decoder model are working (and working together) we'll do a quick test with fake word inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Defining a training iteration\n",
    "\n",
    "To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
    "\n",
    "### Teacher Forcing and Scheduled Sampling\n",
    "\n",
    "\"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
    "\n",
    "The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, model, model_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradients of both optimizers\n",
    "    model_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    # Run words through encoder\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = decoder_seq = Variable(torch.LongTensor([[SOS_token]]))\n",
    "#     decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_seq = decoder_input.cuda()\n",
    "    K = input_variable.view(1, input_length)\n",
    "    Q = decoder_seq.view(1, 1)\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output = model(Q,K)[0,-1,:].view(1,-1)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "            Q = torch.cat([Q, decoder_input.view(1,1)], dim=1)\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output = model(Q,K)[0,-1,:].view(1,-1)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            ni = top_idx = torch.topk(decoder_output,1)[1].item()\n",
    "        \n",
    "            decoder_input = Variable(torch.LongTensor([ni])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "            Q = torch.cat([Q, decoder_input.view(1,1)], dim=1)\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "#     encoder_outputs = torch.cat([encoder_outputs, decoder_rnn_output], dim=0)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    model_optimizer.step()\n",
    "    \n",
    "    return loss.data.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally helper functions to print time elapsed and estimated time remaining, given the current time and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    if percent == 0:\n",
    "        es = 0.\n",
    "    else:\n",
    "        es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running training\n",
    "\n",
    "With everything in place we can actually initialize a network and start training.\n",
    "\n",
    "To start, we initialize models, optimizers, and a loss function (criterion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init postional matrix with length : 200 \n",
      "torch.Size([1, 12]) torch.Size([1, 24])\n",
      "torch.Size([1, 12, 50000])\n"
     ]
    }
   ],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 128\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "\n",
    "    \n",
    "# Transformer paper baseline hyper-parameters\n",
    "\n",
    "    \n",
    "bat = 1\n",
    "\n",
    "model = Net(hidden_size, n_layers, input_lang.n_words, output_lang.n_words)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# test\n",
    "training_pair = variables_from_pair(random.choice(pairs))\n",
    "input_variable = training_pair[0]\n",
    "target_variable = training_pair[1]\n",
    "Q = target_variable.view(1,-1)\n",
    "K = input_variable.view(1,-1)\n",
    "print Q.shape, K.shape\n",
    "o = model(Q,K)\n",
    "print o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up variables for plotting and tracking progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 500000\n",
    "plot_every = 20\n",
    "print_every = 2000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually train, we call the train function many times, printing a summary as we go.\n",
    "\n",
    "*Note:* If you run this notebook you can train, interrupt the kernel, evaluate, and continue training later. You can comment out the lines above where the encoder and decoder are initialized (so they aren't reset) or simply run the notebook starting from the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1999/500001 [07:21<25:06:15,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 34s (- 1885m 42s) (2000 0%) 6.2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2000/500001 [07:22<65:31:04,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 等 至 夜半 倦 眼伴 泪容 EOS c r v n a uj n NOP eng NOE 7 NOR\n",
      "= SOS 要是 你 愿 化作 柔情 的 春风 EOS\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3999/500001 [14:38<30:58:45,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14m 51s (- 1843m 0s) (4000 0%) 5.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4000/500001 [14:39<67:11:09,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 易笛 加列 加列 不 啦 加列 不 啦 加列 EOS j ns ns NOP a NOE 3 NOR\n",
      "= SOS 固 苏美 固苏玛 EOS\n",
      "< SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS SOS EOS EOS SOS SOS SOS SOS SOS SOS SOS EOS EOS EOS SOS EOS SOS EOS SOS EOS SOS EOS SOS SOS EOS EOS SOS SOS SOS EOS SOS SOS SOS EOS SOS SOS SOS SOS EOS SOS SOS SOS SOS EOS SOS SOS SOS EOS EOS SOS SOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6000/500001 [21:52<26:35:08,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22m 5s (- 1818m 48s) (6000 1%) 5.3134\n",
      "> SOS 当 从前 你 给 我 的 梦 EOS p n a f NOP ou NOE 4 NOR\n",
      "= SOS 被 爱 伤害 以后 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8000/500001 [28:36<29:12:05,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28m 49s (- 1772m 58s) (8000 1%) 4.4939\n",
      "> SOS 填 上 没 人 知道 的 地址 EOS v d v uj n NOP i NOE 5 NOR\n",
      "= SOS 寄给 从不 存在 的 名字 EOS\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10000/500001 [35:39<33:09:52,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35m 52s (- 1758m 3s) (10000 2%) 4.8548\n",
      "> SOS 还是 世纪末 的 无聊 消遣 EOS n x v m ng n NOP uan NOE 6 NOR\n",
      "= SOS 香烟 氲 成 一 滩 光圈 EOS\n",
      "< SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11999/500001 [42:43<31:24:26,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42m 56s (- 1746m 21s) (12000 2%) 4.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 12000/500001 [42:43<38:26:23,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 因为 我 相信 说 过 了 再见 EOS d v v NOP ian NOE 3 NOR\n",
      "= SOS 一定 会 再见 EOS\n",
      "< SOS EOS SOS SOS SOS EOS EOS SOS EOS SOS SOS EOS EOS SOS SOS SOS EOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14000/500001 [48:50<29:33:36,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49m 3s (- 1703m 2s) (14000 2%) 5.0697\n",
      "> SOS 我 愿 放弃 鲜花 满丛 EOS c v r v NOP ang NOE 4 NOR\n",
      "= SOS 只为 看 你 绽放 EOS\n",
      "< EOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16000/500001 [55:42<29:19:40,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55m 55s (- 1691m 31s) (16000 3%) 4.9271\n",
      "> SOS 在 这 令人 迷醉 的 黄色 的 正中间 EOS v m n uj n NOP i NOE 5 NOR\n",
      "= SOS 是 一片 紫色 的 风信子 EOS\n",
      "< SOS SOS SOS SOS SOS EOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 17999/500001 [1:02:30<29:21:21,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62m 43s (- 1679m 37s) (18000 3%) 4.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 18000/500001 [1:02:31<49:51:51,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 我 愿意 承受 所有 绝望 与 苦难 EOS c r v a uj v NOP ai NOE 6 NOR\n",
      "= SOS 如果 一切 是 最好 的 安排 EOS\n",
      "< SOS EOS SOS SOS EOS EOS SOS SOS SOS EOS EOS EOS SOS SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS SOS EOS EOS EOS SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS EOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20000/500001 [1:09:27<36:13:43,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69m 39s (- 1671m 58s) (20000 4%) 4.9204\n",
      "> SOS 尤其 是 对联 EOS r n v d d v uj NOP e NOE 7 NOR\n",
      "= SOS 这 兴趣 是 从小 就 养成 的 EOS\n",
      "< EOS EOS EOS EOS EOS SOS EOS SOS EOS SOS EOS SOS EOS EOS EOS EOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 22000/500001 [1:16:33<30:08:27,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76m 46s (- 1667m 58s) (22000 4%) 5.1587\n",
      "> SOS 他们 各 由 自己 的 信徒 簇拥着 EOS v n v n NOP en NOE 4 NOR\n",
      "= SOS 开始 辩论 是否 有神 EOS\n",
      "< EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 24000/500001 [1:23:34<32:25:34,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83m 47s (- 1661m 52s) (24000 4%) 5.0637\n",
      "> SOS 我 连 呼吸 都 反复 练习 EOS nr nr uj ns NOP uan NOE 4 NOR\n",
      "= SOS 兰伯特 仁慈 的 冰川 EOS\n",
      "< SOS EOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 26000/500001 [1:30:44<30:45:56,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90m 57s (- 1658m 8s) (26000 5%) 5.1604\n",
      "> SOS 下 一秒 却 又 让 我 EOS v NOP ou NOE 1 NOR\n",
      "= SOS 猜不透 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 28000/500001 [1:37:42<27:16:56,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97m 55s (- 1650m 44s) (28000 5%) 4.9316\n",
      "> SOS 曾经 相同 的 眼神 EOS d v a n NOP in NOE 4 NOR\n",
      "= SOS 却 有 不同 心 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 30000/500001 [1:44:41<29:54:05,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104m 54s (- 1643m 40s) (30000 6%) 4.9693\n",
      "> SOS 生活 赠与 我们 的 是 许许多多 实实在在 的 丰富 意蕴 EOS r v p n uj i c l n v z v m NOP an NOE 13 NOR\n",
      "= SOS 我们 岂能 被 人生 的 风风雨雨 和 云遮 雾 绕 迷蒙 住 双眼 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 31999/500001 [1:51:43<28:17:26,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111m 56s (- 1637m 6s) (32000 6%) 4.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 32001/500001 [1:51:44<52:04:14,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 早 习惯 穿梭 充满 诱惑 的 黑夜 EOS c d n v r uj n NOP ian NOE 7 NOR\n",
      "= SOS 但 却 无法 忘记 你 的 脸 EOS\n",
      "< EOS EOS SOS SOS SOS EOS SOS EOS EOS SOS SOS SOS <UNK> EOS SOS SOS SOS EOS SOS EOS SOS EOS SOS SOS SOS SOS EOS EOS EOS SOS SOS SOS SOS SOS EOS SOS SOS EOS SOS SOS SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 34001/500001 [1:58:31<26:03:30,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118m 44s (- 1627m 27s) (34000 6%) 4.6703\n",
      "> SOS 爱上你 是 我 唯一 的 骄傲 EOS n v v v f uj n NOP uo NOE 7 NOR\n",
      "= SOS 男 触电 像 砸 下 的 苹果 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35999/500001 [2:05:09<28:11:31,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125m 22s (- 1615m 58s) (36000 7%) 4.4464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 36000/500001 [2:05:10<53:40:27,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 过眼云烟 也 留情 EOS i d v d v NOP ing NOE 5 NOR\n",
      "= SOS 过眼云烟 也 留情 也 留情 EOS\n",
      "< EOS SOS SOS SOS EOS EOS EOS EOS SOS SOS EOS SOS EOS SOS EOS SOS SOS SOS SOS EOS EOS EOS EOS SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS EOS EOS SOS SOS SOS SOS SOS EOS EOS SOS SOS EOS SOS EOS SOS SOS EOS SOS EOS SOS SOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 38000/500001 [2:11:57<25:10:53,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132m 10s (- 1606m 53s) (38000 7%) 4.7037\n",
      "> SOS 撑起 一 柄 帆 赶快 来到 我 的 身边 EOS n f uj r d d d a NOP uan NOE 8 NOR\n",
      "= SOS 传说 中 的 你 从来 都 不曾 遥远 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 40000/500001 [2:18:52<24:38:45,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139m 5s (- 1599m 38s) (40000 8%) 4.9083\n",
      "> SOS 什么 兵器 最 喜欢 双截棍 柔中带刚 EOS v v ns ns n n c n NOP ang NOE 8 NOR\n",
      "= SOS 想要 去 河南 嵩山 学 少林 和 武当 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41999/500001 [2:25:57<27:17:07,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146m 11s (- 1594m 5s) (42000 8%) 4.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 42001/500001 [2:25:59<47:06:54,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 月亮 也 听见 你 说 EOS v r v d v r NOP o NOE 6 NOR\n",
      "= SOS 说 你 会 一直 爱 我 EOS\n",
      "< EOS EOS EOS SOS SOS SOS EOS EOS SOS EOS EOS SOS SOS SOS SOS SOS EOS EOS EOS SOS EOS EOS EOS EOS EOS EOS SOS SOS EOS SOS EOS SOS EOS EOS EOS SOS EOS EOS EOS EOS EOS EOS EOS EOS EOS SOS EOS EOS EOS EOS EOS EOS EOS SOS EOS EOS EOS EOS EOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 43999/500001 [2:32:57<21:29:14,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153m 10s (- 1587m 30s) (44000 8%) 5.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 44001/500001 [2:32:58<40:06:19,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 走 着 走 着 觉得 累 了 EOS v uz v uz m v uz NOP e NOE 7 NOR\n",
      "= SOS 哭 着 笑 着 一路 爱 着 EOS\n",
      "< SOS EOS SOS EOS SOS EOS SOS EOS SOS EOS SOS SOS EOS SOS SOS EOS EOS EOS EOS SOS SOS EOS SOS EOS EOS SOS EOS EOS SOS EOS SOS EOS EOS SOS EOS SOS SOS SOS EOS EOS SOS EOS EOS EOS SOS EOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 45999/500001 [2:39:58<28:14:58,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160m 11s (- 1581m 5s) (46000 9%) 5.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 46001/500001 [2:40:00<49:10:31,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 学习 建设 社会主义 的 本领 EOS n NOP an NOE 1 NOR\n",
      "= SOS 原子弹 EOS\n",
      "< EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 48000/500001 [2:47:07<25:23:53,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167m 20s (- 1575m 47s) (48000 9%) 5.5324\n",
      "> SOS 时代 更改 青春 在 胸怀 EOS nr n v y v y n v NOP ai NOE 8 NOR\n",
      "= SOS 崔 子格 燃烧 吧 燃烧 吧 好运 澎湃 EOS\n",
      "< SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 50000/500001 [2:53:43<23:28:13,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173m 56s (- 1565m 24s) (50000 10%) 4.4400\n",
      "> SOS 张 假使 跟 你 一起 EOS v d a v v d v NOP i NOE 7 NOR\n",
      "= SOS 关 不必 高 到 打 不 死 EOS\n",
      "< SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52000/500001 [3:00:21<27:42:08,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180m 34s (- 1555m 46s) (52000 10%) 4.3260\n",
      "> SOS 你 有 失控 的 准备 未 EOS n d v n i uj d v v nr NOP ang NOE 10 NOR\n",
      "= SOS 历史 即将 改写 能量 未用尽 的 即将 释放 无需 雪藏 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 54000/500001 [3:07:07<25:26:29,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187m 20s (- 1547m 14s) (54000 10%) 4.5214\n",
      "> SOS 我 心念 出 不 太 懂 的 EOS r m n n NOP ing NOE 4 NOR\n",
      "= SOS 这 一段 心 经 EOS\n",
      "< EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 56000/500001 [3:13:55<32:49:32,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194m 8s (- 1539m 15s) (56000 11%) 4.6578\n",
      "> SOS 让 心情 像 天空 般 一片 蔚蓝 EOS v y NOP a NOE 2 NOR\n",
      "= SOS 回去 吧 EOS\n",
      "< EOS EOS EOS SOS EOS EOS EOS SOS SOS SOS SOS EOS EOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 58000/500001 [3:20:44<26:51:53,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200m 57s (- 1531m 27s) (58000 11%) 4.7262\n",
      "> SOS 我 在 浴缸 蝶泳 在 浴缸 蝶泳 EOS r c v r v v r NOP o NOE 7 NOR\n",
      "= SOS 你 若 羡慕 我 欢迎 跟着 我 EOS\n",
      "< SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60001/500001 [3:27:27<21:33:29,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207m 40s (- 1522m 56s) (60000 12%) 4.5051\n",
      "> SOS 一天 偏 有 百万 人 EOS p n v v p v NOP ie NOE 6 NOR\n",
      "= SOS 为 爱 结合 分开 因 了解 EOS\n",
      "< SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 62000/500001 [3:34:10<25:18:27,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214m 23s (- 1514m 33s) (62000 12%) 4.5830\n",
      "> SOS 喧闹 闹 的 音乐 EOS v ul r v r NOP ei NOE 5 NOR\n",
      "= SOS 忘 了 我 是 谁 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 64000/500001 [3:41:10<28:12:11,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221m 22s (- 1508m 9s) (64000 12%) 5.0863\n",
      "> SOS 而且 这 声音 越来越近 EOS l y NOP a NOE 2 NOR\n",
      "= SOS 想不到 吧 EOS\n",
      "< EOS EOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS EOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 66000/500001 [3:47:56<23:14:33,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228m 9s (- 1500m 17s) (66000 13%) 4.6279\n",
      "> SOS 感情 美好 的 一面 EOS d v nr uj t NOP ian NOE 5 NOR\n",
      "= SOS 都 是 宝贵 的 昨天 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 67999/500001 [3:54:42<24:55:09,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234m 55s (- 1492m 30s) (68000 13%) 4.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 68000/500001 [3:54:43<54:15:38,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 黄尹 EOS v r p v r r uj n n NOP ang NOE 9 NOR\n",
      "= SOS 让 我 在 没有 你 我 的 地方 疗伤 EOS\n",
      "< EOS SOS SOS EOS EOS EOS EOS SOS EOS EOS EOS EOS SOS EOS SOS EOS SOS EOS SOS EOS SOS SOS SOS EOS EOS SOS EOS EOS SOS SOS SOS EOS SOS SOS EOS SOS EOS EOS SOS EOS EOS SOS EOS SOS EOS SOS SOS SOS EOS SOS EOS EOS SOS SOS SOS SOS SOS EOS EOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70000/500001 [4:01:42<30:03:04,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241m 55s (- 1486m 6s) (70000 14%) 5.0373\n",
      "> SOS 只 想 看 你 只要 看 你 EOS v ul n n NOP ong NOE 4 NOR\n",
      "= SOS 流出 了 迷人 笑容 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 72000/500001 [4:08:38<24:52:03,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248m 51s (- 1479m 21s) (72000 14%) 4.8679\n",
      "> SOS 搓 出 了 许多 个 栩栩如生 的 人儿 来 EOS v nr NOP iang NOE 2 NOR\n",
      "= SOS 到 天亮 EOS\n",
      "< SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 74000/500001 [4:15:32<25:58:22,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255m 45s (- 1472m 22s) (74000 14%) 4.9072\n",
      "> SOS 我们 曾 一起 走过 EOS r t v uj r n NOP e NOE 6 NOR\n",
      "= SOS 我 现在 唱 的 这 首歌 EOS\n",
      "< EOS EOS EOS SOS SOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76001/500001 [4:22:36<23:56:15,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262m 48s (- 1466m 13s) (76000 15%) 5.3497\n",
      "> SOS 但 当时 我 只 懂 憎恨 EOS a v i NOP i NOE 3 NOR\n",
      "= SOS 好 想 鼓起勇气 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 78000/500001 [4:29:32<23:59:59,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269m 45s (- 1459m 29s) (78000 15%) 5.0447\n",
      "> SOS 只要 让 你 不再 憔悴 EOS m v d d d NOP ui NOE 5 NOR\n",
      "= SOS 多 想 再次 真心 相对 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 80000/500001 [4:36:38<26:13:06,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276m 50s (- 1453m 27s) (80000 16%) 5.1780\n",
      "> SOS 只要 我 吞下 了 魔鬼 EOS r v r uj a NOP ei NOE 5 NOR\n",
      "= SOS 谁 管 谁 的 真伪 EOS\n",
      "< SOS SOS SOS SOS 我 SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 82000/500001 [4:43:46<28:18:19,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283m 59s (- 1447m 37s) (82000 16%) 5.2337\n",
      "> SOS 我 怎么 拒绝 EOS d v f r r d v NOP ui NOE 7 NOR\n",
      "= SOS 也许 到 最后 你 我 都 反悔 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 84000/500001 [4:50:55<26:16:15,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291m 8s (- 1441m 49s) (84000 16%) 5.2909\n",
      "> SOS 爱 了 几回 你 恨 几回 EOS d p n n d v NOP iu NOE 6 NOR\n",
      "= SOS 都 随着 流 水漂 不 停留 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 86001/500001 [4:58:00<25:22:45,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298m 13s (- 1435m 36s) (86000 17%) 5.1248\n",
      "> SOS 伤口 都 是 小 徽章 记念 了 我 的 坚强 EOS n v uz nr n a a NOP ang NOE 7 NOR\n",
      "= SOS 口袋 藏 着 阳光 天气 好 晴朗 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 88000/500001 [5:04:58<24:18:36,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305m 11s (- 1428m 50s) (88000 17%) 5.0716\n",
      "> SOS 邻居 都 在 梦 中 走散 了 EOS c vn d p r n v NOP i NOE 7 NOR\n",
      "= SOS 不是 考验 不 与 你 内心 对峙 EOS\n",
      "< SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 90000/500001 [5:11:59<28:27:36,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312m 12s (- 1422m 18s) (90000 18%) 5.0823\n",
      "> SOS 燃点 引爆 潜能 超乎 想象 EOS r p n v n NOP ang NOE 5 NOR\n",
      "= SOS 我 用 双手 代替 翅膀 EOS\n",
      "< SOS EOS SOS SOS EOS EOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 92000/500001 [5:18:58<25:29:09,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319m 11s (- 1415m 32s) (92000 18%) 5.1193\n",
      "> SOS 好好 工作 才 有 好 的 生活 EOS d vn y d vn NOP uo NOE 5 NOR\n",
      "= SOS 好好 工作 呀 好好 工作 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 94000/500001 [5:26:01<24:33:15,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326m 14s (- 1409m 4s) (94000 18%) 5.1798\n",
      "> SOS 不准 作弊 谈恋爱 不是 周年 庆 EOS n n NOP ua NOE 2 NOR\n",
      "= SOS 花心 画 EOS\n",
      "< EOS EOS SOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 96000/500001 [5:33:05<27:45:01,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333m 18s (- 1402m 41s) (96000 19%) 5.3022\n",
      "> SOS 枕上 雪 冰封 的 爱恋 EOS d v v v NOP ie NOE 4 NOR\n",
      "= SOS 真心 相拥 才能 融解 EOS\n",
      "< SOS SOS SOS SOS SOS SOS EOS EOS EOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 97999/500001 [5:40:16<22:30:06,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340m 29s (- 1396m 44s) (98000 19%) 5.5098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 98001/500001 [5:40:18<48:13:32,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 自由 地 自然 才 属 我 绝情 地 热情 没 结果 EOS a uj n d c n nr uj p r n d a NOP un NOE 13 NOR\n",
      "= SOS 温柔 的 空间 都 只有 责任 温馨 的 把 我 终生 都 被困 EOS\n",
      "< SOS SOS EOS SOS EOS SOS <UNK> SOS SOS EOS EOS SOS SOS SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS EOS EOS SOS EOS SOS EOS SOS SOS EOS SOS SOS EOS SOS EOS EOS SOS EOS EOS 鼓手 EOS SOS EOS SOS SOS SOS EOS EOS SOS EOS EOS EOS SOS SOS SOS SOS SOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 100000/500001 [5:47:23<26:00:32,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347m 36s (- 1390m 25s) (100000 20%) 5.3703\n",
      "> SOS 孤单 的 夜 泪如雨下 EOS c r n a NOP ei NOE 4 NOR\n",
      "= SOS 如果 你 感觉 累 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 102000/500001 [5:54:29<24:00:44,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354m 42s (- 1384m 3s) (102000 20%) 5.3856\n",
      "> SOS 和 你 分手 时候 彷似 割断 你 千秋 EOS d v v r v v r uj n NOP ou NOE 9 NOR\n",
      "= SOS 还 值得 任 你 咀咒 掷 你 的 石头 EOS\n",
      "< SOS EOS EOS EOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 103999/500001 [6:01:28<21:38:54,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361m 41s (- 1377m 11s) (104000 20%) 5.3245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 104000/500001 [6:01:28<26:35:08,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 以 无 所得 故 EOS n nr g NOP ui NOE 3 NOR\n",
      "= SOS 菩提 萨 陲 EOS\n",
      "< EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 106001/500001 [6:08:32<23:09:47,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368m 45s (- 1370m 39s) (106000 21%) 5.3852\n",
      "> SOS 就 这么 好奇 就 这么 幻想 EOS r a uj t NOP ian NOE 4 NOR\n",
      "= SOS 这么 孤单 的 童年 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 107999/500001 [6:15:35<20:11:11,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375m 48s (- 1364m 1s) (108000 21%) 5.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 108000/500001 [6:15:36<44:57:59,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 归来 吧 归来 哟 EOS r d v v NOP o NOE 4 NOR\n",
      "= SOS 我 已 厌倦 飘泊 EOS\n",
      "< SOS SOS SOS EOS SOS SOS EOS EOS SOS EOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS EOS SOS SOS EOS SOS EOS SOS SOS EOS SOS EOS SOS EOS EOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS SOS EOS EOS SOS EOS SOS SOS SOS SOS SOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 109999/500001 [6:22:46<22:41:49,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382m 59s (- 1357m 52s) (110000 22%) 5.3607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 110000/500001 [6:22:47<48:33:30,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 带 着 以往 的 热烈 EOS v r n uz c r NOP e NOE 6 NOR\n",
      "= SOS 合 我 守候 着 此时 彼刻 EOS\n",
      "< EOS SOS EOS EOS SOS SOS SOS SOS EOS EOS SOS SOS EOS SOS EOS SOS SOS EOS EOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS EOS SOS EOS SOS SOS EOS SOS SOS SOS SOS EOS SOS EOS SOS SOS SOS SOS EOS SOS EOS SOS EOS EOS SOS SOS EOS SOS EOS SOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 111999/500001 [6:29:49<26:17:56,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390m 2s (- 1351m 14s) (112000 22%) 4.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 112001/500001 [6:29:50<36:10:50,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 何处 去 寻找 EOS b uj n NOP i NOE 3 NOR\n",
      "= SOS 穿越时空 的 轨迹 EOS\n",
      "< SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS EOS EOS SOS SOS SOS SOS EOS SOS SOS SOS SOS EOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 114000/500001 [6:36:56<18:49:24,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397m 9s (- 1344m 46s) (114000 22%) 5.0397\n",
      "> SOS 有 谁 曾经 真心真意 爱 上 一只 蝴蝶 EOS v r v n d v a uv nz NOP iang NOE 9 NOR\n",
      "= SOS 有 谁 知道 蝴蝶 从来 不能 自由 地 飞翔 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 115999/500001 [6:44:07<20:50:25,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404m 20s (- 1338m 29s) (116000 23%) 5.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 116000/500001 [6:44:08<49:04:22,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 那 束 玫瑰 或许 会 悄悄的 告诉 她 EOS n p n e v v uj nr NOP a NOE 8 NOR\n",
      "= SOS 麻雀 在 庭院 嘻 闹 盛开 的 乔治亚 EOS\n",
      "< EOS SOS SOS EOS SOS SOS EOS SOS EOS EOS SOS SOS EOS EOS EOS EOS SOS SOS EOS SOS SOS EOS EOS SOS SOS SOS EOS EOS SOS EOS EOS EOS EOS SOS SOS EOS EOS SOS SOS SOS EOS EOS SOS EOS SOS SOS SOS EOS EOS SOS EOS SOS SOS SOS SOS EOS EOS EOS EOS EOS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 117999/500001 [6:51:11<24:32:01,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411m 24s (- 1331m 51s) (118000 23%) 5.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 118000/500001 [6:51:12<33:40:38,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 也 是 你 目头 有 卡高 EOS v d r v v d r v NOP ang NOE 8 NOR\n",
      "= SOS 想要 将 你 放 想要 将 你 放 EOS\n",
      "< SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS EOS SOS SOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 120000/500001 [6:58:15<24:52:49,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418m 27s (- 1325m 8s) (120000 24%) 4.9270\n",
      "> SOS 就算 这 是 灰色 人种 的 天堂 EOS r d d n z uj ng NOP ang NOE 7 NOR\n",
      "= SOS 你 依然 高举 区别 黑白 的 杖 EOS\n",
      "< SOS SOS EOS SOS SOS EOS EOS SOS SOS SOS SOS EOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 122000/500001 [7:05:15<26:26:46,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425m 28s (- 1318m 16s) (122000 24%) 4.8557\n",
      "> SOS 如果 我 问 你 EOS r uj t v v r NOP ang NOE 6 NOR\n",
      "= SOS 你 的 明天 会 是 怎样 EOS\n",
      "< EOS SOS EOS EOS SOS SOS SOS EOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 124001/500001 [7:12:09<20:08:02,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432m 21s (- 1311m 2s) (124000 24%) 4.7810\n",
      "> SOS 打开 电脑 爆满 EOS v d v n v r uj v NOP in NOE 8 NOR\n",
      "= SOS 看一看 才 发现 全都 是 你 的 来信 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 125999/500001 [7:19:02<21:47:47,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439m 15s (- 1303m 50s) (126000 25%) 4.7586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 126000/500001 [7:19:03<34:16:54,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 有 你 的 梦 和 我 所有 的 希望 古巨基 EOS r d r uj n r uj n nrt NOP i NOE 9 NOR\n",
      "= SOS 那儿 就是 我 的 天堂 我 的 家王 珍妮 EOS\n",
      "< SOS SOS 我 EOS SOS EOS EOS SOS EOS SOS SOS EOS SOS EOS SOS SOS SOS SOS EOS SOS EOS EOS SOS EOS EOS EOS EOS SOS EOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 127999/500001 [7:25:52<20:54:41,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446m 5s (- 1296m 27s) (128000 25%) 4.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 128000/500001 [7:25:53<47:01:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 先 开 个 会 EOS d nr NOP ei NOE 2 NOR\n",
      "= SOS 再 喝咖啡 EOS\n",
      "< EOS EOS SOS EOS SOS 混音 SOS SOS SOS SOS SOS EOS SOS EOS SOS SOS SOS SOS SOS EOS EOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS SOS EOS SOS SOS SOS EOS SOS SOS EOS SOS SOS EOS SOS EOS EOS SOS EOS SOS SOS EOS SOS EOS EOS EOS SOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 130001/500001 [7:32:51<20:48:38,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453m 4s (- 1289m 30s) (130000 26%) 4.8482\n",
      "> SOS 明明 都 有 感觉 EOS r d v NOP ui NOE 3 NOR\n",
      "= SOS 为什么 不敢 面对 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 132000/500001 [7:39:42<19:18:42,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459m 55s (- 1282m 11s) (132000 26%) 4.7380\n",
      "> SOS 停下 追赶 的 脚步 倾听 内心 的 声音 喔 EOS v y r uj n l v r uj ns NOP a NOE 10 NOR\n",
      "= SOS 出发 啦 我 的 朋友 别忘了 带上 你 的 吉他 EOS\n",
      "< SOS EOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 134000/500001 [7:46:38<25:42:03,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466m 51s (- 1275m 9s) (134000 26%) 4.8481\n",
      "> SOS 真的 话 假 的话 EOS d p v c NOP ua NOE 4 NOR\n",
      "= SOS 都 比 不了 那句话 EOS\n",
      "< EOS SOS SOS EOS SOS EOS SOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 135999/500001 [7:53:35<16:58:05,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473m 48s (- 1268m 8s) (136000 27%) 4.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 136000/500001 [7:53:36<27:21:38,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 将 美丽 的 回忆 慢慢 重 来 EOS ad f a n nr NOP uai NOE 5 NOR\n",
      "= SOS 突然 之间 浪漫 无法 释怀 EOS\n",
      "< SOS EOS EOS EOS SOS EOS EOS SOS EOS SOS EOS SOS SOS SOS EOS EOS SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 138000/500001 [8:00:29<23:41:14,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480m 42s (- 1260m 58s) (138000 27%) 4.7808\n",
      "> SOS 好像 情侣 亲切 又 甜蜜 EOS n z l n NOP e NOE 4 NOR\n",
      "= SOS 雨丝 淅沥沥 拥抱着 大地 EOS\n",
      "< SOS SOS SOS EOS EOS EOS EOS EOS EOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 140000/500001 [8:07:17<27:31:24,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487m 30s (- 1253m 35s) (140000 28%) 4.5686\n",
      "> SOS 我 找 不到 你 的 身影 EOS r v r s uj n NOP uang NOE 6 NOR\n",
      "= SOS 那 是 我 心里 的 光 EOS\n",
      "< EOS SOS SOS SOS SOS EOS SOS EOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141999/500001 [8:14:07<19:01:12,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494m 20s (- 1246m 18s) (142000 28%) 4.6155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 142001/500001 [8:14:08<22:17:56,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 炙热 了 千年 心中 的 火 EOS v v v v n NOP uo NOE 5 NOR\n",
      "= SOS 冷却 到 熄灭 毫无 线索 EOS\n",
      "< 在 在 在 EOS EOS SOS 在 SOS SOS SOS SOS SOS SOS SOS EOS SOS EOS SOS SOS EOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 144001/500001 [8:20:51<21:47:08,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501m 4s (- 1238m 45s) (144000 28%) 4.5518\n",
      "> SOS 我 满心欢喜 EOS c i NOP u NOE 2 NOR\n",
      "= SOS 虽然 不言不语 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 146000/500001 [8:27:37<19:13:45,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507m 50s (- 1231m 21s) (146000 29%) 4.5397\n",
      "> SOS 假装 正经 帮 她 把 问题 都 摆平 EOS d v ul NOP e NOE 3 NOR\n",
      "= SOS 不多 聊 了 EOS\n",
      "< EOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 148000/500001 [8:34:13<18:36:39,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514m 26s (- 1223m 31s) (148000 29%) 4.5589\n",
      "> SOS 像 送给 我 最 完美 告别 作 我 只是 观众 EOS v ul r d p r v p r n NOP o NOE 10 NOR\n",
      "= SOS 忘 了 我 曾 把 你 拥 在 我 心窝 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 150000/500001 [8:40:44<21:14:34,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520m 57s (- 1215m 34s) (150000 30%) 4.3523\n",
      "> SOS 忙碌 会议 你 头脑 转 不停 EOS r s n d v n NOP i NOE 6 NOR\n",
      "= SOS 我 街头 散步 偷偷 喘 口气 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 152000/500001 [8:47:15<19:25:28,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527m 28s (- 1207m 39s) (152000 30%) 4.3205\n",
      "> SOS 在 最美 的 夜空 中 眨眼 EOS r uj n d z uj n NOP uang NOE 7 NOR\n",
      "= SOS 我 的 眸是 最 闪亮 的 星光 EOS\n",
      "< SOS SOS EOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 154000/500001 [8:53:46<22:53:35,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533m 59s (- 1199m 44s) (154000 30%) 4.2476\n",
      "> SOS 躲猫猫 游戏 听 睡不着 的 摇篮曲 EOS v uz v uj n NOP v NOE 5 NOR\n",
      "= SOS 哼 着 熟悉 的 旋律 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 156000/500001 [9:00:14<17:32:36,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540m 27s (- 1191m 47s) (156000 31%) 4.2678\n",
      "> SOS 花里喃 着 耳语 迎 雾 没 了 EOS s v uz n v v ul NOP e NOE 7 NOR\n",
      "= SOS 怀里 拥 着 温度 沾露 凉 了 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 158000/500001 [9:06:52<19:37:29,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547m 5s (- 1184m 13s) (158000 31%) 4.4568\n",
      "> SOS 千万 记得 天涯 有人 在 等 你 EOS i r d d v NOP i NOE 5 NOR\n",
      "= SOS 风再疾再狂 我 也 不 放弃 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160000/500001 [9:13:34<20:44:12,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553m 47s (- 1176m 48s) (160000 32%) 4.4391\n",
      "> SOS 欧里 呀 EOS y y nr NOP ou NOE 3 NOR\n",
      "= SOS 啊 嘞 欧 EOS\n",
      "< EOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 162000/500001 [9:20:15<17:20:37,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560m 28s (- 1169m 22s) (162000 32%) 4.6562\n",
      "> SOS 对 吗 好 吗 我 又 在 笑 自己 EOS b v r uj n r v v NOP i NOE 8 NOR\n",
      "= SOS 所有 写给 你 的 信 我 没有 寄 EOS\n",
      "< SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 164000/500001 [9:27:00<19:14:27,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567m 13s (- 1162m 7s) (164000 32%) 5.0009\n",
      "> SOS 在 安静 的 早晨 里 突然 醒来 EOS v ul r d d p NOP ai NOE 6 NOR\n",
      "= SOS 想起 了 你 已 不 在 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 166000/500001 [9:33:42<19:42:13,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573m 55s (- 1154m 45s) (166000 33%) 4.6877\n",
      "> SOS 我 担心 会 有 谁 懂 的 疼爱 EOS z uj n NOP u NOE 3 NOR\n",
      "= SOS 雪白 的 礼服 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 168001/500001 [9:40:49<18:22:47,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581m 2s (- 1148m 14s) (168000 33%) 5.4306\n",
      "> SOS 老 情歌 EOS v s uj NOP e NOE 3 NOR\n",
      "= SOS 送给 心里 的 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 170000/500001 [9:47:49<21:42:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588m 2s (- 1141m 28s) (170000 34%) 5.2573\n",
      "> SOS 滋养 了 干涸 相信 我 能 是 你 的 EOS v d v t r q a uj n NOP ang NOE 9 NOR\n",
      "= SOS 彷佛 还 看见 昨日 那 张 悲伤 的 脸庞 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 172000/500001 [9:54:48<18:18:59,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595m 1s (- 1134m 41s) (172000 34%) 5.2018\n",
      "> SOS 此时此刻 的 今天 EOS t d v p n f NOP ong NOE 6 NOR\n",
      "= SOS 当初 不 应该 在 照片 中 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 174000/500001 [10:01:47<18:21:56,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602m 0s (- 1127m 54s) (174000 34%) 5.2760\n",
      "> SOS 他 赔 了 股票 又 赔 了 期货 EOS c nr r n NOP e NOE 4 NOR\n",
      "= SOS 还要 大修 他 那辆车 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 176000/500001 [10:08:48<18:40:38,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609m 1s (- 1121m 10s) (176000 35%) 5.2228\n",
      "> SOS 给 自己 点 掌声 EOS v m v s uj a NOP un NOE 6 NOR\n",
      "= SOS 找 一 找 心里 的 单纯 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 178000/500001 [10:15:51<22:49:58,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616m 3s (- 1114m 27s) (178000 35%) 5.2501\n",
      "> SOS 笑 月 媚 花 情意 长 EOS t f v n zg NOP an NOE 5 NOR\n",
      "= SOS 秋季 里 来 百花 妍 EOS\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 180000/500001 [10:22:53<19:35:42,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623m 6s (- 1107m 45s) (180000 36%) 5.2845\n",
      "> SOS 傻傻的 付出 默默 每 分 每刻 的 所有 EOS m f p n NOP ou NOE 4 NOR\n",
      "= SOS 两年 后面 对 朋友 EOS\n",
      "< SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 182000/500001 [10:29:58<18:08:22,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630m 11s (- 1101m 6s) (182000 36%) 5.2099\n",
      "> SOS 想念 不会 偷懒 EOS r uj n vn p r v NOP uan NOE 7 NOR\n",
      "= SOS 我 的 梦 通通 给 你 保管 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 184000/500001 [10:37:02<19:04:56,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637m 15s (- 1094m 25s) (184000 36%) 5.2595\n",
      "> SOS 你 总 当做 宝贝 EOS r p r uj n d d a NOP ei NOE 8 NOR\n",
      "= SOS 你 给 我 的 爱 也许 不 完美 EOS\n",
      "< SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 186000/500001 [10:44:03<20:53:44,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644m 16s (- 1087m 38s) (186000 37%) 5.2346\n",
      "> SOS 狂呼 我 空虚 空虚 EOS v d r v NOP ui NOE 4 NOR\n",
      "= SOS 恨 极为 她 心碎 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 188000/500001 [10:50:59<19:59:24,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651m 12s (- 1080m 43s) (188000 37%) 5.1637\n",
      "> SOS 说 故事 的 人 是 我 EOS t uj n a NOP o NOE 4 NOR\n",
      "= SOS 过去 的 画面 沉默 EOS\n",
      "< SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 190000/500001 [10:57:52<19:02:03,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658m 4s (- 1073m 42s) (190000 38%) 4.9683\n",
      "> SOS 过去 汹涌 而至 EOS n v v t NOP uo NOE 4 NOR\n",
      "= SOS 问候声 熟悉 如 昨 EOS\n",
      "< SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 192001/500001 [11:04:47<17:37:21,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665m 0s (- 1066m 47s) (192000 38%) 5.0889\n",
      "> SOS 云雾 里 绑起 双脚 跳栏 EOS n d n NOP an NOE 3 NOR\n",
      "= SOS 威风 似 神探 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 194000/500001 [11:11:47<21:11:29,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672m 0s (- 1059m 58s) (194000 38%) 5.2277\n",
      "> SOS 我 终于 敢 和 自己 来 面对面 EOS r v r p v n uj a NOP ie NOE 8 NOR\n",
      "= SOS 那 是 我 用 坚强 武装 的 胆怯 EOS\n",
      "< EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 196000/500001 [11:18:44<20:43:52,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678m 57s (- 1053m 3s) (196000 39%) 5.0048\n",
      "> SOS 绝不 让 你 再 离去 EOS v r n NOP u NOE 3 NOR\n",
      "= SOS 抓住 这次 机遇 EOS\n",
      "< SOS SOS EOS EOS EOS SOS EOS SOS SOS SOS EOS SOS SOS SOS EOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 198000/500001 [11:25:22<18:48:13,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685m 35s (- 1045m 41s) (198000 39%) 4.6581\n",
      "> SOS 我们 提升 自己 走向 超越 之 路 EOS r r m a uj n NOP ang NOE 6 NOR\n",
      "= SOS 那 每 一个 好 的 地方 EOS\n",
      "< EOS SOS SOS SOS SOS SOS EOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 200000/500001 [11:32:01<17:58:26,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692m 14s (- 1038m 21s) (200000 40%) 4.7025\n",
      "> SOS 红红的 小脸儿 温暖 我 的 心窝 EOS v r vn uj i NOP uo NOE 5 NOR\n",
      "= SOS 点亮 我 生命 的 火火火火火火 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 202000/500001 [11:38:53<18:44:48,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699m 6s (- 1031m 22s) (202000 40%) 5.1121\n",
      "> SOS 任 这 世间 谩骂 是 疯子 EOS c n v v r v NOP i NOE 6 NOR\n",
      "= SOS 而 全盘 赌注 得失 有天 知 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 204000/500001 [11:45:57<18:58:30,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706m 10s (- 1024m 38s) (204000 40%) 5.2223\n",
      "> SOS 面对 未来 EOS r x v NOP uan NOE 3 NOR\n",
      "= SOS 怎 麽 判断 EOS\n",
      "< EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206001/500001 [11:52:59<13:02:04,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713m 12s (- 1017m 52s) (206000 41%) 5.2240\n",
      "> SOS 我 这样 的 男人 EOS p n v NOP ang NOE 3 NOR\n",
      "= SOS 在 人世间 飘荡 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 208000/500001 [12:00:00<19:25:17,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720m 13s (- 1011m 5s) (208000 41%) 5.1877\n",
      "> SOS 为何 你 能 爱 得 轻松自如 EOS r v r n v a NOP u NOE 6 NOR\n",
      "= SOS 你 说 你 天生 爱 孤独 EOS\n",
      "< EOS SOS SOS SOS SOS SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 210000/500001 [12:07:04<19:05:06,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727m 17s (- 1004m 21s) (210000 42%) 5.2452\n",
      "> SOS 我 斩断 你 的 手 EOS r d v n n a n i NOP i NOE 8 NOR\n",
      "= SOS 你 再 去 学 人家 坏 样 偷东西 EOS\n",
      "< SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 212000/500001 [12:14:06<19:53:02,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734m 19s (- 997m 33s) (212000 42%) 5.2194\n",
      "> SOS 躲过 一个 巨大 伤痛 EOS p v a v v nr NOP iang NOE 6 NOR\n",
      "= SOS 为了 要 重新 开始 选择 原谅 EOS\n",
      "< SOS SOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 214000/500001 [12:21:07<19:56:05,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741m 20s (- 990m 46s) (214000 42%) 5.1878\n",
      "> SOS 一次 一次 徘徊 在 十字街头 EOS c r i NOP u NOE 3 NOR\n",
      "= SOS 因为 我 不在乎 EOS\n",
      "< SOS SOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 216000/500001 [12:28:07<17:33:37,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748m 20s (- 983m 55s) (216000 43%) 5.2271\n",
      "> SOS 白鸽 往 蓝天 飞翔 EOS n l n NOP ang NOE 3 NOR\n",
      "= SOS 沙漠 拥抱着 仙人掌 EOS\n",
      "< SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 218000/500001 [12:35:10<20:06:56,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755m 23s (- 977m 8s) (218000 43%) 5.2145\n",
      "> SOS 窗外 的 细雨 无声无息 飘落 EOS d ns v ul nz NOP ong NOE 5 NOR\n",
      "= SOS 将 美丽 化成 了 彩虹 EOS\n",
      "< EOS SOS SOS SOS SOS SOS EOS EOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 220000/500001 [12:42:14<16:53:05,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762m 27s (- 970m 24s) (220000 44%) 5.2693\n",
      "> SOS 你 知道 EOS c r p r d NOP ui NOE 5 NOR\n",
      "= SOS 只有 你 对 我 绝对 EOS\n",
      "< <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 222000/500001 [12:49:17<16:27:52,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769m 30s (- 963m 36s) (222000 44%) 5.2723\n",
      "> SOS 我 是 飞鸟 你 是 天 EOS v r v p r s NOP ian NOE 6 NOR\n",
      "= SOS 放任 我 翱翔 在 你 胸前 EOS\n",
      "< EOS SOS EOS SOS <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 223835/500001 [12:55:42<13:44:32,  5.58it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Begin!\n",
    "with tqdm(total=n_epochs + 1) as pbar:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        # Get training data for this cycle\n",
    "        training_pair = variables_from_pair(random.choice(pairs))\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "        # Run the train function\n",
    "        loss = train(input_variable, target_variable, model, model_optimizer, criterion)\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch == 0: continue\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, float(epoch) / n_epochs), epoch, float(epoch) / n_epochs * 100, print_loss_avg)\n",
    "            print(print_summary)\n",
    "            evaluate_randomly()\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss\n",
    "\n",
    "Plotting is done with matplotlib, using the array `plot_losses` that was created while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the network\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = decoder_seq = Variable(torch.LongTensor([[SOS_token]])) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_seq = decoder_input.cuda()\n",
    "\n",
    "    \n",
    "    decoded_words = []\n",
    "    K = input_variable.view(-1,1)\n",
    "    Q = decoder_seq.view(1,1)\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output = model(Q,K)[0,-1,:]\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = torch.topk(decoder_output, k=1, dim=-1)\n",
    "        ni = topi.item()\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "        Q = torch.cat([Q, decoder_input], dim=1)\n",
    "        \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    \n",
    "#     print('>', pair[0])\n",
    "#     print('=', pair[1])\n",
    "#     print('<', output_sentence)\n",
    "#     print('')\n",
    "    print '>', pair[0]\n",
    "    print '=', pair[1]\n",
    "    print '<', output_sentence\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SOS 亿万人民 高歌 同唱 EOS r ns d d v NOP iang NOE 5 NOR\n",
      "= SOS 咱们 中国 一定 更加 富强 EOS\n",
      "< 抬头挺胸 EOS 抬头挺胸 EOS 抬头挺胸 抬头挺胸 抬头挺胸 EOS EOS 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 EOS EOS 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 EOS EOS EOS 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 EOS 抬头挺胸 抬头挺胸 抬头挺胸 EOS EOS 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 抬头挺胸 EOS EOS 抬头挺胸 抬头挺胸 抬头挺胸\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing attention\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
    "\n",
    "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(u\"SOS 所以 我 好 愿意 EOS v r l NOP i NOE 3 NOR\")\n",
    "print len(output_words), attentions.shape\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "zhfont = matplotlib.font_manager.FontProperties(fname=\"/home/k123/simhei.ttf\")\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90, fontproperties=zhfont)\n",
    "    ax.set_yticklabels([''] + output_words, fontproperties=zhfont)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print 'input =', input_sentence\n",
    "    print 'output =', ' '.join(output_words)\n",
    "    show_attention(input_sentence, output_words, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "evaluate_and_show_attention(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"elle a cinq ans de moins que moi .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"elle est trop petit .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"je ne crains pas de mourir .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises\n",
    "\n",
    "* Try with a different dataset\n",
    "    * Another language pair\n",
    "    * Human &rarr; Machine (e.g. IOT commands)\n",
    "    * Chat &rarr; Response\n",
    "    * Question &rarr; Answer\n",
    "* Replace the embedding pre-trained word embeddings such as word2vec or GloVe\n",
    "* Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
    "* If you use a translation file where pairs have two of the same phrase (`I am test \\t I am test`), you can use this as an autoencoder. Try this:\n",
    "    * Train as an autoencoder\n",
    "    * Save only the Encoder network\n",
    "    * Train a new Decoder for translation from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2.7.14 (conda)",
   "language": "python",
   "name": "python-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
