{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667085/667085 [00:01<00:00, 502697.37it/s]\n",
      "100%|██████████| 18338/18338 [00:02<00:00, 7550.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size : 6450, max len : 4016, min len : 5, mean : 180, std : 117\n",
      "lyrics number : 18223\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "with open('../hw_train.csv', 'rb') as f:\n",
    "    ls = f.readlines()[1:]\n",
    "# count vocabulary and max sequence length\n",
    "lyrics_map = {}\n",
    "bos_token = 's'.decode('utf8')\n",
    "eos_token = 'e'.decode('utf8')\n",
    "line_token = 'l'.decode('utf8')\n",
    "oov_token = 'o'.decode('utf8')\n",
    "none_lyrics_words = [u'編詞', u'作曲', u'作詞', u'編曲', u'監製']\n",
    "vocab = [bos_token, eos_token, line_token, oov_token]\n",
    "lens = []\n",
    "c = 0 \n",
    "with tqdm(total=len(ls)) as pbar:\n",
    "    for l in ls:\n",
    "        l = l.decode('utf8')\n",
    "        no, l = l.strip().split(',')\n",
    "        no = int(no)\n",
    "        if no not in lyrics_map:\n",
    "            lyrics_map[no] = []\n",
    "        lyrics_map[no].append(l)\n",
    "        pbar.update(1)\n",
    "# split into Q,K pair\n",
    "with tqdm(total=len(lyrics_map)) as pbar:\n",
    "    for k,v in lyrics_map.items():\n",
    "        line_num = len(v)\n",
    "        V = [bos_token, ]\n",
    "        Q = [bos_token, ]\n",
    "        for i,l in enumerate(v):\n",
    "            if len(l) <= 1:\n",
    "                continue\n",
    "            exist_none_layrics_word = False\n",
    "            for nw in none_lyrics_words:\n",
    "                if nw in l:\n",
    "                    exist_none_layrics_word = True\n",
    "                    break\n",
    "            if exist_none_layrics_word:\n",
    "                continue\n",
    "            \n",
    "            for ws in l.strip().split(' '):\n",
    "                for w in ws:\n",
    "                    if i <= line_num//2:\n",
    "                        V.append(w)\n",
    "                    else:\n",
    "                        Q.append(w)\n",
    "                    vocab.append(w)\n",
    "            if i <= line_num//2:\n",
    "                V.append(line_token)\n",
    "            else:\n",
    "                Q.append(line_token)\n",
    "        \n",
    "        V.append(eos_token)\n",
    "        Q.append(eos_token)\n",
    "        if len(Q) == 2 or len(V) == 2:\n",
    "            lyrics_map.pop(k)\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "        lens.append(len(Q))\n",
    "        lens.append(len(V))\n",
    "        lyrics_map[k] = (Q, V)\n",
    "        pbar.update(1)\n",
    "            \n",
    "print 'vocabulary size : %d, max len : %.0f, min len : %.0f, mean : %.0f, std : %.0f' % (len(set(vocab)), np.max(lens), np.min(lens), np.mean(lens), np.std(lens))\n",
    "print 'lyrics number : %d' % len(lyrics_map)\n",
    "# print np.max(lens), np.mean(lens), np.std(lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6450 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "from constants import MAX_SEQ_LEN, VOCAB_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "texts = vocab\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=VOCAB_DIM, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=False, split=' ', char_level=True, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "with open('tokenizer','wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 242) (1, 233)\n"
     ]
    }
   ],
   "source": [
    "from constants import MAX_SEQ_LEN\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "idx = np.random.permutation(len(lyrics_map))\n",
    "val_num = len(lyrics_map)//10\n",
    "train_idx, val_idx = idx[val_num:], idx[:val_num]\n",
    "train_u_map = {k:lyrics_map[k] for k in lyrics_map.keys()[val_num:]}\n",
    "val_u_map = {k:lyrics_map[k] for k in lyrics_map.keys()[:val_num]}\n",
    "def boostrap_generator(lyrics_map, max_seq_len, tokenizer):\n",
    "    while True:\n",
    "        keys = lyrics_map.keys()\n",
    "        for idx in np.random.permutation(len(lyrics_map)):\n",
    "            no = keys[idx]\n",
    "            Q, K = lyrics_map[no]\n",
    "            Q = np.array([tokenizer.word_index[w] if w in tokenizer.word_index else tokenizer.word_index[oov_token] for w in Q], dtype=np.int32).reshape(1,-1)\n",
    "            K = np.array([tokenizer.word_index[w] if w in tokenizer.word_index else tokenizer.word_index[oov_token] for w in K], dtype=np.int32).reshape(1,-1)\n",
    "            yield Q, K\n",
    "    \n",
    "bat = 4\n",
    "G = boostrap_generator(train_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "q, k = next(G)\n",
    "    \n",
    "print q.shape, k.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 129, 6451])\n",
      "2054195\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import VOCAB_DIM, D_MODEL, MAX_SEQ_LEN\n",
    "# construct neuron network\n",
    "class Seq2seq_att(nn.Module):\n",
    "\n",
    "    def __init__(self, dm, num_lay):\n",
    "        super(Seq2seq_att, self).__init__()\n",
    "#         for construct cache positional encoding matrix.\n",
    "        self.emb = nn.Embedding(VOCAB_DIM+1, dm, padding_idx=0)\n",
    "        self.encoder = nn.GRU(dm, dm, num_lay, batch_first=True)\n",
    "        self.decoder = nn.GRU(dm, dm, num_lay, batch_first=True)\n",
    "        self.linear = nn.Linear(dm, VOCAB_DIM+1)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        K = self.emb(K)\n",
    "        Q = self.emb(Q)\n",
    "        en_out, hn = self.encoder(K) \n",
    "        Q, _ = self.decoder(Q, hn)\n",
    "        batch, q_len, _ = Q.size()\n",
    "        batch, k_len, _ = K.size()\n",
    "        att_in = torch.cat([en_out, Q], dim=1)\n",
    "        Q_mask = self.Q_mask_matrix(batch, q_len)\n",
    "        K_mask = torch.zeros([batch, q_len, k_len], dtype=torch.uint8).cuda()\n",
    "        \n",
    "        mask = torch.cat([K_mask, Q_mask], dim=-1)\n",
    "        out = self.dot_attention(Q, att_in, att_in, mask=mask)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y = self.linear(out)\n",
    "        return y\n",
    "    def Q_mask_matrix(self, batch, Q_len):\n",
    "#         ByteTensor\n",
    "        mask = torch.zeros([1, Q_len, Q_len], dtype=torch.uint8, requires_grad=False)\n",
    "        for i in range(Q_len):\n",
    "            mask[0,i,i+1:] = 1\n",
    "        return mask.repeat(batch,1, 1).cuda()\n",
    "    \n",
    "    def dot_attention(self, Q, K, V, mask):\n",
    "        assert Q.size()[-1] == K.size()[-1]\n",
    "        assert len(Q.size()) == 3 and len(K.size()) == 3 and len(V.size()) == 3\n",
    "        out = torch.matmul(Q,K.permute(0,2,1))\n",
    "        if mask is not None:\n",
    "            out.masked_fill_(mask, -float('inf'))\n",
    "        return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "\n",
    "\n",
    "bat = 7\n",
    "lay_num = 2\n",
    "model = Seq2seq_att(D_MODEL, lay_num).cuda()\n",
    "# print(o.size())\n",
    "q, k = next(G)\n",
    "q = torch.LongTensor(q).cuda()\n",
    "k = torch.LongTensor(k).cuda()\n",
    "# Q = torch.randint(VOCAB_DIM+1, [bat, MAX_SEQ_LEN]).cuda()\n",
    "# K = torch.randint(VOCAB_DIM+1, [bat, MAX_SEQ_LEN]).cuda()\n",
    "\n",
    "o = model(q, k)\n",
    "print(o.size())\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/100000000 [00:01<9658:47:46,  2.88it/s, acc : 0.068, val_acc : 0.075, loss : 0.068, val_loss : 0.075]/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Seq2seq_att. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|          | 2004/100000000 [01:53<1356:48:06, 20.47it/s, acc : 0.172, val_acc : 0.161, loss : 0.172, val_loss : 0.161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred : 我们你l要你们己l果llll我样l我们有你你你l我lll我经不你的我要llll我是你的lllllllll我们有你你你l我lll我你你的的ll以lll我是l的在你的ll是你lll我们你你你你lllll我经不你的不要我lll我是你的lll柔llll我我们有你你你lllll我你你的的ll以lll我是l的在你的我你是你么ll我\n",
      "train label : s收拾好行李我要去哪里l只要跟着你可是梦一推就醒l车外的风景有你的身影l多希望是你牵起我这身白衣裙l是我的婚礼对面不是你l我控制不了我自己如果你出现在这里l我终于成了别人的女人l曾经为你奋不顾身的人l只为你偶尔的温柔越走越深l我终于成了别人的女人l等到最后无路可退的人l还担心留给你的爱还是那么深l车外的风景有你的身影l多希望是你牵起我这身白衣裙l是我的婚礼对面不是你le\n",
      "validation pred : 我们心lll我们心lll我们心lll我的你次ll是l要lll我l\n",
      "validation label : s我的吧的吧l我的吧的吧l我的吧的吧说着一句谁也听不懂的话l我结吧结吧l我结吧结吧l我结吧结吧唱着一句谁也听不懂的歌le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4003/100000000 [03:24<1340:01:41, 20.73it/s, acc : 0.205, val_acc : 0.211, loss : 0.205, val_loss : 0.211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred : 我你见你惜l此llll我llll亮lllll我起lll界l经不有ll我的经不有l一丽的界l我春llllllllll一的的个人待l的ll我一丽的l界l经l抱ll我的经不有l样丽l界l的\n",
      "train label : s心升明月l飞鸟归山林落日入东海l我心上的人你从哪里来l青山随云走大地沿河流l这深情一片等待谁收留l这广阔的天地如何安放我l我如何安放这广阔天地l我心深似海你宛如明月l这般美如画却遥不可及le\n",
      "validation pred : 你的不经ll不你lll我你的果的lll我是是你你么l我l的一ll的ll的心诺l你的你的果你受l你是样的开l的我的\n",
      "validation label : s当我想你的时候l我的心在颤抖l当我想你的时候l泪水也悄悄的滑落l当我想你的时候l才知道寂寞是什么l当我想你的时候l谁听我诉说le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6003/100000000 [04:58<1372:47:01, 20.23it/s, acc : 0.214, val_acc : 0.225, loss : 0.214, val_loss : 0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred : 我不我l天l然要ll是lll不在ll的我l样去llll我里l个都美l我想l能lll我要l去我寞的有ll个人l么l什天lll个歌l我少年春l生l心l成了己l我要要不经lllll我寞的有ll要ll样l寞l人l以lll我\n",
      "train label : s寂寞中想起需要我么l闷闷地想听一首歌l初恋的年头都与我们渡过l曾是醉人情节l再想极傻l玩乐声遮掩不了痛楚l共大家一起苦笑么l多少青年人l伤了变成自我l谁亦也曾年少爱玩火l莫为昨日独自难过l又是现实又是无心的错l没有开始知道这原是结果le\n",
      "validation pred : 我的的我是能再ll的心丽l我想你你天的眼ll我雨你的得我我样l我么不是不见lll我前不不能让我l我的不能l我l我的我的l去l市lll的l去lll我们你身天l间ll市ll默l论l我想有你一你的命l着ll是我么多ll我的现在我的心命l着我llllll我的的我是能再ll的心丽l我的的我是能再ll的心丽l我息\n",
      "validation label : s我想是不期的而遇l你在二月的春风里l怎么就会遇见了你l从此我不再是我l你也不再是你l我想是春天的旨意l风把你吹到了这里l怎么就会遇见了你l从此我不再是我l你也不再是你l你在我走过的城市里走我走过的脚印l我在你千里之外的城市里默默无闻l我没有成为你生活牵绊你总是那么单纯l你出现了我的生活带着前一天的余温le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7672/100000000 [06:28<1405:30:39, 19.76it/s, acc : 0.220, val_acc : 0.221, loss : 0.220, val_loss : 0.221] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-960dab7da1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduled_sampling_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduled_sampling_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1414a37f76e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0men_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f<split>%s<split>%s<split>%s<split>%s\\n' % (n_iter, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label)\n",
    "    log_file_stream.write(log_text.encode('utf8'))\n",
    "    if n_iter % 10 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "def normal_acc(pred, label):\n",
    "    pred = torch.argmax(pred, dim=-1)\n",
    "    mask = torch.ones_like(label, dtype=torch.uint8)\n",
    "#     \n",
    "    acc = pred == label\n",
    "    acc = torch.sum(acc).item() / float(torch.sum(mask).item())\n",
    "    \n",
    "    return acc\n",
    "def seq2text(output, index_word):\n",
    "    assert len(output.size()) == 1\n",
    "    seq = output\n",
    "    s = ''\n",
    "    for i in seq:\n",
    "        i = int(i.item())\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i not in index_word:\n",
    "            w = oov_token\n",
    "        else:\n",
    "            w = index_word[i]\n",
    "        s += w\n",
    "    return s\n",
    "    \n",
    "def rev_mask(m):\n",
    "    out = torch.ones_like(m, dtype=torch.uint8, requires_grad=False)\n",
    "    out.masked_fill_(m, 0)\n",
    "    return out\n",
    "def scheduled_sampling_rate(acc):\n",
    "    return (acc)/3.\n",
    "def scheduled_sampling_label(output, label, rate):\n",
    "    assert len(label.size()) == 2 and len(output.size()) == 2\n",
    "    ret = torch.zeros_like(label)\n",
    "    for b in range(label.size()[0]):\n",
    "        for i in range(label.size()[1]):\n",
    "            r = np.random.random()\n",
    "            if r < rate:\n",
    "                ret[b,i] = output[b,i]\n",
    "            else:\n",
    "                ret[b,i] = label[b,i]\n",
    "    return ret\n",
    "                \n",
    "acc_q = deque(maxlen=100)\n",
    "loss_q = deque(maxlen=10)\n",
    "acc = 0\n",
    "val_acc_q = deque(maxlen=100)\n",
    "val_loss_q = deque(maxlen=10)\n",
    "\n",
    "t = time.time()\n",
    "best_loss = float('inf')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "G = boostrap_generator(train_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "val_G = boostrap_generator(val_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "# criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "weight = torch.ones([VOCAB_DIM+1,], dtype=torch.float)\n",
    "weight[tokenizer.word_index[line_token]] = 100.\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=weight.cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "print 'start training.'\n",
    "with open('log-att.txt', 'w') as f:\n",
    "    with open('best-att.txt', 'w') as best_log:\n",
    "        iters = 100000000\n",
    "        with tqdm(total=iters) as pbar:\n",
    "            for it in range(iters):\n",
    "                optimizer.zero_grad()\n",
    "                model.train()\n",
    "                q, k = next(G)\n",
    "                q = torch.LongTensor(q).cuda()\n",
    "                k = torch.LongTensor(k).cuda()\n",
    "\n",
    "                q.requires_grad_(False)\n",
    "                k.requires_grad_(False)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    output = model(q, k)\n",
    "                q = scheduled_sampling_label(torch.argmax(output, dim=-1), q[:,:-1], scheduled_sampling_rate(acc))\n",
    "            \n",
    "\n",
    "                output = model(q, k)\n",
    "                y = q[:,1:]\n",
    "#                 loss = torch.sum(criterion(output, y) * pad_mask[:,1:, :]) \n",
    "                loss = criterion(output[:,:-1,:].permute(0,2,1), y) \n",
    "                label = y\n",
    "\n",
    "                pred = output[:,:-1,:,]\n",
    "                acc = normal_acc(pred, label)\n",
    "                acc_q.append(acc)\n",
    "                train_pred = seq2text(torch.argmax(output[0,:,:], dim=-1), tokenizer.index_word)\n",
    "                train_label= seq2text(k[0,:], tokenizer.index_word)\n",
    "                loss.backward()\n",
    "                loss_q.append(loss.item())\n",
    "                \n",
    "                optimizer.step()\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    q, k = next(val_G)\n",
    "                    q = torch.LongTensor(q).cuda()\n",
    "                    k = torch.LongTensor(k).cuda()\n",
    "                    \n",
    "                    q.requires_grad_(False)\n",
    "                    k.requires_grad_(False)\n",
    "                    \n",
    "                    output = model(q, k)\n",
    "                    y = q[:,1:]\n",
    "                    val_loss = criterion(output[:,:-1,:,].permute(0,2,1), y) \n",
    "                    label = y\n",
    "\n",
    "                    pred = output[:,:-1,:,]\n",
    "                    val_acc = normal_acc(pred, label)\n",
    "                    val_acc_q.append(val_acc)\n",
    "                    val_pred = seq2text(torch.argmax(output[0,:,:], dim=-1), tokenizer.index_word)\n",
    "                    val_label= seq2text(k[0,:], tokenizer.index_word)\n",
    "                    val_loss_q.append(val_loss.item())\n",
    "\n",
    "\n",
    "                \n",
    "                acc = np.mean(acc_q)\n",
    "                val_acc = np.mean(val_acc_q)\n",
    "                loss = np.mean(acc_q)\n",
    "                val_loss = np.mean(val_acc_q)\n",
    "                \n",
    "#                     pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss : %.3f, val_loss : %.3f \\t %.3f, %.3f, %.3f, %.3f' % (acc, val_acc, loss.item(), val_loss.item(), a,b,c,d), refresh=False)\n",
    "                pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss : %.3f, val_loss : %.3f' % (acc, val_acc, loss.item(), val_loss.item()), refresh=False)\n",
    "                pbar.update(batch_size)\n",
    "                dump_log(model, (it+1)*batch_size, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label, f,'./tmp-att.pt')\n",
    "                if val_loss.item() < best_loss and it > 100:\n",
    "                    torch.save(model, './best-att.pt')\n",
    "                    best_loss = val_loss\n",
    "                    best_log.write('%d\\t%.5f\\n' % ((it+1)*batch_size, best_loss))\n",
    "                    best_log.flush()\n",
    "                if it % 2000 == 0 and it >= 100: \n",
    "                    print 'train pred : %s\\ntrain label : %s' % (train_pred, train_label)\n",
    "                    print 'validation pred : %s\\nvalidation label : %s' % (val_pred, val_label)\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print output.shape\n",
    "print y.shape\n",
    "print q.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
