{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667085/667085 [00:01<00:00, 497470.43it/s]\n",
      "100%|██████████| 18338/18338 [00:02<00:00, 7511.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size : 6456, max len : 4026, mean : 179, std : 118\n",
      "lyrics number : 18338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "with open('../hw_train.csv', 'rb') as f:\n",
    "    ls = f.readlines()[1:]\n",
    "# count vocabulary and max sequence length\n",
    "lyrics_map = {}\n",
    "bos_token = 's'.decode('utf8')\n",
    "eos_token = 'e'.decode('utf8')\n",
    "line_token = 'l'.decode('utf8')\n",
    "oov_token = 'o'.decode('utf8')\n",
    "\n",
    "none_lyrics_words = [u'編詞', u'作曲', u'作詞', u'編曲', u'監製']\n",
    "vocab = [bos_token, eos_token, line_token]\n",
    "lens = []\n",
    "c = 0 \n",
    "with tqdm(total=len(ls)) as pbar:\n",
    "    for l in ls:\n",
    "        l = l.decode('utf8')\n",
    "        no, l = l.strip().split(',')\n",
    "        no = int(no)\n",
    "        if no not in lyrics_map:\n",
    "            lyrics_map[no] = []\n",
    "        lyrics_map[no].append(l)\n",
    "        pbar.update(1)\n",
    "# split into Q,K pair\n",
    "with tqdm(total=len(lyrics_map)) as pbar:\n",
    "    for k,v in lyrics_map.items():\n",
    "        line_num = len(v)\n",
    "        V = [bos_token, ]\n",
    "        Q = [bos_token, ]\n",
    "        for i,l in enumerate(v):\n",
    "            exist_none_layrics_word = False\n",
    "            for nw in none_lyrics_words:\n",
    "                if nw in l:\n",
    "                    exist_none_layrics_word = True\n",
    "                    break\n",
    "            if exist_none_layrics_word:\n",
    "                continue\n",
    "            \n",
    "            for ws in l.strip().split(' '):\n",
    "                for w in ws:\n",
    "                    if i <= line_num//2:\n",
    "                        V.append(w)\n",
    "                    else:\n",
    "                        Q.append(w)\n",
    "                    vocab.append(w)\n",
    "            if i <= line_num//2:\n",
    "                V.append(line_token)\n",
    "            else:\n",
    "                Q.append(line_token)\n",
    "        V.append(eos_token)\n",
    "        Q.append(eos_token)\n",
    "        lens.append(len(Q))\n",
    "        lens.append(len(V))\n",
    "        lyrics_map[k] = (Q, V)\n",
    "        pbar.update(1)\n",
    "            \n",
    "print 'vocabulary size : %d, max len : %.0f, mean : %.0f, std : %.0f' % (len(set(vocab)), np.max(lens), np.mean(lens), np.std(lens))\n",
    "print 'lyrics number : %d' % len(lyrics_map)\n",
    "# print np.max(lens), np.mean(lens), np.std(lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6457 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "from constants import MAX_SEQ_LEN, VOCAB_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "texts = vocab\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=VOCAB_DIM, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=False, split=' ', char_level=True, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "with open('tokenizer','wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 108) (1, 116)\n"
     ]
    }
   ],
   "source": [
    "from constants import MAX_SEQ_LEN\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "idx = np.random.permutation(len(lyrics_map))\n",
    "val_num = len(lyrics_map)//10\n",
    "train_idx, val_idx = idx[val_num:], idx[:val_num]\n",
    "train_u_map = {k:lyrics_map[k] for k in lyrics_map.keys()[val_num:]}\n",
    "val_u_map = {k:lyrics_map[k] for k in lyrics_map.keys()[:val_num]}\n",
    "def boostrap_generator(lyrics_map, max_seq_len, tokenizer):\n",
    "    while True:\n",
    "        keys = lyrics_map.keys()\n",
    "        for idx in np.random.permutation(len(lyrics_map)):\n",
    "            no = keys[idx]\n",
    "            Q, K = lyrics_map[no]\n",
    "            Q = np.array([tokenizer.word_index[w] if w in tokenizer.word_index else tokenizer.word_index[oov_token] for w in Q], dtype=np.int32).reshape(1,-1)\n",
    "            K = np.array([tokenizer.word_index[w] if w in tokenizer.word_index else tokenizer.word_index[oov_token] for w in K], dtype=np.int32).reshape(1,-1)\n",
    "            yield Q, K\n",
    "    \n",
    "bat = 4\n",
    "G = boostrap_generator(train_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "q, k = next(G)\n",
    "    \n",
    "print q.shape, k.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/backends/cudnn/__init__.py:102: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 98, 6451])\n",
      "2054195\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Seq2seq import Seq2seq\n",
    "from constants import D_MODEL, MAX_SEQ_LEN\n",
    "\n",
    "bat = 7\n",
    "lay_num = 2\n",
    "model = Seq2seq(D_MODEL, lay_num).cuda()\n",
    "# print(o.size())\n",
    "q, k = next(G)\n",
    "q = torch.LongTensor(q).cuda()\n",
    "k = torch.LongTensor(k).cuda()\n",
    "# Q = torch.randint(VOCAB_DIM+1, [bat, MAX_SEQ_LEN]).cuda()\n",
    "# K = torch.randint(VOCAB_DIM+1, [bat, MAX_SEQ_LEN]).cuda()\n",
    "\n",
    "o = model(q, k)\n",
    "print(o.size())\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2003/100000000 [04:25<3104:42:26,  8.95it/s, acc : 0.202, val_acc : 0.190, loss : 0.202, val_loss : 0.190]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred : 我你么l不以l我是我我我的lll我要要一我lll我要要一你lll我弃我我l有我ll我天的的的我个l我间的有你ll我有我的要llll我们的不有你ll我我我心要我ll我爱我寞l我我ll我天的的我我我l我我么l不以l我是我我我llll我要要我我lll我要要一你lll我弃我ll有我ll我天的的的我个l我间的有你ll我有我的要llll我们的不有你ll我我我心要我ll我爱我寞l我我ll我寞\n",
      "train label : s首先告诉你我是一个人l然后再告诉你我刚单身l孤单的夜里遭遇伤心l摇摇手机排遣郁闷l如果你现在也是一个人l感谢你接受我添加邀请l都是陌生人不要拘谨l反正神马都是浮云l今夜我愿陪着你l说什么都可以l只要别跟我谈感情l不想再看旧伤痕l不想再为谁冲动l放下过去只要开心l今夜我们在一起l时空没有距离l只是我不想谈感情l我们都没有情人l当然更不是情人l别把寂寞当做缘分l如果你现在也是一个人l感谢你接受我添加邀请l都是陌生人不要拘谨l反正神马都是浮云l今夜我愿陪着你le\n",
      "validation pred : 我们我个人雨lll眼ll我们我个人些的里的爱光l我们我个人有人的ll人ll我们我个人么l天的人光l我们我个人的l的l人光l我空的亮我里个l我界的必间是不ll我是要我的扎的我实我的要我个人llll我以够们我人狂的我们要我一的爱ll我然我我的天l我实我的是我个人llll我寞\n",
      "validation label : s我是一个天真活泼的孩子l我是一个喜欢春天的孩子l我是一个爱笑的孩子l我是一个没有玩具的孩子l我是一个有理想的孩子l我是一个没有人疼的孩子l天会阴到哪一天l世界何时才会改变l只想努力挣钱l其实我不是一个文艺青年l可能我是个疯子l我不愿做你的棋子l虽然年过三十l其实我还是一个文艺青年l我是一个内心浮躁的孩子le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4002/100000000 [08:48<4069:24:47,  6.83it/s, acc : 0.233, val_acc : 0.219, loss : 0.233, val_loss : 0.219] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred : 你一l啦都不l了我是你法的乐ll信l你到后的束ll间llll膀我梭的梭你法ll你我西我ll待l我是爱中们有远l得ll你为你的否的心ll你是我春的你你的你你是我你l是你l你ll你生的界的在经不见ll你一惯的你我手lle是爱天lllll你能道福的否llll你待你一了爱间le你你的你我们道l你为你们有ll见l你llll我寞\n",
      "train label : s有一日咱若老l找无人甲咱有孝l我会陪你坐惦椅寮l听你讲少年的时阵你有外l吃好吃丑无计较l怨天怨地嘛袂晓l你的手我会甲你牵条条l因为你是我的家后l你将青春嫁置阮兜l你对少年跟阮跟甲老l人情世事已经看透透l有啥人比你卡重要l你的一生献乎阮兜l才知幸福是吵吵闹闹l等待返去的时阵若到l我会让你先走l因为我会呒甘放你为我目屎流l有一日咱若老le\n",
      "validation pred : 你你你泪的眼水ll我长的的的l来l子ll你爱的你的说你的泣l你方的我l然不阳ll我你你着的l你的福l你然是着我吹然不一我l你们你中中间的的我的我有你的爱子ll你们不多你惜l己l你有你们心月ll你的我护l的己l你是你的方l来ll你们不轻l方l己l你要你我一间见道你方l我们你的的有你我天l我是你我一的见道你方l我们你的的有你我天l我水\n",
      "validation label : s轻轻的我将离开你l请将眼角的泪拭去l漫漫长夜里未来日子里l亲爱的你别为我哭泣l前方的路虽然太凄迷l请在笑容里为我祝福l虽然迎著风虽然下著雨l我在风雨之中念著你l没有你的日子里l我会更加珍惜自己l没有我的岁月里l你要保重你自己l你问我何时归故里l我也轻声地问自己l不是在此时不知在何时l我想大约会是在冬季l不是在此时不知在何时l我想大约会是在冬季l轻轻的我将离开你le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4151/100000000 [09:08<4055:46:54,  6.85it/s, acc : 0.214, val_acc : 0.226, loss : 0.214, val_loss : 0.226]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cublas runtime error : the GPU program failed to execute at /home/k123/git/pytorch/aten/src/THC/THCBlas.cu:258",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ff27744140d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#                 loss = torch.sum(criterion(output, y) * pad_mask[:,1:, :])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/STML/hw3/task0/src/Seq2seq.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0men_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cublas runtime error : the GPU program failed to execute at /home/k123/git/pytorch/aten/src/THC/THCBlas.cu:258"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f<split>%s<split>%s<split>%s<split>%s\\n' % (n_iter, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label)\n",
    "    log_file_stream.write(log_text.encode('utf8'))\n",
    "    if n_iter % 10 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "def normal_acc(pred, label):\n",
    "    pred = torch.argmax(pred, dim=-1)\n",
    "    mask = torch.ones_like(label, dtype=torch.uint8)\n",
    "#     \n",
    "    acc = pred == label\n",
    "    acc = torch.sum(acc).item() / float(torch.sum(mask).item())\n",
    "    \n",
    "    return acc\n",
    "def seq2text(output, index_word):\n",
    "    assert len(output.shape) == 1\n",
    "    seq = output\n",
    "    s = ''\n",
    "    for i in seq:\n",
    "        i = int(i.item())\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i not in index_word:\n",
    "            w = oov_token\n",
    "        else:\n",
    "            w = index_word[i]\n",
    "        \n",
    "        s += w\n",
    "    return s\n",
    "    \n",
    "def rev_mask(m):\n",
    "    out = torch.ones_like(m, dtype=torch.uint8, requires_grad=False)\n",
    "    out.masked_fill_(m, 0)\n",
    "    return out\n",
    "        \n",
    "acc_q = deque(maxlen=100)\n",
    "loss_q = deque(maxlen=10)\n",
    "\n",
    "val_acc_q = deque(maxlen=100)\n",
    "val_loss_q = deque(maxlen=10)\n",
    "\n",
    "t = time.time()\n",
    "best_loss = float('inf')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "G = boostrap_generator(train_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "val_G = boostrap_generator(val_u_map, MAX_SEQ_LEN, tokenizer)\n",
    "# criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "weight = torch.ones([VOCAB_DIM+1,], dtype=torch.float)\n",
    "weight[tokenizer.word_index[line_token]] = 100.\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=weight.cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "print 'start training.'\n",
    "with open('log.txt', 'w') as f:\n",
    "    with open('best.txt', 'w') as best_log:\n",
    "        iters = 100000000\n",
    "        with tqdm(total=iters) as pbar:\n",
    "            for it in range(iters):\n",
    "                optimizer.zero_grad()\n",
    "                model.train()\n",
    "                q, k = next(G)\n",
    "                q = torch.LongTensor(q).cuda()\n",
    "                k = torch.LongTensor(k).cuda()\n",
    "\n",
    "                q.requires_grad_(False)\n",
    "                k.requires_grad_(False)\n",
    "\n",
    "\n",
    "                output = model(q, k)\n",
    "                y = q[:,1:]\n",
    "#                 loss = torch.sum(criterion(output, y) * pad_mask[:,1:, :]) \n",
    "                loss = criterion(output[:,:-1,:,].permute(0,2,1), y) \n",
    "                label = y\n",
    "\n",
    "                pred = output[:,:-1,:,]\n",
    "                acc = normal_acc(pred, label)\n",
    "                acc_q.append(acc)\n",
    "                train_pred = seq2text(torch.argmax(output[0,:,:], dim=-1), tokenizer.index_word)\n",
    "                train_label= seq2text(k[0,:], tokenizer.index_word)\n",
    "                loss.backward()\n",
    "                loss_q.append(loss.item())\n",
    "                \n",
    "                optimizer.step()\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    q, k = next(val_G)\n",
    "                    a = q\n",
    "                    b = k\n",
    "                    q = torch.LongTensor(q).cuda()\n",
    "                    k = torch.LongTensor(k).cuda()\n",
    "                    \n",
    "                    q.requires_grad_(False)\n",
    "                    k.requires_grad_(False)\n",
    "                    \n",
    "                    output = model(q, k)\n",
    "                    y = q[:,1:]\n",
    "                    val_loss = criterion(output[:,:-1,:,].permute(0,2,1), y) \n",
    "                    label = y\n",
    "\n",
    "                    pred = output[:,:-1,:,]\n",
    "                    val_acc = normal_acc(pred, label)\n",
    "                    val_acc_q.append(val_acc)\n",
    "                    val_pred = seq2text(torch.argmax(output[0,:,:], dim=-1), tokenizer.index_word)\n",
    "                    val_label= seq2text(k[0,:], tokenizer.index_word)\n",
    "                    val_loss_q.append(val_loss.item())\n",
    "\n",
    "\n",
    "                \n",
    "                acc = np.mean(acc_q)\n",
    "                val_acc = np.mean(val_acc_q)\n",
    "                loss = np.mean(acc_q)\n",
    "                val_loss = np.mean(val_acc_q)\n",
    "                \n",
    "#                     pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss : %.3f, val_loss : %.3f \\t %.3f, %.3f, %.3f, %.3f' % (acc, val_acc, loss.item(), val_loss.item(), a,b,c,d), refresh=False)\n",
    "                pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss : %.3f, val_loss : %.3f' % (acc, val_acc, loss.item(), val_loss.item()), refresh=False)\n",
    "                pbar.update(batch_size)\n",
    "                dump_log(model, (it+1)*batch_size, loss, val_loss, acc, val_acc, train_pred, train_label, val_pred, val_label, f,'./tmp.pt')\n",
    "                if val_loss.item() < best_loss and it > 100:\n",
    "                    torch.save(model, './best.pt')\n",
    "                    best_loss = val_loss\n",
    "                    best_log.write('%d\\t%.5f\\n' % ((it+1)*batch_size, best_loss))\n",
    "                    best_log.flush()\n",
    "                if it % 2000 == 0 and it >= 100: \n",
    "                    print 'train pred : %s\\ntrain label : %s' % (train_pred, train_label)\n",
    "                    print 'validation pred : %s\\nvalidation label : %s' % (val_pred, val_label)\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print q.shape, k.shape\n",
    "# print a\n",
    "# print b\n",
    "print a.shape\n",
    "print seq2text(a.flatten(), tokenizer.index_word)\n",
    "print seq2text(b.flatten(), tokenizer.index_word)\n",
    "m = model\n",
    "m = m.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
