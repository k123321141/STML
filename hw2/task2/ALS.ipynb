{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2681494/2681494 [00:22<00:00, 121423.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as  np\n",
    "from tqdm import tqdm\n",
    "np.random.seed(1337)\n",
    "with open('./kaggle/rating_train.csv', 'r') as f:\n",
    "    ls = f.readlines()[1:]\n",
    "u_map = {}\n",
    "\n",
    "dates = []\n",
    "foods = []\n",
    "users = []\n",
    "    \n",
    "\n",
    "with tqdm(total=len(ls)) as pbar:\n",
    "    for l in ls:\n",
    "        date_str, user, food = l.strip().split(',')\n",
    "        date = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        user, food = int(user), int(food)\n",
    "        if user not in u_map:\n",
    "            u_map[user] = []\n",
    "        u_map[user].append( (date, food) )\n",
    "        \n",
    "        dates.append(date)\n",
    "        foods.append(food)\n",
    "        users.append(user)\n",
    "        pbar.update(1)\n",
    "        \n",
    "\n",
    "        \n",
    "food_map = {f:i for i, f in enumerate(set(foods))}\n",
    "user_map = {u:i for i, u in enumerate(set(users))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2608/2608 [00:01<00:00, 1694.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 5532)\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### ALS embeddingimport numpy as  np\n",
    "from scipy.sparse import csr_matrix\n",
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "with tqdm(total=len(u_map)) as pbar:\n",
    "    \n",
    "#     split 1/10 for future\n",
    "    X = {}\n",
    "    X_len = {}\n",
    "    \n",
    "    pairs = []\n",
    "    for user,v in u_map.items():\n",
    "        history = v\n",
    "        x = np.zeros([1, MAX_SEQ_LEN, len(food_map)])\n",
    "        \n",
    "        ds = np.array([d for d,f in history])\n",
    "        fs = np.array([f for d,f in history])\n",
    "        sorted_idx = np.argsort(ds)\n",
    "        ds = ds[sorted_idx]\n",
    "        fd = fs[sorted_idx]\n",
    "\n",
    "        date_idx = 0\n",
    "        now_date = ds[0]\n",
    "        for food, date in zip(fs,ds):\n",
    "            if date != now_date:\n",
    "                date_idx+=1\n",
    "                now_date = date\n",
    "            key = (user, date_idx, food_map[food])\n",
    "            X[key] = 1\n",
    "            pair = (user_map[user], food_map[food])\n",
    "            pairs.append(pair)\n",
    "        \n",
    "        X_len[user] = date_idx\n",
    "        pbar.update(1)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    pairs = set(pairs)\n",
    "    for pair in pairs:\n",
    "        u, f = pair\n",
    "        rows.append(u)\n",
    "        cols.append(f)\n",
    "    data = np.ones([len(rows),])\n",
    "    R = csr_matrix((data, (rows,cols)), shape=(len(user_map),len(food_map)))\n",
    "print R.shape, len(X), len(X_len)\n",
    "print 'Done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "# initialize a model\n",
    "MODELS = {\"als\":  AlternatingLeastSquares,\n",
    "#           \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "#           \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "#           \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "#           \"tfidf\": TFIDFRecommender,\n",
    "#           \"cosine\": CosineRecommender,\n",
    "          \"bpr\": BayesianPersonalizedRanking,\n",
    "#           \"bm25\": BM25Recommender\n",
    "         }\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    print(\"getting model %s\" % model_name)\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': 128, 'dtype': np.float32, 'iterations':100}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 64, 'dtype': np.float32, 'iterations':100, 'verify_negative_samples':True}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == 'cosine':\n",
    "        params = {}\n",
    "    if model_name == 'faiss_als':\n",
    "        params['use_gpu'] = False\n",
    "    return model_class(**params)\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=256, use_gpu=True, iterations=1000)\n",
    "rev = {v:k for k,v in user_map.items()}\n",
    "\n",
    "# for s in MODELS:\n",
    "for f in [32*2**i for i in range(6)]:\n",
    "    for it in [10*(i+1) for i in range(10)]:\n",
    "#     model = get_model(s)\n",
    "    \n",
    "        model = MODELS.get('bpr')(use_gpu=True, factors=f, dtype=np.float32, iterations=it, verify_negative_samples=True)\n",
    "        user_items = R.transpose()\n",
    "        model.fit(user_items, show_progress=False)\n",
    "        hits = []\n",
    "        rec_count = 20\n",
    "        for idx in range(12,64):\n",
    "            user = rev[idx]\n",
    "            recommendations = model.recommend(idx, user_items, N=rec_count)\n",
    "            last_idx = X_len[user]\n",
    "            hit = [(user, last_idx, i) in X for i,_ in recommendations]\n",
    "            hits.append(np.mean(hit))\n",
    "            # hit = [arr[i]==1 and Y_map[rev[i]][0,i] == 1for i,_ in recommendations]\n",
    "        print f, it, s, np.mean(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from scipy.linalg import svd\n",
    "# \n",
    "# a,src_b,c = svd(R.todense()+0.001)\n",
    "a,src_b,c = svd(R.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 2608) (2608,) (5532, 5532)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "a,b,c = la.svd(R.todense())\n",
    "print a.shape, b.shape,c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 2608) (2608,) (5532, 5532)\n",
      "(2608, 5532)\n",
      "0.1839148773006135\n"
     ]
    }
   ],
   "source": [
    "d_s = 2608\n",
    "\n",
    "b = src_b\n",
    "print a.shape, b.shape,c.shape\n",
    "u = csr_matrix((b, (np.arange(b.shape[0]), np.arange(b.shape[0]))), shape=(a.shape[0],c.shape[0])).todense()\n",
    "p1 = np.matmul(a,u)\n",
    "p2 = np.matmul(p1,c)\n",
    "print p2.shape\n",
    "k = 20\n",
    "hits = []\n",
    "rev = {v:k for k,v in user_map.items()}\n",
    "for u in range(a.shape[0]):\n",
    "    arr = np.asarray(p2[u,:]).flatten()\n",
    "    rank_idx = [i for i in reversed(np.argsort(arr)[-k:])]\n",
    "    hit = [Y_map[rev[u]][0,i] != 0 for i in rank_idx]\n",
    "    hits.append(np.mean(hit))\n",
    "print np.mean(hits)\n",
    "# for u in range()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 2608) (2608,) (5532, 5532)\n",
      "(2608, 5532)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "d_s = 2608\n",
    "\n",
    "b = src_b\n",
    "print a.shape, b.shape,c.shape\n",
    "u = csr_matrix((b, (np.arange(b.shape[0]), np.arange(b.shape[0]))), shape=(a.shape[0],c.shape[0])).todense()\n",
    "p1 = np.matmul(a,u)\n",
    "p2 = np.matmul(p1,c)\n",
    "print p2.shape\n",
    "k = 20\n",
    "rev_food_map = {v:k for k,v in food_map.items()}\n",
    "rev = {v:k for k,v in user_map.items()}\n",
    "with open('./SVD_predict.csv', 'w') as f:\n",
    "    f.write('userid,foodid\\n')\n",
    "    for u in range(a.shape[0]):\n",
    "        arr = np.asarray(p2[u,:]).flatten()\n",
    "        rank_idx = [i for i in reversed(np.argsort(arr)[-k:])]\n",
    "        s = ''\n",
    "        for food_idx in rank_idx:\n",
    "            s += ' %d' % rev_food_map[food_idx]\n",
    "        user = rev[u]\n",
    "        f.write('%d,%s\\n' % (user,s) )\n",
    "print 'Done'\n",
    "# for u in range()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:00<00:09, 29.76it/s, skipped=22.04%, correct=57.86%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model bpr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:08<00:00, 35.40it/s, skipped=22.17%, correct=99.36%]\n",
      " 14%|█▍        | 14.0/100 [00:00<00:00, 137.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpr 0.0\n",
      "getting model als\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100.0/100 [00:00<00:00, 126.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als 0.0\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "# initialize a model\n",
    "MODELS = {\"als\":  AlternatingLeastSquares,\n",
    "#           \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "#           \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "#           \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "#           \"tfidf\": TFIDFRecommender,\n",
    "#           \"cosine\": CosineRecommender,\n",
    "          \"bpr\": BayesianPersonalizedRanking,\n",
    "#           \"bm25\": BM25Recommender\n",
    "         }\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    print(\"getting model %s\" % model_name)\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': 64, 'dtype': np.float32, 'iterations':100}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 512, 'dtype': np.float32, 'iterations':300, 'verify_negative_samples':True}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    if model_name == 'faiss_als':\n",
    "        params['use_gpu'] = False\n",
    "    return model_class(**params)\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=256, use_gpu=True, iterations=1000)\n",
    "rev = {v:k for k,v in user_map.items()}\n",
    "\n",
    "for s in MODELS:\n",
    "    model = get_model(s)\n",
    "    user_items = R.transpose()\n",
    "    model.fit(user_items, show_progress=True)\n",
    "    hits = []\n",
    "    kkk=20\n",
    "    for idx in range(12,64):\n",
    "        recommendations = model.recommend(idx, user_items, N=kkk)\n",
    "        hit = [Y_map[rev[idx]][0,i] != 0 for i,_ in recommendations]\n",
    "        hits.append(np.mean(hit))\n",
    "        # hit = [arr[i]==1 and Y_map[rev[i]][0,i] == 1for i,_ in recommendations]\n",
    "    print s, np.mean(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.49it/s, skipped=22.07%, correct=89.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als 0.0\n"
     ]
    }
   ],
   "source": [
    "model = BayesianPersonalizedRanking(factors=512, use_gpu=True, iterations=100, verify_negative_samples=True)\n",
    "model.fit(user_items, show_progress=True)\n",
    "hits = []\n",
    "kkk=20\n",
    "for idx in user_map.values():\n",
    "    recommendations = model.recommend(idx, user_items, N=kkk)\n",
    "    hit = [Y_map[rev[idx]][0,i] != 0 for i,_ in recommendations]\n",
    "    hits.append(np.mean(hit))\n",
    "    # hit = [arr[i]==1 and Y_map[rev[i]][0,i] == 1for i,_ in recommendations]\n",
    "print s, np.mean(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, False, True, True, True, False, False, False, True, False, False, False, False, True, False, True, True, False] 0.45\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000.0/1000 [00:18<00:00, 53.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 256)\n",
      "(2608, 5532)\n",
      "(5532, 2608)\n",
      "[(168, 1.3599495), (105, 1.3211579), (309, 1.2180662), (530, 1.207345), (86, 1.1754689), (839, 1.1561897), (185, 1.1467923), (272, 1.1443896), (369, 1.141603), (102, 1.1302487), (529, 1.1113687), (213, 1.1074361), (232, 1.1065829), (125, 1.0634801), (42, 1.0571473), (34, 1.0482899), (442, 1.0473948), (166, 1.0442796), (1, 1.0230695), (224, 1.016206)]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True] 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=256, regularization=0.0001, use_gpu=True, iterations=1000)\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=16, use_gpu=False)\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "user_items = R.transpose()\n",
    "model.fit(user_items)\n",
    "print model.user_factors.shape\n",
    "print R.shape\n",
    "\n",
    "idx = 12\n",
    "kkk=20\n",
    "print user_items.shape\n",
    "recommendations = model.recommend(idx, user_items, N=kkk)\n",
    "print recommendations\n",
    "\n",
    "# exp = model.explain(idx, user_items, recommendations[0][0], user_weights=None, N=10)\n",
    "# print exp\n",
    "\n",
    "arr = np.asarray(R[idx,:].todense()).flatten()\n",
    "hit = [arr[i]==1 for i,_ in recommendations]\n",
    "print hit, np.mean(hit)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from scipy.linalg import svd\n",
    "\n",
    "a,b,c = svd(R.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 2608) (2608,) (5532, 5532)\n",
      "[ 10.64648245  10.65367948  10.66624767  10.67021413  10.67334045\n",
      "  10.68360938  10.68639945  10.70094656  10.70857433  10.7131845\n",
      "  10.71967545  10.7240006   10.7305354   10.74214919  10.74734611\n",
      "  10.75218476  10.76177446  10.76757014  10.77296421  10.77622253\n",
      "  10.78342728  10.79419318  10.79868604  10.80705244  10.81995604\n",
      "  10.82511747  10.83511752  10.84442115  10.85269664  10.86183542\n",
      "  10.86247807  10.86922979  10.87368852  10.88398512  10.89248233\n",
      "  10.89639047  10.90650091  10.91871078  10.92334268  10.93945871\n",
      "  10.94431328  10.9615918   10.96273193  10.97498591  10.98638158\n",
      "  10.99363707  10.99600286  11.00331262  11.01178987  11.01769174\n",
      "  11.0184026   11.0251905   11.03329023  11.04112607  11.04868927\n",
      "  11.0647313   11.07478709  11.07755246  11.09114625  11.09553927\n",
      "  11.10346267  11.10827575  11.11706384  11.11965244  11.14115998\n",
      "  11.14583848  11.15123093  11.16325272  11.16999321  11.1793486\n",
      "  11.18103032  11.18895846  11.19127406  11.19841508  11.20901949\n",
      "  11.21337342  11.22985916  11.23644213  11.23995192  11.24974872\n",
      "  11.2585772   11.26245709  11.27371102  11.27634858  11.2839192\n",
      "  11.29677232  11.30465695  11.30917495  11.32059274  11.33378558\n",
      "  11.33965798  11.34580756  11.34994841  11.35900781  11.36823132\n",
      "  11.37223027  11.38305033  11.38555377  11.39975178  11.42239285\n",
      "  11.42327413  11.42940167  11.43387985  11.44419247  11.45384114\n",
      "  11.46322948  11.4736764   11.4785944   11.48983629  11.49505323\n",
      "  11.50631173  11.51981877  11.52992068  11.53768787  11.54366148\n",
      "  11.54968499  11.56001094  11.57222651  11.57697877  11.58483552\n",
      "  11.59192389  11.59638634  11.60845217  11.62557527  11.62885768\n",
      "  11.63952017  11.64676885  11.65077888  11.66158067  11.67246932\n",
      "  11.68178359  11.69023569  11.70600875  11.71271839  11.72498832\n",
      "  11.72977536  11.73289795  11.74686731  11.74987797  11.76209868\n",
      "  11.76391683  11.77405162  11.78108804  11.78306747  11.79121801\n",
      "  11.80719349  11.81303032  11.81617397  11.82881353  11.83741675\n",
      "  11.8458693   11.85269403  11.86420348  11.86524155  11.87888194\n",
      "  11.88419616  11.88875343  11.89632014  11.91485163  11.92363584\n",
      "  11.93959456  11.94646566  11.95522094  11.96118572  11.96910294\n",
      "  11.9777257   11.98194674  11.98549456  11.98972792  12.00473586\n",
      "  12.017544    12.02808109  12.03459424  12.04451864  12.0541656\n",
      "  12.06570504  12.0670345   12.08038402  12.08841726  12.0993302\n",
      "  12.1028544   12.12169845  12.12737519  12.13783194  12.1450516\n",
      "  12.14927377  12.160096    12.16930866  12.17743295  12.18629873\n",
      "  12.20168471  12.20509964  12.21869708  12.22956125  12.23529176\n",
      "  12.24348027  12.25690645  12.26483608  12.26867168  12.27708659\n",
      "  12.30367421  12.30599691  12.31436618  12.32268971  12.32786884\n",
      "  12.33833074  12.34382057  12.35150429  12.35688413  12.36069938\n",
      "  12.38467782  12.39084573  12.39858945  12.4078617   12.4220529\n",
      "  12.42695714  12.43931598  12.44765612  12.45498918  12.47228054\n",
      "  12.47664368  12.48300447  12.49259139  12.50172217  12.51404375\n",
      "  12.51654313  12.52773309  12.53304683  12.53942596  12.5554361\n",
      "  12.56508434  12.57753911  12.59099179  12.60018919  12.60846248\n",
      "  12.61583386  12.62628091  12.63573083  12.64375807  12.64977496\n",
      "  12.65902817  12.67077124  12.67746474  12.69213371  12.6959153\n",
      "  12.71884024  12.72698141  12.73747846  12.75161658  12.75399293\n",
      "  12.76404437  12.77051545  12.77683763  12.78313159  12.79986563\n",
      "  12.81725304  12.82229115  12.82705873  12.83210898  12.83712038\n",
      "  12.84449915  12.85340298  12.87179198  12.88743823  12.8950201\n",
      "  12.90314467  12.92124805  12.92529904  12.93795501  12.95164757\n",
      "  12.95721972  12.96154299  12.96784629  12.98162394  12.98553533\n",
      "  12.99902471  13.00316479  13.01123296  13.03641141  13.04456921\n",
      "  13.0466726   13.06995044  13.08070463  13.08776211  13.09524372\n",
      "  13.10832892  13.11175126  13.12237722  13.13347819  13.14587414\n",
      "  13.15500985  13.16325234  13.17631118  13.18696881  13.19727979\n",
      "  13.20076186  13.2205296   13.22433221  13.23511665  13.24103137\n",
      "  13.24790542  13.25718612  13.2693358   13.27958682  13.28856456\n",
      "  13.30684296  13.31494944  13.32800061  13.3315763   13.34235408\n",
      "  13.35925132  13.36898995  13.37690134  13.38473213  13.39606071\n",
      "  13.41791192  13.42425429  13.43482604  13.44686049  13.45903145\n",
      "  13.4645948   13.48462688  13.49431136  13.50038578  13.50655695\n",
      "  13.51449869  13.52870115  13.53490485  13.56245319  13.57747466\n",
      "  13.59045565  13.59512861  13.59735512  13.6176723   13.62698535\n",
      "  13.63500173  13.6503207   13.6580284   13.67785542  13.68594608\n",
      "  13.69493749  13.70507247  13.70796774  13.7191827   13.73484865\n",
      "  13.74991844  13.75169293  13.774138    13.77836417  13.79029849\n",
      "  13.81092403  13.81589064  13.83289511  13.8352689   13.85272778\n",
      "  13.86019902  13.86662239  13.8717242   13.88373541  13.89858149\n",
      "  13.90378954  13.91614169  13.92627276  13.9422473   13.94486019\n",
      "  13.95848527  13.97817288  13.99383699  13.99984205  14.02041459\n",
      "  14.03174823  14.0442313   14.05894187  14.06550475  14.08672293\n",
      "  14.10081272  14.10872696  14.12163365  14.12355333  14.13006\n",
      "  14.1442201   14.16736176  14.17230385  14.17518674  14.1959145\n",
      "  14.20600886  14.21261256  14.22204389  14.23807557  14.24050817\n",
      "  14.25639347  14.28074327  14.28841945  14.29233425  14.30516508\n",
      "  14.31956456  14.33912498  14.34021081  14.34873507  14.35944203\n",
      "  14.37550089  14.39308813  14.40332924  14.42170948  14.42435723\n",
      "  14.44910587  14.45542328  14.46461811  14.47581763  14.48492543\n",
      "  14.50251426  14.51834853  14.53106893  14.55639776  14.5779205\n",
      "  14.58662898  14.59314384  14.60832057  14.62142535  14.62233369\n",
      "  14.63999888  14.64803429  14.6605355   14.66784612  14.68518935\n",
      "  14.69216129  14.69772662  14.70736911  14.71805835  14.73668242\n",
      "  14.75238391  14.75727521  14.77112818  14.78538713  14.79271731\n",
      "  14.83057398  14.84106164  14.84899979  14.85780209  14.87643937\n",
      "  14.87984456  14.89397616  14.90615713  14.91455919  14.93894311\n",
      "  14.95296153  14.96006622  14.97318209  14.99397646  14.99977895\n",
      "  15.02070757  15.03042242  15.03919154  15.04910463  15.06096667\n",
      "  15.08772715  15.09951037  15.11634438  15.11746732  15.13614044\n",
      "  15.14533367  15.17184338  15.18132457  15.20120472  15.2094699\n",
      "  15.23898927  15.25784064  15.25999504  15.26691201  15.27734934\n",
      "  15.29329994  15.31053338  15.31947252  15.32703144  15.33185908\n",
      "  15.3554554   15.37343801  15.40000557  15.4075559   15.411243\n",
      "  15.42445229  15.43341839  15.44836264  15.4618375   15.4844976\n",
      "  15.49005346  15.4970031   15.52173466  15.52997112  15.54101774\n",
      "  15.55267735  15.56378523  15.57395515  15.5895499   15.61289967\n",
      "  15.62197084  15.6331043   15.65053741  15.67990732  15.69831426\n",
      "  15.71827844  15.72910527  15.73256498  15.73677443  15.74692003\n",
      "  15.7648395   15.77704018  15.80578712  15.81274513  15.82693038\n",
      "  15.84424256  15.85595949  15.87106172  15.88797255  15.90116119\n",
      "  15.91565468  15.93329112  15.94122527  15.95128335  15.97882428\n",
      "  15.99404173  16.00824624  16.02259431  16.03375704  16.03952207\n",
      "  16.04871852  16.06682849  16.07337435  16.09663689  16.12370824\n",
      "  16.13648303  16.15384265  16.16728258  16.17198065  16.18704621\n",
      "  16.21689871  16.22853423  16.24443501  16.25130085  16.27891423\n",
      "  16.28710186  16.30670774  16.32929402  16.34794348  16.35463819\n",
      "  16.36378767  16.37934973  16.39759883  16.41036606  16.43400611\n",
      "  16.44803555  16.45260996  16.46592604  16.47182633  16.48023146\n",
      "  16.51426729  16.53925556  16.56242376  16.57116243  16.59517026\n",
      "  16.60154998  16.62888186  16.63638254  16.65278869  16.66964535\n",
      "  16.68042089  16.69675431  16.7020046   16.73654857  16.74833604\n",
      "  16.7561496   16.76798886  16.80800432  16.81786475  16.83780573\n",
      "  16.84276355  16.87717273  16.88825278  16.89227104  16.90592528\n",
      "  16.91402998  16.94977414  16.96845735  16.98025834  17.00316733\n",
      "  17.00957877  17.02433001  17.0432336   17.05681787  17.07209986\n",
      "  17.07960326  17.11207896  17.12216517  17.15398033  17.16935576\n",
      "  17.17150792  17.1940779   17.21573967  17.22577131  17.24647743\n",
      "  17.25614379  17.30018834  17.31230227  17.31682455  17.3271733\n",
      "  17.34120925  17.35985529  17.37992971  17.40014039  17.41406055\n",
      "  17.42696858  17.44570865  17.47675282  17.49199819  17.51468909\n",
      "  17.54582946  17.56241702  17.57437204  17.58963347  17.59608014\n",
      "  17.63982649  17.64204772  17.65226155  17.66805418  17.70973788\n",
      "  17.72947587  17.75654567  17.76206741  17.78893521  17.8106283\n",
      "  17.83709108  17.84795375  17.87849614  17.89494936  17.90551788\n",
      "  17.92052437  17.9475131   17.94934411  17.97104456  17.99531741\n",
      "  18.01285916  18.04844313  18.05906532  18.07620258  18.08200023\n",
      "  18.10185275  18.12904106  18.14372729  18.1592908   18.17992119\n",
      "  18.1921881   18.21332177  18.21569407  18.24366026  18.25344035\n",
      "  18.28657121  18.3012934   18.33089977  18.36446689  18.37261831\n",
      "  18.37904383  18.40509689  18.44320433  18.46538636  18.48225474\n",
      "  18.49546995  18.50906962  18.52434365  18.54787818  18.57035083\n",
      "  18.58848283  18.6061501   18.62263621  18.6633775   18.67325206\n",
      "  18.6872225   18.69420001  18.72379556  18.75669315  18.75954281\n",
      "  18.77732665  18.80655952  18.82191724  18.85633401  18.86970653\n",
      "  18.87572907  18.89515167  18.92940057  18.93887244  18.96034688\n",
      "  18.99320736  19.01327785  19.02242825  19.06170881  19.06403513\n",
      "  19.10411992  19.12000823  19.15179795  19.17976675  19.18866007\n",
      "  19.21417623  19.23344745  19.25848521  19.29197178  19.30598106\n",
      "  19.31380199  19.33199641  19.35952987  19.41314761  19.42583446\n",
      "  19.43358382  19.4579265   19.5123216   19.54802909  19.56542216\n",
      "  19.57890064  19.59902875  19.61940957  19.62702189  19.64848252\n",
      "  19.68140869  19.68749541  19.69949312  19.72107905  19.7575112\n",
      "  19.76808963  19.80043208  19.83143397  19.85267808  19.86477241\n",
      "  19.87945416  19.93580473  19.94437751  19.96217636  20.02315315\n",
      "  20.04223124  20.04756291  20.08407002  20.10126137  20.13334124\n",
      "  20.15456302  20.1697737   20.19671893  20.20385498  20.22551428\n",
      "  20.26694147  20.28544424  20.30361983  20.33469543  20.35792311\n",
      "  20.38535564  20.41232442  20.45929689  20.4910943   20.51123828\n",
      "  20.51803386  20.55093536  20.57884918  20.60740572  20.63639739\n",
      "  20.6436621   20.69192926  20.72624528  20.74415233  20.76076188\n",
      "  20.77689445  20.80079197  20.84379927  20.85869474  20.89077578\n",
      "  20.92962489  20.94845893  20.97136742  20.9968295   21.03238339\n",
      "  21.04853893  21.06249907  21.08898729  21.12972469  21.18571338\n",
      "  21.21138255  21.25616684  21.26284319  21.28748727  21.30118068\n",
      "  21.33896788  21.34698781  21.38702724  21.41700971  21.43616186\n",
      "  21.49055739  21.50119237  21.52806214  21.55944935  21.5820122\n",
      "  21.60807265  21.6505359   21.68563857  21.72896566  21.74231425\n",
      "  21.75163983  21.78636333  21.81323826  21.83400234  21.86435039\n",
      "  21.89004771  21.92509062  21.97945406  22.01927357  22.03038688\n",
      "  22.03438943  22.09859751  22.11381458  22.16396438  22.18533849\n",
      "  22.21195001  22.243643    22.32595284  22.34895745  22.3636742\n",
      "  22.42801375  22.44227187  22.46652387  22.47753945  22.49574029\n",
      "  22.52212219  22.55989624  22.59279077  22.6245477   22.70030204\n",
      "  22.72675933  22.74055424  22.78028965  22.79944261  22.82267962\n",
      "  22.86417971  22.89341817  22.93138109  22.95406407  22.96817972\n",
      "  23.01958074  23.05496382  23.08575828  23.1074386   23.14233168\n",
      "  23.18484419  23.22399857  23.24097902  23.31164995  23.35761225\n",
      "  23.38884585  23.40634648  23.42454307  23.45646842  23.52105222\n",
      "  23.54603289  23.5546685   23.64642421  23.66799202  23.72368619\n",
      "  23.77353432  23.79036518  23.85908342  23.86112478  23.90921194\n",
      "  23.94148736  23.94843707  24.01207985  24.02274711  24.09540606\n",
      "  24.10936726  24.16525283  24.2265482   24.26326646  24.28866619\n",
      "  24.31451424  24.37233551  24.40399859  24.46351207  24.48779218\n",
      "  24.5535617   24.58247713  24.60723226  24.62464866  24.64657943\n",
      "  24.68536173  24.70771639  24.78943669  24.8137029   24.85619875\n",
      "  24.89064842  24.93332134  24.98672174  25.0290323   25.0595384\n",
      "  25.12007193  25.16674534  25.17759618  25.22481851  25.2723239\n",
      "  25.35329585  25.38490079  25.45868645  25.48248115  25.52013733\n",
      "  25.60278108  25.63855921  25.6470919   25.71739807  25.74936895\n",
      "  25.8079291   25.84951898  25.87046868  25.89224421  25.97955424\n",
      "  26.0655453   26.09431502  26.12723836  26.17624534  26.23014317\n",
      "  26.29429724  26.39686977  26.43484953  26.46784159  26.53857972\n",
      "  26.59977085  26.66159634  26.72889151  26.74133157  26.77428728\n",
      "  26.78992323  26.86933692  26.9169861   27.0004063   27.11055322\n",
      "  27.13048207  27.22124113  27.2456617   27.28722539  27.36492522\n",
      "  27.39606629  27.47295748  27.5042886   27.56057123  27.63924487\n",
      "  27.75997436  27.81394233  27.85361496  27.90184462  28.02461954\n",
      "  28.02853886  28.11438246  28.170852    28.23399832  28.32420957\n",
      "  28.4329769   28.57451332  28.60249692  28.6946803   28.73099382\n",
      "  28.8855608   28.97868009  29.03726331  29.09492252  29.24703143\n",
      "  29.4158671   29.44108827  29.65804664  29.74091898  29.81526051\n",
      "  29.94991285  30.13318743  30.3728997   30.48768522  30.69963764\n",
      "  30.89914753  31.12188449  31.19595107  31.80016076  32.04735945\n",
      "  32.11218027  32.35740411  32.63641952  33.19950943  33.73271109\n",
      "  34.331374    34.57155883  35.75192051  35.84591646  36.9613222\n",
      "  38.77220784  39.4940577   41.0840719   43.09088543  45.69211815\n",
      "  48.36384916  53.35912725  66.95325457  80.47335994 338.90389992]\n"
     ]
    }
   ],
   "source": [
    "print a.shape, b.shape,c.shape\n",
    "print np.sort(b)[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.FloatTensor([0,0,1,1,0,0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2608/2608 [00:09<00:00, 282.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# user_items = item_user_data.T.tocsr()\n",
    "kkk = 20\n",
    "rev_food_map = {v:k for k,v in food_map.items()}\n",
    "with open('./ALS_predict.csv', 'w') as f:\n",
    "    \n",
    "    f.write('userid,foodid\\n')\n",
    "    with tqdm(total=len(u_map)) as pbar:\n",
    "        for user, i in user_map.items():\n",
    "            recommendations = model.recommend(i, user_items, N=kkk)\n",
    "            s = ''\n",
    "            for food_idx, value in recommendations:\n",
    "                s += ' %d' % rev_food_map[food_idx]\n",
    "            f.write('%d,%s\\n' % (user,s) )\n",
    "            pbar.update(1)\n",
    "print 'Done'\n",
    "print len(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(5532, 2608)\n",
      "[(39, 1.0589447), (139, 1.0535698), (18, 1.0461819), (34, 1.0157015), (107, 0.9683679), (168, 0.96572435), (41, 0.9407524), (125, 0.9335048), (839, 0.92211986), (224, 0.9000232), (25, 0.89088106), (88, 0.8828891), (117, 0.83348477), (80, 0.82915735), (763, 0.8249409), (81, 0.8217071), (102, 0.8114673), (105, 0.7993405), (42, 0.7891038), (69, 0.7713862)]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True] 0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print len(recommendations)\n",
    "idx = 12\n",
    "print user_items.shape\n",
    "recommendations = model.recommend(idx, user_items, N=kkk)\n",
    "print recommendations\n",
    "\n",
    "exp = model.explain(idx, user_items, recommendations[0][0], user_weights=None, N=10)\n",
    "# print exp\n",
    "\n",
    "arr = np.asarray(R[idx,:].todense()).flatten()\n",
    "hit = [arr[i]==1 for i,_ in recommendations]\n",
    "print hit, np.mean(hit)\n",
    "    \n",
    "# print [(i,arr[i]) for i in reversed(np.argsort(arr)[-kkk:])]\n",
    "\n",
    "# # find related items\n",
    "# a = model.user_factors\n",
    "# b = model.item_factors\n",
    "# c = np.matmul(a,b.transpose())\n",
    "# arr = np.asarray(c[idx,:]).flatten()\n",
    "# print [(i,arr[i]) for i in reversed(np.argsort(arr)[-kkk:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5532, 256)\n",
      "(2608, 5532)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print model.user_factors.shape\n",
    "# print np.matmul(model.user_factors, model.item_factors.transpose()).shape\n",
    "print R.shape\n",
    "# for user, i in user_map.items():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare sample generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 165, 5532) (32, 1) (32, 1)\n",
      "(16, 165, 5532) (16, 1) (16, 1)\n",
      "(165, 5532) (1,) (1,)\n"
     ]
    }
   ],
   "source": [
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "val_num = len(pseudo_history_map) // 10\n",
    "idx = np.random.permutation(len(pseudo_history_map))\n",
    "train_idx, val_idx = idx[val_num:], idx[:val_num]\n",
    "train_u_map = {k:pseudo_history_map[k] for k in pseudo_history_map.keys()[val_num:]}\n",
    "val_u_map = {k:pseudo_history_map[k] for k in pseudo_history_map.keys()[:val_num]}\n",
    "def batch_boostrap_generator(batch_size, u_map, food_map, Y_map, max_history_len, flip):\n",
    "    G = boostrap_generator(u_map, food_map, Y_map, max_history_len, flip)\n",
    "    while True:\n",
    "        X = []\n",
    "        pos_Y = []\n",
    "        neg_Y = []\n",
    "        for i in range(batch_size):\n",
    "            x, pos_y, neg_y = next(G)\n",
    "            x = np.pad(x, ((0,max_history_len-x.shape[0]),(0,0)), 'constant', constant_values=0)\n",
    "            X.append(np.expand_dims(x, axis=0))\n",
    "            pos_Y.append(np.expand_dims(pos_y, axis=0))\n",
    "            neg_Y.append(np.expand_dims(neg_y, axis=0))\n",
    "        yield np.vstack(X), np.vstack(pos_Y), np.vstack(neg_Y) \n",
    "def boostrap_generator(u_map, food_map, Y_map, max_history_len, flip):\n",
    "    while True:\n",
    "        keys = u_map.keys()\n",
    "        for user_idx in np.random.permutation(len(u_map)):\n",
    "            user = keys[user_idx]\n",
    "            X = np.zeros([max_history_len, len(food_map)])\n",
    "            Y = Y_map[user].flatten()\n",
    "            history = u_map[user]\n",
    "            ds = np.array([d for d,f in history])\n",
    "            fs = np.array([f for d,f in history])\n",
    "            sorted_idx = np.flip(np.argsort(ds), axis=-1) if flip else np.argsort(ds)\n",
    "            ds = ds[sorted_idx]\n",
    "            fd = fs[sorted_idx]\n",
    "            \n",
    "            date_idx = 0\n",
    "            now_date = ds[0]\n",
    "            for food, date in zip(fs,ds):\n",
    "                if date != now_date:\n",
    "                    date_idx+=1\n",
    "                    now_date = date\n",
    "                X[date_idx, food_map[food]] = 1\n",
    "            \n",
    "    #         positive sample\n",
    "            idx = np.random.permutation(len(Y))\n",
    "            pos_i = neg_i = -1\n",
    "            for i in idx:\n",
    "                if Y[i] == 1 and pos_i == -1:\n",
    "                    pos_i = i\n",
    "                if Y[i] == 0 and neg_i == -1:\n",
    "                    neg_i = i\n",
    "                if pos_i != -1 and neg_i != -1:\n",
    "                    break\n",
    "            yield X, np.array([pos_i]), np.array([neg_i])\n",
    "            \n",
    "    \n",
    "\n",
    "G = batch_boostrap_generator(32, train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "val_G = batch_boostrap_generator(32//2, val_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "\n",
    "x, pos_y, neg_y = next(G)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n",
    "x, pos_y, neg_y = next(val_G)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n",
    "\n",
    "G2 = boostrap_generator(train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "x, pos_y, neg_y = next(G2)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([3,2,1,4])\n",
    "b = np.flip(a, axis=-1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/14427456 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 320/14427456 [00:07<88:27:13, 45.31it/s, acc : 0.528, val_acc : 0.525, 0.578, 0.529, 0.42413, 0.50843] /home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.15/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Food_embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  3%|▎         | 372992/14427456 [1:44:16<60:10:55, 64.87it/s, acc : 0.739, val_acc : 0.750, 0.945, 0.603, 0.74552, 0.55210]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  7%|▋         | 954240/14427456 [4:14:01<57:57:35, 64.57it/s, acc : 0.790, val_acc : 0.794, 0.973, 0.270, 0.21521, 0.35542]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  8%|▊         | 1145024/14427456 [5:03:57<56:45:23, 65.01it/s, acc : 0.797, val_acc : 0.795, 0.243, 0.271, 0.95806, 0.24254]"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, acc, val_loss, val_acc, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f\\n' % (n_iter, loss, acc, val_loss, val_acc)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 10 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "        \n",
    "acc_q = deque(maxlen=1000)\n",
    "loss_q = deque(maxlen=1000)\n",
    "val_acc_q = deque(maxlen=1000)\n",
    "val_loss_q = deque(maxlen=1000)\n",
    "t = time.time()\n",
    "best_acc  = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "G = batch_boostrap_generator(batch_size, train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=False)\n",
    "val_G = batch_boostrap_generator(batch_size, val_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=False)\n",
    "\n",
    "print 'start training.'\n",
    "with open('log.txt', 'a') as f:\n",
    "    with open('best.txt', 'w') as best_log:\n",
    "        for e in range(epochs):\n",
    "            iters = len(food_map) * len(user_map)\n",
    "            with tqdm(total=iters) as pbar:\n",
    "                for it in range(iters):\n",
    "                    optimizer.zero_grad()\n",
    "                    model.train()\n",
    "                    x, pos_y, neg_y = next(G)\n",
    "    #                 print 'x1', np.sum(x[0,:])\n",
    "                    x = torch.FloatTensor(x).cuda()\n",
    "                    pos_y,neg_y = torch.LongTensor(pos_y), torch.LongTensor(neg_y)\n",
    "\n",
    "    #                 positive\n",
    "                    output = model(pos_y.cuda(), x)\n",
    "                    a = output[0,0].item()\n",
    "                    pred = output > 0.5\n",
    "                    label = torch.ones_like(output).cuda()\n",
    "                    pos_loss = criterion(output, label)\n",
    "\n",
    "                    acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                    acc_q.append(acc)\n",
    "    #                 pos_loss.backward()\n",
    "\n",
    "    #                 negative\n",
    "                    output = model(neg_y.cuda(), x)\n",
    "                    b = output[0,0].item()\n",
    "                    pred = output > 0.5\n",
    "                    label = torch.zeros_like(output).cuda()\n",
    "                    neg_loss = criterion(output, label )\n",
    "                    acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                    acc_q.append(acc)\n",
    "    #                 neg_loss.backward()\n",
    "\n",
    "                    loss = pos_loss + neg_loss\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    with torch.no_grad():\n",
    "                        model.eval()\n",
    "    #                 positive\n",
    "                        x, pos_y, neg_y = next(val_G)\n",
    "    #                     print 'x2', np.sum(x[0,:])\n",
    "                        x = torch.FloatTensor(x).cuda()\n",
    "                        pos_y,neg_y = torch.LongTensor(pos_y), torch.LongTensor(neg_y)\n",
    "    #                       \n",
    "                        output = model(pos_y.cuda(), x)\n",
    "    #                     o1 = model.transformer.decoder.mid\n",
    "    #                     o1 = model.mid\n",
    "\n",
    "                        c = output[0,0].item()\n",
    "                        pred = output > 0.5\n",
    "                        label = torch.ones_like(output).cuda()\n",
    "\n",
    "                        pos_loss = criterion(output, label )\n",
    "\n",
    "                        val_acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                        val_acc_q.append(val_acc)\n",
    "    #                 negative\n",
    "    #                     print pos_y, neg_y\n",
    "    #                     print output\n",
    "\n",
    "                        output = model(neg_y.cuda(), x)\n",
    "    #                     o2 = model.mid\n",
    "    #                     print o2.shape\n",
    "    #                     print neg_y.cuda().shape\n",
    "    #                     print neg_y.cuda()[0,0]\n",
    "    #                     print (o1 == o2).all()\n",
    "                        d = output[0,0].item()\n",
    "    #                     print c == d\n",
    "    #                     wf\n",
    "    #                     print pos_y == neg_y\n",
    "    #                     print output\n",
    "\n",
    "\n",
    "                        pred = output > 0.5\n",
    "                        label = torch.zeros_like(output).cuda()\n",
    "\n",
    "                        neg_loss = criterion(output, label )\n",
    "                        val_acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                        val_acc_q.append(val_acc)\n",
    "\n",
    "                        val_loss = pos_loss + neg_loss\n",
    "                    acc = np.mean(acc_q)\n",
    "                    val_acc = np.mean(val_acc_q)\n",
    "\n",
    "    #                 dump_log(model, it+1, loss, acc, val_loss, val_acc, f, './tmp.pt')\n",
    "\n",
    "    #                 pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, %.3f, %.3f, %.3f' % (acc, val_acc,a,b,c), refresh=False)\n",
    "                    pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, %.3f, %.3f, %.5f, %.5f' % (acc, val_acc,a,b,c,d), refresh=False)\n",
    "                    pbar.update(batch_size)\n",
    "                    dump_log(model, (it+1)*batch_size, loss, acc, val_loss, val_acc, f, './tmp.pt')\n",
    "                    if val_acc > best_acc and it > 100:\n",
    "                        torch.save(model, './best.pt')\n",
    "                        best_acc = val_acc\n",
    "                        best_log.write('%d\\t%.5f\\n' % ((it+1)*batch_size, best_acc))\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
