{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2681494/2681494 [00:20<00:00, 133456.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as  np\n",
    "from tqdm import tqdm\n",
    "np.random.seed(1337)\n",
    "with open('./kaggle/rating_train.csv', 'r') as f:\n",
    "    ls = f.readlines()[1:]\n",
    "u_map = {}\n",
    "\n",
    "dates = []\n",
    "foods = []\n",
    "users = []\n",
    "    \n",
    "\n",
    "with tqdm(total=len(ls)) as pbar:\n",
    "    for l in ls:\n",
    "        date_str, user, food = l.strip().split(',')\n",
    "        date = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        user, food = int(user), int(food)\n",
    "        if user not in u_map:\n",
    "            u_map[user] = []\n",
    "        u_map[user].append( (date, food) )\n",
    "        \n",
    "        dates.append(date)\n",
    "        foods.append(food)\n",
    "        users.append(user)\n",
    "        pbar.update(1)\n",
    "        \n",
    "\n",
    "        \n",
    "food_map = {f:i for i, f in enumerate(set(foods))}\n",
    "user_map = {u:i for i, u in enumerate(set(users))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 23 95.21165644171779 34.48409857182605\n",
      "5569 194 1028.1802147239264 599.6642539977294\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "for k,v in u_map.items():\n",
    "    ds = [d for d,f in v]\n",
    "    \n",
    "    set_ds = set(ds)\n",
    "    a.append(len(set_ds))\n",
    "    b.append(len(ds))\n",
    "print max(a), min(a),np.mean(a), np.std(a)\n",
    "print max(b), min(b),np.mean(b), np.std(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2608/2608 [00:01<00:00, 1339.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2608 (2608, 5532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### ALS embeddingimport numpy as  np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "with tqdm(total=len(u_map)) as pbar:\n",
    "    \n",
    "#     split 1/10 for future\n",
    "    Y_map = {}\n",
    "    pairs = []\n",
    "    pseudo_history_map = {} # for training and validation\n",
    "    for user,v in u_map.items():\n",
    "        history = v\n",
    "        dates_history = [d for d,f in history]\n",
    "        min_date, max_date = min(dates_history), max(dates_history)\n",
    "        date_list = sorted(set(dates_history))\n",
    "        rest_date_set = set(date_list[-7:])\n",
    "        \n",
    "        \n",
    "        pseudo_history_map[user] = [(d,f) for d,f in history if d not in rest_date_set]\n",
    "#         calculate the Y\n",
    "        y = np.zeros([1, len(food_map)])\n",
    "        for d,f in history:\n",
    "            if d in rest_date_set:\n",
    "                y[0, food_map[f]] = 1\n",
    "            \n",
    "            else:\n",
    "                pair = (user_map[user], food_map[f])\n",
    "                pairs.append(pair)\n",
    "        Y_map[user] = y\n",
    "        pbar.update(1)\n",
    "        \n",
    "    rows = []\n",
    "    cols = []\n",
    "    pairs = set(pairs)\n",
    "    for pair in pairs:\n",
    "        u, f = pair\n",
    "        rows.append(u)\n",
    "        cols.append(f)\n",
    "    data = np.ones([len(rows),])\n",
    "    R = csr_matrix((data, (rows,cols)), shape=(len(user_map),len(food_map)))\n",
    "        \n",
    "    \n",
    "print len(Y_map), R.shape\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 100.0/100 [00:00<00:00, 208.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 32)\n",
      "(2608, 5532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=32, use_gpu=True, iterations=100)\n",
    "user_items = R.transpose()\n",
    "model.fit(user_items)\n",
    "print model.user_factors.shape\n",
    "print R.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer with ALS embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([7, 1])\n",
      "1564801\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import Transformer\n",
    "import numpy as np\n",
    "from constants import FOOD_NUM\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, dm, p_drop):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        self.food_emb = Food_embedding(FOOD_NUM, dm, 2, p_drop)\n",
    "        self.target_food_emb = nn.Embedding(FOOD_NUM, dm)\n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        nn.init.xavier_normal_(self.summary_weight)\n",
    "        self.linears = nn.ModuleList([nn.Linear(2*dm, 2*dm) for i in range(2)])\n",
    "        self.output_linear = nn.Linear(2*dm, 1)\n",
    "\n",
    "    def forward(self, food, history):\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        batch, _ =  food.size() \n",
    "        target = self.target_food_emb(food).view(batch, -1)\n",
    "        \n",
    "        K = history\n",
    "        \n",
    "        K = self.food_emb(K)\n",
    "        \n",
    "        \n",
    "        batch, K_len, d = K.size()\n",
    "        Q = self.summary_weight.repeat(batch,1).view(batch, 1, -1)\n",
    "        att_out = self.attention(Q, K)\n",
    "        x = torch.cat([att_out, target],dim=-1)\n",
    "        for lay in self.linears:\n",
    "            x = F.selu(lay(x))\n",
    "            x = self.drop(x)\n",
    "        x = self.output_linear(x)\n",
    "        y = torch.sigmoid(x)\n",
    "        return y\n",
    "    def to_ont_hot(self, one_hot_dim, indices):\n",
    "        batch, _ = indices.size()\n",
    "        one_hot = torch.zeros(batch, one_hot_dim, requires_grad=False)\n",
    "        one_hot.scatter_(1, indices.cpu(), 1)\n",
    "        return one_hot.cuda()\n",
    "    def attention(self, Q,K):\n",
    "        assert len(Q.shape) == 3 and len(K.shape) == 3\n",
    "        e = torch.bmm(Q,K.permute(0,2,1))\n",
    "        \n",
    "        att = F.softmax(e, dim=-1)\n",
    "        out = torch.bmm(att, K).squeeze(1)\n",
    "        return out\n",
    "        \n",
    "class Food_embedding(nn.Module):\n",
    "    def __init__(self, c_in, dm, layer_num, p_drop, activation_fn=F.selu):\n",
    "        super(Food_embedding, self).__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        assert layer_num >= 1\n",
    "        self.first_linear = nn.Linear(c_in, dm)\n",
    "        self.linears = nn.ModuleList([nn.Linear(dm, dm) for i in range(layer_num-1)])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        x = self.first_linear(x)\n",
    "        x = self.activation_fn(x)\n",
    "        x = self.drop(x)\n",
    "        for lay in self.linears:\n",
    "            x = self.drop(self.activation_fn(lay(x)))\n",
    "        return x\n",
    "    \n",
    "batch = 7\n",
    "dm = 128\n",
    "K = torch.rand([batch, 18, FOOD_NUM]).cuda()\n",
    "Q = torch.randint(FOOD_NUM,[batch,1], dtype=torch.long).cuda()\n",
    "model = Net(dm, 0.1).cuda()\n",
    "print(Q.dtype)\n",
    "o = model(Q, K)\n",
    "# print t\n",
    "print(o.size())\n",
    "# print o\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare sample generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 165, 5532) (32, 1) (32, 1)\n",
      "(16, 165, 5532) (16, 1) (16, 1)\n",
      "(165, 5532) (1,) (1,)\n"
     ]
    }
   ],
   "source": [
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "val_num = len(pseudo_history_map) // 10\n",
    "idx = np.random.permutation(len(pseudo_history_map))\n",
    "train_idx, val_idx = idx[val_num:], idx[:val_num]\n",
    "train_u_map = {k:pseudo_history_map[k] for k in pseudo_history_map.keys()[val_num:]}\n",
    "val_u_map = {k:pseudo_history_map[k] for k in pseudo_history_map.keys()[:val_num]}\n",
    "def batch_boostrap_generator(batch_size, u_map, food_map, Y_map, max_history_len, flip):\n",
    "    G = boostrap_generator(u_map, food_map, Y_map, max_history_len, flip)\n",
    "    while True:\n",
    "        X = []\n",
    "        pos_Y = []\n",
    "        neg_Y = []\n",
    "        for i in range(batch_size):\n",
    "            x, pos_y, neg_y = next(G)\n",
    "            x = np.pad(x, ((0,max_history_len-x.shape[0]),(0,0)), 'constant', constant_values=0)\n",
    "            X.append(np.expand_dims(x, axis=0))\n",
    "            pos_Y.append(np.expand_dims(pos_y, axis=0))\n",
    "            neg_Y.append(np.expand_dims(neg_y, axis=0))\n",
    "        yield np.vstack(X), np.vstack(pos_Y), np.vstack(neg_Y) \n",
    "def boostrap_generator(u_map, food_map, Y_map, max_history_len, flip):\n",
    "    while True:\n",
    "        keys = u_map.keys()\n",
    "        for user_idx in np.random.permutation(len(u_map)):\n",
    "            user = keys[user_idx]\n",
    "            X = np.zeros([max_history_len, len(food_map)])\n",
    "            Y = Y_map[user].flatten()\n",
    "            history = u_map[user]\n",
    "            ds = np.array([d for d,f in history])\n",
    "            fs = np.array([f for d,f in history])\n",
    "            sorted_idx = np.flip(np.argsort(ds), axis=-1) if flip else np.argsort(ds)\n",
    "            ds = ds[sorted_idx]\n",
    "            fd = fs[sorted_idx]\n",
    "            \n",
    "            date_idx = 0\n",
    "            now_date = ds[0]\n",
    "            for food, date in zip(fs,ds):\n",
    "                if date != now_date:\n",
    "                    date_idx+=1\n",
    "                    now_date = date\n",
    "                X[date_idx, food_map[food]] = 1\n",
    "            \n",
    "    #         positive sample\n",
    "            idx = np.random.permutation(len(Y))\n",
    "            pos_i = neg_i = -1\n",
    "            for i in idx:\n",
    "                if Y[i] == 1 and pos_i == -1:\n",
    "                    pos_i = i\n",
    "                if Y[i] == 0 and neg_i == -1:\n",
    "                    neg_i = i\n",
    "                if pos_i != -1 and neg_i != -1:\n",
    "                    break\n",
    "            yield X, np.array([pos_i]), np.array([neg_i])\n",
    "            \n",
    "    \n",
    "\n",
    "G = batch_boostrap_generator(32, train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "val_G = batch_boostrap_generator(32//2, val_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "\n",
    "x, pos_y, neg_y = next(G)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n",
    "x, pos_y, neg_y = next(val_G)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n",
    "\n",
    "G2 = boostrap_generator(train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=True)\n",
    "x, pos_y, neg_y = next(G2)\n",
    "print x.shape, pos_y.shape, neg_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/14427456 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 256/14427456 [00:04<74:13:04, 54.00it/s, acc : 0.488, val_acc : 0.471, 0.422, 0.464, 0.47487, 0.52471]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf6f00f0b6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#                 print 'x1', np.sum(x[0,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6fedea566efe>\u001b[0m in \u001b[0;36mbatch_boostrap_generator\u001b[0;34m(batch_size, u_map, food_map, Y_map, max_history_len, flip)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mneg_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_history_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6fedea566efe>\u001b[0m in \u001b[0;36mboostrap_generator\u001b[0;34m(u_map, food_map, Y_map, max_history_len, flip)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_history_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, acc, val_loss, val_acc, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f\\n' % (n_iter, loss, acc, val_loss, val_acc)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 10 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "        \n",
    "acc_q = deque(maxlen=1000)\n",
    "loss_q = deque(maxlen=1000)\n",
    "val_acc_q = deque(maxlen=1000)\n",
    "val_loss_q = deque(maxlen=1000)\n",
    "t = time.time()\n",
    "best_acc  = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "G = batch_boostrap_generator(batch_size, train_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=False)\n",
    "val_G = batch_boostrap_generator(batch_size, val_u_map, food_map, Y_map, max_history_len=MAX_SEQ_LEN, flip=False)\n",
    "\n",
    "print 'start training.'\n",
    "with open('log_att.txt', 'a') as f:\n",
    "    with open('best_att.txt', 'w') as best_log:\n",
    "        for e in range(epochs):\n",
    "            iters = len(food_map) * len(user_map)\n",
    "            with tqdm(total=iters) as pbar:\n",
    "                for it in range(iters):\n",
    "                    optimizer.zero_grad()\n",
    "                    model.train()\n",
    "                    x, pos_y, neg_y = next(G)\n",
    "    #                 print 'x1', np.sum(x[0,:])\n",
    "                    x = torch.FloatTensor(x).cuda()\n",
    "                    pos_y,neg_y = torch.LongTensor(pos_y), torch.LongTensor(neg_y)\n",
    "\n",
    "    #                 positive\n",
    "                    output = model(pos_y.cuda(), x)\n",
    "                    a = output[0,0].item()\n",
    "                    pred = output > 0.5\n",
    "                    label = torch.ones_like(output).cuda()\n",
    "                    pos_loss = criterion(output, label)\n",
    "\n",
    "                    acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                    acc_q.append(acc)\n",
    "    #                 pos_loss.backward()\n",
    "\n",
    "    #                 negative\n",
    "                    output = model(neg_y.cuda(), x)\n",
    "                    b = output[0,0].item()\n",
    "                    pred = output > 0.5\n",
    "                    label = torch.zeros_like(output).cuda()\n",
    "                    neg_loss = criterion(output, label )\n",
    "                    acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                    acc_q.append(acc)\n",
    "    #                 neg_loss.backward()\n",
    "\n",
    "                    loss = pos_loss + neg_loss\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    with torch.no_grad():\n",
    "                        model.eval()\n",
    "    #                 positive\n",
    "                        x, pos_y, neg_y = next(val_G)\n",
    "    #                     print 'x2', np.sum(x[0,:])\n",
    "                        x = torch.FloatTensor(x).cuda()\n",
    "                        pos_y,neg_y = torch.LongTensor(pos_y), torch.LongTensor(neg_y)\n",
    "    #                       \n",
    "                        output = model(pos_y.cuda(), x)\n",
    "    #                     o1 = model.transformer.decoder.mid\n",
    "    #                     o1 = model.mid\n",
    "\n",
    "                        c = output[0,0].item()\n",
    "                        pred = output > 0.5\n",
    "                        label = torch.ones_like(output).cuda()\n",
    "\n",
    "                        pos_loss = criterion(output, label )\n",
    "\n",
    "                        val_acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                        val_acc_q.append(val_acc)\n",
    "    #                 negative\n",
    "    #                     print pos_y, neg_y\n",
    "    #                     print output\n",
    "\n",
    "                        output = model(neg_y.cuda(), x)\n",
    "    #                     o2 = model.mid\n",
    "    #                     print o2.shape\n",
    "    #                     print neg_y.cuda().shape\n",
    "    #                     print neg_y.cuda()[0,0]\n",
    "    #                     print (o1 == o2).all()\n",
    "                        d = output[0,0].item()\n",
    "    #                     print c == d\n",
    "    #                     wf\n",
    "    #                     print pos_y == neg_y\n",
    "    #                     print output\n",
    "\n",
    "\n",
    "                        pred = output > 0.5\n",
    "                        label = torch.zeros_like(output).cuda()\n",
    "\n",
    "                        neg_loss = criterion(output, label )\n",
    "                        val_acc = torch.sum(pred == label.type(torch.uint8)).item() / float(output.shape[0])\n",
    "                        val_acc_q.append(val_acc)\n",
    "\n",
    "                        val_loss = pos_loss + neg_loss\n",
    "                    acc = np.mean(acc_q)\n",
    "                    val_acc = np.mean(val_acc_q)\n",
    "\n",
    "    #                 dump_log(model, it+1, loss, acc, val_loss, val_acc, f, './tmp.pt')\n",
    "\n",
    "    #                 pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, %.3f, %.3f, %.3f' % (acc, val_acc,a,b,c), refresh=False)\n",
    "                    pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, %.3f, %.3f, %.5f, %.5f' % (acc, val_acc,a,b,c,d), refresh=False)\n",
    "                    pbar.update(batch_size)\n",
    "                    dump_log(model, (it+1)*batch_size, loss, acc, val_loss, val_acc, f, './tmp_att.pt')\n",
    "                    if val_acc > best_acc and it > 100:\n",
    "                        torch.save(model, './best_att.pt')\n",
    "                        best_acc = val_acc\n",
    "                        best_log.write('%d\\t%.5f\\n' % ((it+1)*batch_size, best_acc))\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing with Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "        \n",
    "flip = False       \n",
    "model = torch.load('./best.pt')\n",
    "model.eval()\n",
    "batch_size = 256\n",
    "food_buf = torch.LongTensor(np.arange(len(food_map))).view(1,-1).repeat(batch_size, 1).cuda()\n",
    "answer_sheet = np.zeros([len(u_map), len(food_map)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(u_map)*len(food_map)) as pbar:\n",
    "        keys = u_map.keys()\n",
    "        ran = range((len(keys) // batch_size) +1) if len(keys) % batch_size != 0 else range(len(keys) // batch_size)\n",
    "        for i in ran:\n",
    "            a = i*batch_size\n",
    "            b = (i+1)*batch_size if (i+1)*batch_size < len(keys) else len(keys)\n",
    "            X = []\n",
    "            for user in keys[a:b]:\n",
    "                x = np.zeros([MAX_SEQ_LEN, len(food_map)])\n",
    "                history = u_map[user]\n",
    "                ds = np.array([d for d,f in history])\n",
    "                fs = np.array([f for d,f in history])\n",
    "                sorted_idx = np.flip(np.argsort(ds), axis=-1) if flip else np.argsort(ds)\n",
    "                ds = ds[sorted_idx]\n",
    "                fd = fs[sorted_idx]\n",
    "\n",
    "                date_idx = 0\n",
    "                now_date = ds[0]\n",
    "                for food, date in zip(fs,ds):\n",
    "                    if date != now_date:\n",
    "                        date_idx+=1\n",
    "                        now_date = date\n",
    "                    x[date_idx, food_map[food]] = 1\n",
    "                X.append(np.expand_dims(x,axis=0))\n",
    "            \n",
    "            X = torch.FloatTensor(np.vstack(X)).cuda()\n",
    "            for food_idx  in range(len(food_map)):\n",
    "                target = food_buf[:b-a, food_idx:food_idx+1]\n",
    "                output = model(target, X)\n",
    "                answer_sheet[a:b, food_idx:food_idx+1] =  output.cpu()\n",
    "                pbar.update(batch_size)\n",
    "                \n",
    "np.save('./output_sheet', answer_sheet)\n",
    "print answer_sheet.shape\n",
    "print'Done'\n",
    "\n",
    "rev_food_map = {v:k for k,v in food_map.items()}\n",
    "k=20\n",
    "a = ''\n",
    "buf = []\n",
    "with open('predict.csv', 'w') as f:\n",
    "    f.write('userid,foodid\\n')\n",
    "    for i,user in enumerate(u_map.keys()):\n",
    "        s = ''\n",
    "        for food_idx in reversed(np.argsort(answer_sheet[i,:])[-k:]):\n",
    "            s += ' %d' % rev_food_map[food_idx]\n",
    "        f.write('%d,%s\\n' % (user, s) )\n",
    "        buf.append(a == s)\n",
    "        a = s\n",
    "print buf\n",
    "print 'done'\n",
    "\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {user:i for i,user in enumerate(u_map.keys())}\n",
    "for k in u_map.keys():\n",
    "    assert m[k] == user_map[k]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
