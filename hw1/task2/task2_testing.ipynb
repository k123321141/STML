{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "# environment\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\" if with_gpu else \"cpu\")\n",
    "\n",
    "def positional_encoding(pos):\n",
    "    assert D_MODEL % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,D_MODEL], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "def get_pos_mat(length):\n",
    "    if length > MAX_SEQUENCE_LENGTH:\n",
    "        print('sequence length reach PE_MAT_CACHE. %d ' % length)\n",
    "        ret = torch.cat([positional_encoding(i) for i in range(length)], dim=0).to(device)\n",
    "        ret.requires_grad = False\n",
    "        global PE_CACHE_MATRIX\n",
    "        PE_CACHE_MATRIX = ret\n",
    "        return ret\n",
    "    else:\n",
    "        return PE_CACHE_MATRIX[:length]\n",
    "    \n",
    "PE_CACHE_MATRIX = torch.cat([positional_encoding(i) for i in range(0,MAX_SEQUENCE_LENGTH)], dim=0).to(device)\n",
    "PE_CACHE_MATRIX.requires_grad = False\n",
    "\n",
    "# construct neuron network\n",
    "\n",
    "def scaled_dot_attention(Q, K, V, mask=None):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    out = torch.matmul(Q,K.t()) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out = out.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        self.summary_decoder = Stack_Decoder(2, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "        self.output_linear = nn.Linear(3*dm, 1)\n",
    "\n",
    "    def forward(self, Q, K, Q_fea, K_fea):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        \n",
    "        \n",
    "        summary = self.summary_decoder(self.summary_weight, de_out)\n",
    "        x = torch.cat([summary, Q_fea.view([1,-1]), K_fea.view([1,-1])], dim=-1)\n",
    "        out = self.output_linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "class Word_Embedding(nn.Module):\n",
    "    def __init__(self, emb_matrix):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.emb = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, padding_idx=0)\n",
    "        self.emb.weight = nn.parameter.Parameter(torch.FloatTensor(emb_matrix))\n",
    "        self.emb.weight.requires_grad_(False)\n",
    "        \n",
    "        self.linear = nn.Linear(EMBEDDING_DIM, D_MODEL, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K               \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.attention_norm_lay = nn.LayerNorm([dm,])\n",
    "        self.att_drop = nn.Dropout(P_DROP)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "        att_out = self.attention_norm_lay(K + attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(att_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "        out = self.ff_norm_lay(att_out + linear_out)\n",
    "        out = att_out + linear_out\n",
    "    \n",
    "        return out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        Q_len, d = Q.size()\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out, mask=None)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Decoder, self).__init__()\n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.Q_att_drop = nn.Dropout(P_DROP)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.QK_att_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out, mask):\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = self.Q_attention_norm_lay(Q + Q_attention_out)\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = self.QK_attention_norm_lay(Q_att_out + QK_attention_out)\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = self.ff_norm_lay(QK_att_out + linear_out)\n",
    "        return out\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask=None):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "            \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len,_ = x.size()\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# encoder = Stack_Encoder(6, 64,64,20,8)\n",
    "# # print net\n",
    "print 'load done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all 17500 xml files.\n",
      "Found 82709 unique tokens.\n",
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from os.path import join\n",
    "import os\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from constants import MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def quote_title_abstract(xml_path):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    soup = BS(data)\n",
    "    title, abstract = soup.find('title').text, soup.find('abstract').text\n",
    "    return title.strip(), abstract.strip()\n",
    "\n",
    "# text preprocessing\n",
    "data_path = join('./','kaggle/')\n",
    "xml_dir = join(data_path, 't2-doc')\n",
    "xml_list = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "# print(len(xml_list))\n",
    "\n",
    "\n",
    "texts = []\n",
    "\n",
    "for xml in xml_list:\n",
    "    path = join(xml_dir,xml)\n",
    "    title, abstract = quote_title_abstract(path)\n",
    "    text = title + '' + abstract\n",
    "    texts.append(text)\n",
    "#     texts.append(title)\n",
    "#     texts.append(abstract)\n",
    "print('read all %d xml files.' % len(xml_list))\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=True, split=' ', char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "xml_id_map = {}\n",
    "for i,xml in enumerate(xml_list):\n",
    "    node_id = int(xml.replace('.xml',''))\n",
    "    xml_id_map[node_id] = data[i,:]\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r', encoding='utf8') as f:\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         coefs = np.asarray(values[1:], dtype='float32')\n",
    "#         embeddings_index[word] = coefs\n",
    "# prepare embedding matrix\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load text model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "# environment\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\" if with_gpu else \"cpu\")\n",
    "\n",
    "def positional_encoding(pos):\n",
    "    assert D_MODEL % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,D_MODEL], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "def get_pos_mat(length):\n",
    "    if length > MAX_SEQUENCE_LENGTH:\n",
    "        print('sequence length reach PE_MAT_CACHE. %d ' % length)\n",
    "        ret = torch.cat([positional_encoding(i) for i in range(length)], dim=0).to(device)\n",
    "        ret.requires_grad = False\n",
    "        global PE_CACHE_MATRIX\n",
    "        PE_CACHE_MATRIX = ret\n",
    "        return ret\n",
    "    else:\n",
    "        return PE_CACHE_MATRIX[:length]\n",
    "    \n",
    "PE_CACHE_MATRIX = torch.cat([positional_encoding(i) for i in range(0,MAX_SEQUENCE_LENGTH)], dim=0).to(device)\n",
    "PE_CACHE_MATRIX.requires_grad = False\n",
    "\n",
    "# construct neuron network\n",
    "\n",
    "def scaled_dot_attention(Q, K, V, mask=None):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    out = torch.matmul(Q,K.t()) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out = out.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        self.summary_decoder = Stack_Decoder(2, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "        self.output_linear = nn.Linear(dm, 1)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        \n",
    "        \n",
    "        summary = self.summary_decoder(self.summary_weight, de_out)\n",
    "        out = self.output_linear(summary)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "class Word_Embedding(nn.Module):\n",
    "    def __init__(self, emb_matrix):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.emb = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, padding_idx=0)\n",
    "        self.emb.weight = nn.parameter.Parameter(torch.FloatTensor(emb_matrix))\n",
    "        self.emb.weight.requires_grad_(False)\n",
    "        \n",
    "        self.linear = nn.Linear(EMBEDDING_DIM, D_MODEL, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K               \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.attention_norm_lay = nn.LayerNorm([dm,])\n",
    "        self.att_drop = nn.Dropout(P_DROP)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "        att_out = self.attention_norm_lay(K + attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(att_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "        out = self.ff_norm_lay(att_out + linear_out)\n",
    "        out = att_out + linear_out\n",
    "    \n",
    "        return out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        Q_len, d = Q.size()\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out, mask=None)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Decoder, self).__init__()\n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.Q_att_drop = nn.Dropout(P_DROP)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.QK_att_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out, mask):\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = self.Q_attention_norm_lay(Q + Q_attention_out)\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = self.QK_attention_norm_lay(Q_att_out + QK_attention_out)\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = self.ff_norm_lay(QK_att_out + linear_out)\n",
    "        return out\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask=None):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "            \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len,_ = x.size()\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# encoder = Stack_Encoder(6, 64,64,20,8)\n",
    "# # print net\n",
    "print('load text model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/76947 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536920726299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-816c2ad6e0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mwf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d,%d\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wf' is not defined"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "model = torch.load('./text_best_loss.pt')\n",
    "model.eval()\n",
    "\n",
    "edges_unordered = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "with torch.no_grad():\n",
    "    with open('weight.csv', 'w') as f:\n",
    "        with tqdm(total=edges_unordered.shape[0]) as pbar:\n",
    "            f.write('query_id,prediction\\n')\n",
    "            for i in range(edges_unordered.shape[0]):\n",
    "                src, dst = edges_unordered[i, :]\n",
    "\n",
    "                q = xml_id_map[dst]\n",
    "                k = xml_id_map[src]\n",
    "\n",
    "\n",
    "                q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "\n",
    "                output = model(q.cuda(), k.cuda()).flatten().item()\n",
    "                print output\n",
    "                wf\n",
    "                out = 1 if output >= 0.5 else 0\n",
    "                f.write('%d,%d\\n' % (1 + i, out))\n",
    "                if src not in training_node_set and dst not in training_node_set:\n",
    "                    g.write('%d,%d\\n' % (1 + i, 0))\n",
    "                else:\n",
    "                    g.write('%d,%d\\n' % (1 + i, out))\n",
    "                pbar.update(1)\n",
    "print c\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb\n",
    "buf = np.genfromtxt('./t2.emb', skip_header=1, dtype=np.float32)\n",
    "nodes = buf[:,0].astype(np.int32)\n",
    "emb = buf[:,1:]\n",
    "\n",
    "node_emb_dict = {}\n",
    "for i in range(emb.shape[0]):\n",
    "    node_id = nodes[i]\n",
    "    x = emb[i,:]\n",
    "    node_emb_dict[node_id] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76947/76947 [43:43<00:00, 29.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "model = torch.load('./best_loss.pt')\n",
    "model.eval()\n",
    "\n",
    "edges_unordered = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "links = np.genfromtxt('./kaggle/t2-train.txt', dtype=np.int32)\n",
    "training_node_set = set(links.flatten().tolist())\n",
    "c = 1\n",
    "with torch.no_grad():\n",
    "    with open('pred.txt.csv', 'w') as f:\n",
    "        with open('guess.csv', 'w') as g:\n",
    "            with tqdm(total=edges_unordered.shape[0]) as pbar:\n",
    "\n",
    "                f.write('query_id,prediction\\n')\n",
    "                g.write('query_id,prediction\\n')\n",
    "                for i in range(edges_unordered.shape[0]):\n",
    "\n",
    "                    src, dst = edges_unordered[i, :]\n",
    "                        \n",
    "                    q = xml_id_map[dst]\n",
    "                    k = xml_id_map[src]\n",
    "\n",
    "                    q_f = node_emb_dict[dst]\n",
    "                    k_f = node_emb_dict[src]\n",
    "\n",
    "                    q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "                    q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "                    output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda()).flatten().item()\n",
    "\n",
    "                    out = 1 if output >= 0.5 else 0\n",
    "                    f.write('%d,%d\\n' % (1 + i, out))\n",
    "                    if src not in training_node_set and dst not in training_node_set:\n",
    "                        g.write('%d,%d\\n' % (1 + i, 0))\n",
    "                    else:\n",
    "                        g.write('%d,%d\\n' % (1 + i, out))\n",
    "                    pbar.update(1)\n",
    "print c\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to libsvm type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " transformer2 done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "class Transformer2(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer2, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        self.summary_decoder = Stack_Decoder(2, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "        self.output_linear = nn.Linear(3*dm, 1)\n",
    "\n",
    "    def forward(self, Q, K, Q_fea, K_fea):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        \n",
    "        \n",
    "        summary = self.summary_decoder(self.summary_weight, de_out)\n",
    "        x = torch.cat([summary, Q_fea.view([1,-1]), K_fea.view([1,-1])], dim=-1)\n",
    "        out = self.output_linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out,x\n",
    "\n",
    "print ' transformer2 done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2003515/2003515 [00:06<00:00, 294116.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,), (128,), (128,))\n",
      "((16161, 150), (16161, 150), (16161, 128), (16161, 128))\n",
      "((145458, 150), (145458, 150), (145458, 128), (145458, 128))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list, node_emb_dict, neighbor_link_rate=0.8):\n",
    "    \n",
    "    \n",
    "    exist_node_list = xml_id_map.keys()\n",
    "    exist_N = len(training_node_list)\n",
    "    N = adj_mat.shape[0]\n",
    "    \n",
    "#     adj mat\n",
    "    links = np.array(list(map(idx_map.get, links.flatten())),\n",
    "                     dtype=np.int32).reshape(links.shape)\n",
    "    \n",
    "    adj_sp = sp.coo_matrix((np.ones(links.shape[0]), (links[:, 0], links[:, 1])),\n",
    "                        shape=(N, N),\n",
    "                        dtype=np.uint8)\n",
    "    adj_sp_2 = (sp.coo_matrix.dot(adj_sp,adj_sp) + adj_sp).tocoo()\n",
    "    \n",
    "    rev_map = {v:k for k,v in idx_map.items()}\n",
    "    adj_map = {i:[] for i in range(N)}\n",
    "    with tqdm(total=len(adj_sp_2.row)) as pbar:\n",
    "        for i,j,v in zip(adj_sp_2.row, adj_sp_2.col, adj_sp_2.data):\n",
    "            if adj_mat[i, j] != 1 and v == 1:\n",
    "                adj_map[i].append(j)\n",
    "            pbar.update(1)\n",
    "#             print i,N\n",
    "                \n",
    "    while True:\n",
    "        src = training_node_list[np.random.randint(exist_N)]\n",
    "        \n",
    "#         choose neighbor link\n",
    "        if np.random.rand(1) <= neighbor_link_rate:\n",
    "        \n",
    "            i = idx_map[src]\n",
    "            high = len(adj_map[i])\n",
    "            while high == 0:\n",
    "                src = training_node_list[np.random.randint(exist_N)]\n",
    "                i = idx_map[src]\n",
    "                high = len(adj_map[i])\n",
    "                \n",
    "            idx = np.random.randint(high)\n",
    "            dst = adj_map[i][idx]\n",
    "            dst = rev_map[dst]\n",
    "        else:\n",
    "            dst = training_node_list[np.random.randint(exist_N)]\n",
    "            while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "                dst = training_node_list[np.random.randint(exist_N)]\n",
    "        Q = xml_id_map[dst]\n",
    "        K = xml_id_map[src]\n",
    "        Q_fea = node_emb_dict[dst]\n",
    "        K_fea = node_emb_dict[src]\n",
    "        yield Q, K, Q_fea, K_fea\n",
    "\n",
    "def val_data(edges, xml_id_map):\n",
    "    Q, K = [],[]\n",
    "    Q_f, K_f = [],[]\n",
    "    \n",
    "    for idx in range(edges.shape[0]):\n",
    "        src, dst = edges[idx, :]\n",
    "        q = xml_id_map[dst]\n",
    "        k = xml_id_map[src]\n",
    "        q_fea = node_emb_dict[dst]\n",
    "        k_fea = node_emb_dict[src]\n",
    "        \n",
    "        Q.append(q)\n",
    "        K.append(k)\n",
    "        Q_f.append(q_fea)\n",
    "        K_f.append(k_fea)\n",
    "        \n",
    "    Q = np.vstack(Q)\n",
    "    K = np.vstack(K)\n",
    "    Q_fea = np.vstack(Q_f)\n",
    "    K_fea = np.vstack(K_f)\n",
    "    \n",
    "    return Q, K, Q_fea, K_fea\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "links = np.genfromtxt(join(data_path,'t2-fake.txt'), dtype=np.int32)\n",
    "idx_map = {node:idx for idx, node in enumerate(list(set(links.flatten().tolist())))}\n",
    "N = links.shape[0]\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "for i in range(links.shape[0]):\n",
    "    src, dst = links[i].tolist()\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "\n",
    "\n",
    "idx = np.random.permutation(N)\n",
    "train_idx = idx[N//10:]\n",
    "val_idx = idx[:N//10]\n",
    "\n",
    "training_node_list = list(set(links.flatten().tolist()))\n",
    "neg_G = negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list, node_emb_dict)\n",
    "pos_Q, pos_K, pos_Q_fea, pos_K_fea = val_data(links[train_idx,:], xml_id_map)\n",
    "val_Q, val_K, val_Q_fea, val_K_fea = val_data(links[val_idx,:], xml_id_map)\n",
    "\n",
    "q,k,q_f,k_f = next(neg_G)\n",
    "print(q.shape,k.shape, q_f.shape, k_f.shape)\n",
    "print(val_Q.shape,val_K.shape, val_Q_fea.shape, val_K_fea.shape)\n",
    "print(pos_Q.shape,pos_K.shape, pos_Q_fea.shape, pos_K_fea.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 76946\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "# emb\n",
    "buf = np.genfromtxt('./t2.emb', skip_header=1, dtype=np.float32)\n",
    "nodes = buf[:,0].astype(np.int32)\n",
    "emb = buf[:,1:]\n",
    "\n",
    "node_emb_dict = {}\n",
    "for i in range(emb.shape[0]):\n",
    "    node_id = nodes[i]\n",
    "    x = emb[i,:]\n",
    "    node_emb_dict[node_id] = x\n",
    "#     \n",
    "    \n",
    "    \n",
    "links = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "with open('pred.txt.csv', 'w') as f:\n",
    "    f.write('query_id,prediction\\n')\n",
    "    for i in range(links.shape[0]):\n",
    "\n",
    "        a = node_emb_dict[src]\n",
    "        b = node_emb_dict[dst]\n",
    "        d = cos_d(a, b)\n",
    "        if d >= 0.242:\n",
    "            f.write('%d,1\\n' % (1 + i))\n",
    "        else:\n",
    "            f.write('%d,0\\n' % (1 + i))\n",
    "    \n",
    "print 'done', i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161619\n",
      "(161715, 256) (161715, 1)\n",
      "0.923%, 0.242\n",
      "0.11969484\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "def get_node_set(path):\n",
    "    # training data\n",
    "    edges_unordered = np.genfromtxt(path,\n",
    "                                    dtype=np.int32)\n",
    "    id_set = set(edges_unordered.flatten().tolist())\n",
    "    return id_set\n",
    "\n",
    "data_path = join('./','kaggle')\n",
    "# emb\n",
    "buf = np.genfromtxt('./t2.emb', skip_header=1, dtype=np.float32)\n",
    "nodes = buf[:,0].astype(np.int32)\n",
    "emb = buf[:,1:]\n",
    "\n",
    "node_emb_dict = {}\n",
    "for i in range(emb.shape[0]):\n",
    "    node_id = nodes[i]\n",
    "    x = emb[i,:]\n",
    "    node_emb_dict[node_id] = x\n",
    "    \n",
    "# training data\n",
    "idx_map = {k:i for i,k in enumerate(nodes.tolist())}\n",
    "links = np.genfromtxt('./kaggle/t2-fake.txt', dtype=np.int32)\n",
    "\n",
    "N = len(idx_map)\n",
    "X = []\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "for i in range(links.shape[0]):\n",
    "    \n",
    "    src, dst = links[i].tolist()\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "    fea = np.concatenate([node_emb_dict[src], node_emb_dict[dst]], axis=-1)\n",
    "    X.append(fea)\n",
    "X = np.vstack(X)\n",
    "    \n",
    "\n",
    "batch_size = 128\n",
    "def naive_bootsrap_generator(X, adj_mat, idx_map, node_emb_dict, train_node_set, batch_size=128, neg_rate=1. ):\n",
    "    train_node_list = list(train_node_set)\n",
    "    train_N = len(train_node_list)\n",
    "    num_edge = X.shape[0]\n",
    "        \n",
    "    while True:\n",
    "        idx = np.random.choice(num_edge, batch_size)\n",
    "        pos_X = X[idx, :]\n",
    "        \n",
    "        neg_count = int(batch_size*neg_rate)\n",
    "        neg_idx = np.random.randint(train_N, size=[neg_count, 2])\n",
    "        neg_X = []\n",
    "        for i in range(neg_count):\n",
    "            src, dst = neg_idx[i]\n",
    "            src = train_node_list[src]\n",
    "            dst = train_node_list[dst]\n",
    "            if src != dst and adj_mat[idx_map[src], idx_map[dst]] == 0:\n",
    "                fea = np.concatenate([node_emb_dict[src], node_emb_dict[dst]], axis=-1)\n",
    "                neg_X.append(fea)\n",
    "        neg_X = np.vstack(neg_X)\n",
    "\n",
    "        ret_X = np.vstack([pos_X, neg_X])\n",
    "        ret_Y = np.zeros([ret_X.shape[0], 1])\n",
    "        ret_Y[:batch_size, 0] = 1\n",
    "        yield ret_X, ret_Y\n",
    "\n",
    "N = X.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "train_idx = idx[N//10:]\n",
    "val_idx = idx[:N//10]\n",
    "\n",
    "train_X = X[train_idx,:]\n",
    "val_X = X[val_idx,:]\n",
    "\n",
    "train_node_set = get_node_set('./kaggle/t2-train.txt')\n",
    "G = naive_bootsrap_generator(train_X, adj_mat, idx_map, node_emb_dict, train_node_set, batch_size=batch_size)\n",
    "val_G = naive_bootsrap_generator(val_X, adj_mat, idx_map, node_emb_dict, train_node_set,batch_size=batch_size, neg_rate=0.1)\n",
    "x,y = next(G)\n",
    "# print x.shape,y.shape\n",
    "x,y = next(val_G)\n",
    "# print x.shape,y.shape\n",
    "\n",
    "N = X.shape[0]\n",
    "print N\n",
    "xx = []\n",
    "yy = []\n",
    "\n",
    "for i in range((N//2) // batch_size +1):\n",
    "    x,y = next(G)\n",
    "#     x = x[batch_size:,:]\n",
    "#     y = y[batch_size:,:]\n",
    "    yy.append(y)\n",
    "XX = np.vstack(xx)\n",
    "YY = np.vstack(yy)\n",
    "\n",
    "\n",
    "# XX = np.vstack([X,XX])\n",
    "# YY = np.vstack([np.ones([X.shape[0],1]),YY])\n",
    "print XX.shape, YY.shape\n",
    "\n",
    "    \n",
    "def cos_d(x,y):\n",
    "    assert x.shape==y.shape==(128,)\n",
    "    return np.dot(x,y)/(np.linalg.norm(x, ord=2) * np.linalg.norm(y, ord=2))\n",
    "\n",
    "def foo(X, Y):\n",
    "    N,dim = X.shape\n",
    "    out = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        src, dst = X[i,:dim//2], X[i,dim//2:]\n",
    "        d = cos_d(src, dst)\n",
    "        out.append(d)\n",
    "    out = np.array(out)\n",
    "    label = Y.flatten().astype(np.bool)\n",
    "    best_acc = best_threshold = 0\n",
    "    for threshold in np.linspace(0,1,100):\n",
    "        buf = out >= threshold\n",
    "        acc = np.mean(buf == label)\n",
    "#         print '%.2f%%' % acc, threshold\n",
    "    \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_acc, best_threshold, out\n",
    "acc, threshold, out = foo(XX,YY)\n",
    "print '%.3f%%, %.3f' % (acc, threshold)\n",
    "\n",
    "# XX = np.vstack([X,XX])\n",
    "# YY = np.vstack([np.ones([X.shape[0],1]),YY])\n",
    "acc, threshold, out2 = foo(XX,YY)\n",
    "buf = np.sort(out2)\n",
    "l = len(buf)\n",
    "print buf[l//4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "with open(join('./','t2_fake.emb')) as f:\n",
    "    num_nodes, D = f.readline().strip().split(' ')\n",
    "    num_nodes = int(num_nodes)\n",
    "    D = int(D)\n",
    "    \n",
    "    ls = f.readlines()\n",
    "node_emb_dict = {}\n",
    "for l in ls:\n",
    "    buf = l.strip().split(' ')\n",
    "    node_id, emb = int(buf[0]), buf[1:]\n",
    "    x = np.asarray([float(i) for i in emb], dtype=np.float32)\n",
    "    node_emb_dict[node_id] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 300)\n"
     ]
    }
   ],
   "source": [
    "print embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print q.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 135/323238 [00:09<6:02:09, 14.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0558b78ed709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mq_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#                 output, mid = model(q, k, q_f, k_f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mmid_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7efcff058826>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, Q_fea, K_fea)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa7ab0cddf32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, encoder_out)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mQ_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa7ab0cddf32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, encoder_out, mask)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mQ_att_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_attention_norm_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ_attention_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#         query key attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mQK_attention_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQK_attention_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_att_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mQK_attention_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQK_att_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQK_attention_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mQK_att_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQK_attention_norm_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_att_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQK_attention_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa7ab0cddf32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q_input, K_input, V_input, mask)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa7ab0cddf32>\u001b[0m in \u001b[0;36mscaled_dot_attention\u001b[0;34m(Q, K, V, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscaled_dot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "tmp = torch.load('./best_loss.pt')\n",
    "model = Transformer2(STACKED_NUM, DK, DV, D_MODEL, H, emb_matrix=np.zeros([10001, 300])).to(device)\n",
    "model.load_state_dict(tmp.state_dict())\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "edges_unordered = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "# links = np.genfromtxt('./kaggle/t2-train.txt', dtype=np.int32)\n",
    "# training_node_set = set(links.flatten().tolist())\n",
    "mid_X = []\n",
    "val_mid_X = []\n",
    "weight = []\n",
    "neg_rate = 1\n",
    "total_N = pos_Q.shape[0] + int(pos_Q.shape[0]*neg_rate) + 2*val_Q.shape[0]\n",
    "with torch.no_grad():\n",
    "    for i in range(edges_unordered.shape[0]):\n",
    "        with tqdm(total=total_N) as pbar:\n",
    "    #         positive train\n",
    "            for i in range(pos_Q.shape[0]):\n",
    "                q,k = pos_Q[i,:], val_K[i,:]\n",
    "                q_f,k_f = pos_Q_fea[i,:], pos_K_fea[i,:]\n",
    "                q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "                q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "                output, mid = model(q.to(device), k.to(device), q_f.to(device), k_f.to(device))\n",
    "#                 output, mid = model(q, k, q_f, k_f)\n",
    "                mid_X.append(mid)\n",
    "                weight.append(1)\n",
    "                pbar.update(1)\n",
    "    #         negative train\n",
    "            for i in range(pos_Q.shape[0]*neg_rate):\n",
    "                q,k,q_f,k_f = next(neg_G)\n",
    "                q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "                q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "                output, mid = model(q.to(device), k.to(device), q_f.to(device), k_f.to(device))\n",
    "                mid_X.append(mid)\n",
    "                weight.append(1./neg_rate)\n",
    "                pbar.update(1)\n",
    "    #         positive val\n",
    "            for val_i in range(val_Q.shape[0]):\n",
    "                q,k = val_Q[val_i,:], val_K[val_i,:]\n",
    "                q_f,k_f = val_Q_fea[val_i,:], val_K_fea[val_i,:]\n",
    "                q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "                q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "                output, mid = model(q.to(device), k.to(device), q_f.to(device), k_f.to(device))\n",
    "                val_mid_X.append(mid)\n",
    "                pbar.update(1)\n",
    "\n",
    "    #         negative val\n",
    "            for val_i in range(val_Q.shape[0]):\n",
    "                q,k,q_f,k_f = next(neg_G)\n",
    "                q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "                q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "                output, mid = model(q.to(device), k.to(device), q_f.to(device), k_f.to(device))\n",
    "                val_mid_X.append(mid)\n",
    "                pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all 17500 xml files.\n",
      "Found 82709 unique tokens.\n",
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from os.path import join\n",
    "import os\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from constants import MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "def quote_title_abstract(xml_path):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    soup = BS(data)\n",
    "    title, abstract = soup.find('title').text, soup.find('abstract').text\n",
    "    return title.strip(), abstract.strip()\n",
    "\n",
    "# text preprocessing\n",
    "data_path = join('./','kaggle/')\n",
    "xml_dir = join(data_path, 't2-doc')\n",
    "xml_list = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "# print(len(xml_list))\n",
    "\n",
    "\n",
    "texts = []\n",
    "\n",
    "for xml in xml_list:\n",
    "    path = join(xml_dir,xml)\n",
    "    title, abstract = quote_title_abstract(path)\n",
    "    text = title + '' + abstract\n",
    "    texts.append(text)\n",
    "#     texts.append(title)\n",
    "#     texts.append(abstract)\n",
    "print('read all %d xml files.' % len(xml_list))\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=True, split=' ', char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "xml_id_map = {}\n",
    "for i,xml in enumerate(xml_list):\n",
    "    node_id = int(xml.replace('.xml',''))\n",
    "    xml_id_map[node_id] = data[i,:]\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r', encoding='utf8') as f:\n",
    "with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76947/76947 [1:30:33<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write done\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "tmp = torch.load('./best_loss_2.pt')\n",
    "model = Transformer2(STACKED_NUM, DK, DV, D_MODEL, H, emb_matrix=np.zeros([10001, 300])).to(device)\n",
    "model.load_state_dict(tmp.state_dict())\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "edges_unordered = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "# links = np.genfromtxt('./kaggle/t2-train.txt', dtype=np.int32)\n",
    "# training_node_set = set(links.flatten().tolist())\n",
    "test_mid_X = []\n",
    "test_Y = []\n",
    "with torch.no_grad():\n",
    "#     with tqdm(total=total_N) as pbar:\n",
    "    with tqdm(total=edges_unordered.shape[0]) as pbar:\n",
    "        for i in range(edges_unordered.shape[0]):\n",
    "\n",
    "            src, dst = edges_unordered[i, :]\n",
    "\n",
    "            q = xml_id_map[dst]\n",
    "            k = xml_id_map[src]\n",
    "\n",
    "            q_f = node_emb_dict[dst]\n",
    "            k_f = node_emb_dict[src]\n",
    "\n",
    "            q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "            q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "            output,mid = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda())\n",
    "\n",
    "            out = 1 if output.flatten().item() >= 0.5 else 0\n",
    "            test_mid_X.append(mid)\n",
    "            test_Y.append(out)\n",
    "            pbar.update(1)\n",
    "\n",
    "        \n",
    "test_mid = np.vstack(test_mid_X)\n",
    "test_out = np.array(test_Y)\n",
    "with open('./test_mid', 'wb') as f:\n",
    "    np.save(f,test_mid)\n",
    "with open('./test_out', 'wb') as f:\n",
    "    np.save(f,test_out)\n",
    "print 'write done'\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12(virtualenv)",
   "language": "python",
   "name": "python2.7.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
