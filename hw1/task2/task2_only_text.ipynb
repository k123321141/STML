{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all 17500 xml files.\n",
      "Found 82709 unique tokens.\n",
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from os.path import join\n",
    "import os\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from constants import MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "def quote_title_abstract(xml_path):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    soup = BS(data)\n",
    "    title, abstract = soup.find('title').text, soup.find('abstract').text\n",
    "    return title.strip(), abstract.strip()\n",
    "\n",
    "# text preprocessing\n",
    "data_path = join('./','kaggle/')\n",
    "xml_dir = join(data_path, 't2-doc')\n",
    "xml_list = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "# print(len(xml_list))\n",
    "\n",
    "\n",
    "texts = []\n",
    "\n",
    "for xml in xml_list:\n",
    "    path = join(xml_dir,xml)\n",
    "    title, abstract = quote_title_abstract(path)\n",
    "    text = title + '' + abstract\n",
    "    texts.append(text)\n",
    "#     texts.append(title)\n",
    "#     texts.append(abstract)\n",
    "print('read all %d xml files.' % len(xml_list))\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=True, split=' ', char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "xml_id_map = {}\n",
    "for i,xml in enumerate(xml_list):\n",
    "    node_id = int(xml.replace('.xml',''))\n",
    "    xml_id_map[node_id] = data[i,:]\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r', encoding='utf8') as f:\n",
    "with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([1, 1])\n",
      "5583361\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "# environment\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\" if with_gpu else \"cpu\")\n",
    "\n",
    "def positional_encoding(pos):\n",
    "    assert D_MODEL % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,D_MODEL], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "def get_pos_mat(length):\n",
    "    if length > MAX_SEQUENCE_LENGTH:\n",
    "        print('sequence length reach PE_MAT_CACHE. %d ' % length)\n",
    "        ret = torch.cat([positional_encoding(i) for i in range(length)], dim=0).to(device)\n",
    "        ret.requires_grad = False\n",
    "        global PE_CACHE_MATRIX\n",
    "        PE_CACHE_MATRIX = ret\n",
    "        return ret\n",
    "    else:\n",
    "        return PE_CACHE_MATRIX[:length]\n",
    "    \n",
    "PE_CACHE_MATRIX = torch.cat([positional_encoding(i) for i in range(0,MAX_SEQUENCE_LENGTH)], dim=0).to(device)\n",
    "PE_CACHE_MATRIX.requires_grad = False\n",
    "\n",
    "# construct neuron network\n",
    "\n",
    "def scaled_dot_attention(Q, K, V, mask=None):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    out = torch.matmul(Q,K.t()) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out = out.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        self.summary_decoder = Stack_Decoder(2, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "        self.output_linear = nn.Linear(dm, 1)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        \n",
    "        \n",
    "        summary = self.summary_decoder(self.summary_weight, de_out)\n",
    "        out = self.output_linear(summary)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "class Word_Embedding(nn.Module):\n",
    "    def __init__(self, emb_matrix):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.emb = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, padding_idx=0)\n",
    "        self.emb.weight = nn.parameter.Parameter(torch.FloatTensor(emb_matrix))\n",
    "        self.emb.weight.requires_grad_(False)\n",
    "        \n",
    "        self.linear = nn.Linear(EMBEDDING_DIM, D_MODEL, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K               \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.attention_norm_lay = nn.LayerNorm([dm,])\n",
    "        self.att_drop = nn.Dropout(P_DROP)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "        att_out = self.attention_norm_lay(K + attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(att_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "        out = self.ff_norm_lay(att_out + linear_out)\n",
    "        out = att_out + linear_out\n",
    "    \n",
    "        return out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        Q_len, d = Q.size()\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out, mask=None)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Decoder, self).__init__()\n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.Q_att_drop = nn.Dropout(P_DROP)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.QK_att_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out, mask):\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = self.Q_attention_norm_lay(Q + Q_attention_out)\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = self.QK_attention_norm_lay(Q_att_out + QK_attention_out)\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = self.ff_norm_lay(QK_att_out + linear_out)\n",
    "        return out\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask=None):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "            \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len,_ = x.size()\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# encoder = Stack_Encoder(6, 64,64,20,8)\n",
    "# # print net\n",
    "Q = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "V = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "Q_fea = torch.rand([D_MODEL,]).to(device)\n",
    "K_fea = torch.rand([D_MODEL,]).to(device)\n",
    "net = Transformer(STACKED_NUM, DK, DV, D_MODEL, H, embedding_matrix).to(device)\n",
    "print(Q.dtype)\n",
    "o = net(Q, V)\n",
    "# print t\n",
    "print(o.size())\n",
    "# print o\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight done\n"
     ]
    }
   ],
   "source": [
    "tmp_m = torch.load('./best_loss.pt')\n",
    "net.decoder.load_state_dict(tmp_m.decoder.state_dict())\n",
    "net.encoder.load_state_dict(tmp_m.encoder.state_dict())\n",
    "# torch.nn.init.xavier_uniform_(net.output_linear.weight)\n",
    "print 'load weight done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = np.genfromtxt(join(data_path,'t2-train.txt'), dtype=np.int32)\n",
    "idx_map = {node:idx for idx, node in enumerate(list(set(links.flatten().tolist())))}\n",
    "N = links.shape[0]\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "for i in range(links.shape[0]):\n",
    "    src, dst = links[i].tolist()\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581426/581426 [00:01<00:00, 338265.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,))\n",
      "((8668, 150), (8668, 150))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def positive_bootsrap_generator(edges, xml_id_map):\n",
    "    num_edge = len(edges)\n",
    "        \n",
    "    while True:\n",
    "        for idx in np.random.permutation(num_edge):\n",
    "            src, dst = edges[idx, :]\n",
    "            Q = xml_id_map[dst]\n",
    "            K = xml_id_map[src]\n",
    "            yield Q, K\n",
    "def negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list, neighbor_link_rate=0.8):\n",
    "    \n",
    "    \n",
    "    exist_node_list = xml_id_map.keys()\n",
    "    exist_N = len(training_node_list)\n",
    "    N = adj_mat.shape[0]\n",
    "    \n",
    "#     adj mat\n",
    "    links = np.array(list(map(idx_map.get, links.flatten())),\n",
    "                     dtype=np.int32).reshape(links.shape)\n",
    "    \n",
    "    adj_sp = sp.coo_matrix((np.ones(links.shape[0]), (links[:, 0], links[:, 1])),\n",
    "                        shape=(N, N),\n",
    "                        dtype=np.uint8)\n",
    "    adj_sp_2 = (sp.coo_matrix.dot(adj_sp,adj_sp) + adj_sp).tocoo()\n",
    "    \n",
    "    rev_map = {v:k for k,v in idx_map.items()}\n",
    "    adj_map = {i:[] for i in range(N)}\n",
    "    with tqdm(total=len(adj_sp_2.row)) as pbar:\n",
    "        for i,j,v in zip(adj_sp_2.row, adj_sp_2.col, adj_sp_2.data):\n",
    "            if adj_mat[i, j] != 1 and v == 1:\n",
    "                adj_map[i].append(j)\n",
    "            pbar.update(1)\n",
    "#             print i,N\n",
    "                \n",
    "    while True:\n",
    "        src = training_node_list[np.random.randint(exist_N)]\n",
    "        \n",
    "#         choose neighbor link\n",
    "        if np.random.rand(1) <= neighbor_link_rate:\n",
    "        \n",
    "            i = idx_map[src]\n",
    "            high = len(adj_map[i])\n",
    "            while high == 0:\n",
    "                src = training_node_list[np.random.randint(exist_N)]\n",
    "                i = idx_map[src]\n",
    "                high = len(adj_map[i])\n",
    "                \n",
    "            idx = np.random.randint(high)\n",
    "            dst = adj_map[i][idx]\n",
    "            dst = rev_map[dst]\n",
    "        else:\n",
    "            dst = training_node_list[np.random.randint(exist_N)]\n",
    "            while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "                dst = training_node_list[np.random.randint(exist_N)]\n",
    "        Q = xml_id_map[dst]\n",
    "        K = xml_id_map[src]\n",
    "        yield Q, K\n",
    "\n",
    "def val_data(edges, xml_id_map):\n",
    "    Q, K = [],[]\n",
    "    \n",
    "    for idx in range(edges.shape[0]):\n",
    "        src, dst = edges[idx, :]\n",
    "        q = xml_id_map[dst]\n",
    "        k = xml_id_map[src]\n",
    "        \n",
    "        Q.append(q)\n",
    "        K.append(k)\n",
    "        \n",
    "    Q = np.vstack(Q)\n",
    "    K = np.vstack(K)\n",
    "    \n",
    "    return Q, K\n",
    "    \n",
    "N = links.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "train_idx = idx[N//10:]\n",
    "val_idx = idx[:N//10]\n",
    "\n",
    "pos_G = positive_bootsrap_generator(links[train_idx,:], xml_id_map)\n",
    "training_node_list = list(set(links[train_idx,:].flatten().tolist()))\n",
    "neg_G = negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list)\n",
    "val_Q, val_K = val_data(links[val_idx,:], xml_id_map)\n",
    "q,k = next(pos_G)\n",
    "print(q.shape,k.shape)\n",
    "q,k = next(neg_G)\n",
    "print(q.shape,k.shape)\n",
    "print(val_Q.shape,val_K.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Transformer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Word_Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Multi_Head_attention_layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type PositionwiseFeedForward. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 0101', 'loss_train: 1.4029', 'acc_train: 0.4650', 'loss_val: 0.7021', 'acc_val: 0.5300', 'time: 19.3228s')\n",
      "('iter: 0201', 'loss_train: 1.4047', 'acc_train: 0.4375', 'loss_val: 0.6961', 'acc_val: 0.5650', 'time: 49.0655s')\n",
      "('iter: 0301', 'loss_train: 1.3993', 'acc_train: 0.4583', 'loss_val: 0.6951', 'acc_val: 0.5233', 'time: 70.0715s')\n",
      "('iter: 0401', 'loss_train: 1.3996', 'acc_train: 0.4662', 'loss_val: 0.6947', 'acc_val: 0.5300', 'time: 90.4702s')\n",
      "('iter: 0501', 'loss_train: 1.3966', 'acc_train: 0.4800', 'loss_val: 0.6946', 'acc_val: 0.5140', 'time: 109.6129s')\n",
      "('iter: 0601', 'loss_train: 1.3945', 'acc_train: 0.4850', 'loss_val: 0.6933', 'acc_val: 0.5367', 'time: 130.0137s')\n",
      "('iter: 0701', 'loss_train: 1.3940', 'acc_train: 0.5020', 'loss_val: 0.6926', 'acc_val: 0.5457', 'time: 151.5763s')\n",
      "('iter: 0801', 'loss_train: 1.3940', 'acc_train: 0.4990', 'loss_val: 0.6923', 'acc_val: 0.5463', 'time: 170.6986s')\n",
      "('iter: 0901', 'loss_train: 1.3936', 'acc_train: 0.4970', 'loss_val: 0.6921', 'acc_val: 0.5478', 'time: 190.3045s')\n",
      "('iter: 1001', 'loss_train: 1.3945', 'acc_train: 0.4790', 'loss_val: 0.6928', 'acc_val: 0.5350', 'time: 209.5317s')\n",
      "('iter: 1101', 'loss_train: 1.3928', 'acc_train: 0.4860', 'loss_val: 0.6919', 'acc_val: 0.5340', 'time: 229.3429s')\n",
      "('iter: 1201', 'loss_train: 1.3907', 'acc_train: 0.4930', 'loss_val: 0.6921', 'acc_val: 0.5260', 'time: 248.4823s')\n",
      "('iter: 1301', 'loss_train: 1.3904', 'acc_train: 0.5050', 'loss_val: 0.6918', 'acc_val: 0.5330', 'time: 268.3331s')\n",
      "('iter: 1401', 'loss_train: 1.3898', 'acc_train: 0.4990', 'loss_val: 0.6925', 'acc_val: 0.5070', 'time: 287.8109s')\n",
      "('iter: 1501', 'loss_train: 1.3905', 'acc_train: 0.5060', 'loss_val: 0.6916', 'acc_val: 0.5330', 'time: 308.2898s')\n",
      "('iter: 1601', 'loss_train: 1.3901', 'acc_train: 0.5070', 'loss_val: 0.6919', 'acc_val: 0.5170', 'time: 327.5411s')\n",
      "('iter: 1701', 'loss_train: 1.3901', 'acc_train: 0.4990', 'loss_val: 0.6917', 'acc_val: 0.5240', 'time: 346.6708s')\n",
      "('iter: 1801', 'loss_train: 1.3892', 'acc_train: 0.4910', 'loss_val: 0.6914', 'acc_val: 0.5340', 'time: 366.5116s')\n",
      "('iter: 1901', 'loss_train: 1.3886', 'acc_train: 0.5050', 'loss_val: 0.6912', 'acc_val: 0.5360', 'time: 385.6503s')\n",
      "('iter: 2001', 'loss_train: 1.3870', 'acc_train: 0.5090', 'loss_val: 0.6900', 'acc_val: 0.5440', 'time: 408.3961s')\n",
      "('iter: 2101', 'loss_train: 1.3884', 'acc_train: 0.4990', 'loss_val: 0.6904', 'acc_val: 0.5330', 'time: 428.2005s')\n",
      "('iter: 2201', 'loss_train: 1.3898', 'acc_train: 0.4940', 'loss_val: 0.6904', 'acc_val: 0.5310', 'time: 447.3813s')\n",
      "('iter: 2301', 'loss_train: 1.3900', 'acc_train: 0.4920', 'loss_val: 0.6899', 'acc_val: 0.5580', 'time: 467.5891s')\n",
      "('iter: 2401', 'loss_train: 1.3892', 'acc_train: 0.4870', 'loss_val: 0.6892', 'acc_val: 0.5810', 'time: 492.6206s')\n",
      "('iter: 2501', 'loss_train: 1.3888', 'acc_train: 0.4920', 'loss_val: 0.6900', 'acc_val: 0.5670', 'time: 511.8648s')\n",
      "('iter: 2601', 'loss_train: 1.3896', 'acc_train: 0.5020', 'loss_val: 0.6905', 'acc_val: 0.5640', 'time: 531.1154s')\n",
      "('iter: 2701', 'loss_train: 1.3887', 'acc_train: 0.5080', 'loss_val: 0.6914', 'acc_val: 0.5380', 'time: 550.3472s')\n",
      "('iter: 2801', 'loss_train: 1.3902', 'acc_train: 0.4980', 'loss_val: 0.6921', 'acc_val: 0.5270', 'time: 569.5773s')\n",
      "('iter: 2901', 'loss_train: 1.3908', 'acc_train: 0.4980', 'loss_val: 0.6924', 'acc_val: 0.5240', 'time: 588.8155s')\n",
      "('iter: 3001', 'loss_train: 1.3912', 'acc_train: 0.4890', 'loss_val: 0.6927', 'acc_val: 0.5420', 'time: 608.1141s')\n",
      "('iter: 3101', 'loss_train: 1.3897', 'acc_train: 0.4860', 'loss_val: 0.6923', 'acc_val: 0.5430', 'time: 627.5472s')\n",
      "('iter: 3201', 'loss_train: 1.3884', 'acc_train: 0.4900', 'loss_val: 0.6926', 'acc_val: 0.5340', 'time: 646.7814s')\n",
      "('iter: 3301', 'loss_train: 1.3889', 'acc_train: 0.4930', 'loss_val: 0.6934', 'acc_val: 0.5000', 'time: 666.0030s')\n",
      "('iter: 3401', 'loss_train: 1.3894', 'acc_train: 0.4900', 'loss_val: 0.6935', 'acc_val: 0.4890', 'time: 685.2271s')\n",
      "('iter: 3501', 'loss_train: 1.3891', 'acc_train: 0.5030', 'loss_val: 0.6935', 'acc_val: 0.4820', 'time: 704.4723s')\n",
      "('iter: 3601', 'loss_train: 1.3887', 'acc_train: 0.5050', 'loss_val: 0.6937', 'acc_val: 0.4740', 'time: 723.6936s')\n",
      "('iter: 3701', 'loss_train: 1.3883', 'acc_train: 0.5120', 'loss_val: 0.6933', 'acc_val: 0.4950', 'time: 742.9220s')\n",
      "('iter: 3801', 'loss_train: 1.3874', 'acc_train: 0.5190', 'loss_val: 0.6936', 'acc_val: 0.4670', 'time: 762.3527s')\n",
      "('iter: 3901', 'loss_train: 1.3876', 'acc_train: 0.5250', 'loss_val: 0.6939', 'acc_val: 0.4600', 'time: 781.5691s')\n",
      "('iter: 4001', 'loss_train: 1.3883', 'acc_train: 0.5060', 'loss_val: 0.6937', 'acc_val: 0.4750', 'time: 800.8206s')\n",
      "('iter: 4101', 'loss_train: 1.3887', 'acc_train: 0.5000', 'loss_val: 0.6936', 'acc_val: 0.4800', 'time: 820.0519s')\n",
      "('iter: 4201', 'loss_train: 1.3885', 'acc_train: 0.4870', 'loss_val: 0.6935', 'acc_val: 0.4780', 'time: 839.2826s')\n",
      "('iter: 4301', 'loss_train: 1.3876', 'acc_train: 0.4970', 'loss_val: 0.6935', 'acc_val: 0.4780', 'time: 858.6167s')\n",
      "('iter: 4401', 'loss_train: 1.3875', 'acc_train: 0.4940', 'loss_val: 0.6935', 'acc_val: 0.4820', 'time: 877.9616s')\n",
      "('iter: 4501', 'loss_train: 1.3879', 'acc_train: 0.4990', 'loss_val: 0.6937', 'acc_val: 0.4820', 'time: 898.1749s')\n",
      "('iter: 4601', 'loss_train: 1.3880', 'acc_train: 0.5060', 'loss_val: 0.6932', 'acc_val: 0.5070', 'time: 917.8870s')\n",
      "('iter: 4701', 'loss_train: 1.3889', 'acc_train: 0.5180', 'loss_val: 0.6929', 'acc_val: 0.5200', 'time: 937.1437s')\n",
      "('iter: 4801', 'loss_train: 1.3895', 'acc_train: 0.4980', 'loss_val: 0.6924', 'acc_val: 0.5560', 'time: 956.4101s')\n",
      "('iter: 4901', 'loss_train: 1.3895', 'acc_train: 0.4910', 'loss_val: 0.6918', 'acc_val: 0.5670', 'time: 975.9113s')\n",
      "('iter: 5001', 'loss_train: 1.3885', 'acc_train: 0.4910', 'loss_val: 0.6926', 'acc_val: 0.5230', 'time: 996.1256s')\n",
      "('iter: 5101', 'loss_train: 1.3883', 'acc_train: 0.4920', 'loss_val: 0.6929', 'acc_val: 0.5140', 'time: 1016.2353s')\n",
      "('iter: 5201', 'loss_train: 1.3890', 'acc_train: 0.4720', 'loss_val: 0.6924', 'acc_val: 0.5450', 'time: 1035.7140s')\n",
      "('iter: 5301', 'loss_train: 1.3893', 'acc_train: 0.4890', 'loss_val: 0.6921', 'acc_val: 0.5670', 'time: 1055.3410s')\n",
      "('iter: 5401', 'loss_train: 1.3887', 'acc_train: 0.4980', 'loss_val: 0.6918', 'acc_val: 0.5760', 'time: 1074.9860s')\n",
      "('iter: 5501', 'loss_train: 1.3884', 'acc_train: 0.5140', 'loss_val: 0.6919', 'acc_val: 0.5660', 'time: 1095.1751s')\n",
      "('iter: 5601', 'loss_train: 1.3885', 'acc_train: 0.5070', 'loss_val: 0.6919', 'acc_val: 0.5620', 'time: 1115.4078s')\n",
      "('iter: 5701', 'loss_train: 1.3883', 'acc_train: 0.5220', 'loss_val: 0.6925', 'acc_val: 0.5290', 'time: 1134.5598s')\n",
      "('iter: 5801', 'loss_train: 1.3868', 'acc_train: 0.5300', 'loss_val: 0.6919', 'acc_val: 0.5510', 'time: 1155.0224s')\n",
      "('iter: 5901', 'loss_train: 1.3865', 'acc_train: 0.5320', 'loss_val: 0.6923', 'acc_val: 0.5360', 'time: 1175.3427s')\n",
      "('iter: 6001', 'loss_train: 1.3866', 'acc_train: 0.5190', 'loss_val: 0.6920', 'acc_val: 0.5520', 'time: 1195.8306s')\n",
      "('iter: 6101', 'loss_train: 1.3859', 'acc_train: 0.5330', 'loss_val: 0.6919', 'acc_val: 0.5640', 'time: 1215.0715s')\n",
      "('iter: 6201', 'loss_train: 1.3856', 'acc_train: 0.5240', 'loss_val: 0.6921', 'acc_val: 0.5550', 'time: 1234.5500s')\n",
      "('iter: 6301', 'loss_train: 1.3855', 'acc_train: 0.5150', 'loss_val: 0.6923', 'acc_val: 0.5420', 'time: 1253.9216s')\n",
      "('iter: 6401', 'loss_train: 1.3858', 'acc_train: 0.5190', 'loss_val: 0.6926', 'acc_val: 0.5220', 'time: 1274.2921s')\n",
      "('iter: 6501', 'loss_train: 1.3866', 'acc_train: 0.5160', 'loss_val: 0.6924', 'acc_val: 0.5340', 'time: 1293.6566s')\n",
      "('iter: 6601', 'loss_train: 1.3868', 'acc_train: 0.5000', 'loss_val: 0.6921', 'acc_val: 0.5370', 'time: 1312.8841s')\n",
      "('iter: 6701', 'loss_train: 1.3871', 'acc_train: 0.5050', 'loss_val: 0.6920', 'acc_val: 0.5480', 'time: 1332.6978s')\n",
      "('iter: 6801', 'loss_train: 1.3882', 'acc_train: 0.4870', 'loss_val: 0.6926', 'acc_val: 0.5190', 'time: 1352.3850s')\n",
      "('iter: 6901', 'loss_train: 1.3882', 'acc_train: 0.4810', 'loss_val: 0.6927', 'acc_val: 0.5090', 'time: 1371.6686s')\n",
      "('iter: 7001', 'loss_train: 1.3871', 'acc_train: 0.4900', 'loss_val: 0.6924', 'acc_val: 0.5310', 'time: 1390.9435s')\n",
      "('iter: 7101', 'loss_train: 1.3880', 'acc_train: 0.4990', 'loss_val: 0.6921', 'acc_val: 0.5450', 'time: 1410.6554s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 7201', 'loss_train: 1.3881', 'acc_train: 0.4990', 'loss_val: 0.6921', 'acc_val: 0.5370', 'time: 1431.3805s')\n",
      "('iter: 7301', 'loss_train: 1.3883', 'acc_train: 0.5050', 'loss_val: 0.6920', 'acc_val: 0.5440', 'time: 1451.8062s')\n",
      "('iter: 7401', 'loss_train: 1.3882', 'acc_train: 0.5030', 'loss_val: 0.6915', 'acc_val: 0.5730', 'time: 1472.3266s')\n",
      "('iter: 7501', 'loss_train: 1.3882', 'acc_train: 0.4950', 'loss_val: 0.6919', 'acc_val: 0.5570', 'time: 1493.2076s')\n",
      "('iter: 7601', 'loss_train: 1.3876', 'acc_train: 0.5040', 'loss_val: 0.6919', 'acc_val: 0.5700', 'time: 1514.2270s')\n",
      "('iter: 7701', 'loss_train: 1.3869', 'acc_train: 0.5120', 'loss_val: 0.6913', 'acc_val: 0.5990', 'time: 1536.3868s')\n",
      "('iter: 7801', 'loss_train: 1.3865', 'acc_train: 0.5220', 'loss_val: 0.6914', 'acc_val: 0.5940', 'time: 1557.6656s')\n",
      "('iter: 7901', 'loss_train: 1.3868', 'acc_train: 0.5170', 'loss_val: 0.6913', 'acc_val: 0.6040', 'time: 1577.9057s')\n",
      "('iter: 8001', 'loss_train: 1.3879', 'acc_train: 0.5270', 'loss_val: 0.6915', 'acc_val: 0.5900', 'time: 1598.2019s')\n",
      "('iter: 8101', 'loss_train: 1.3882', 'acc_train: 0.5060', 'loss_val: 0.6918', 'acc_val: 0.5550', 'time: 1618.2903s')\n",
      "('iter: 8201', 'loss_train: 1.3876', 'acc_train: 0.5010', 'loss_val: 0.6915', 'acc_val: 0.5840', 'time: 1639.0944s')\n",
      "('iter: 8301', 'loss_train: 1.3877', 'acc_train: 0.5020', 'loss_val: 0.6913', 'acc_val: 0.5890', 'time: 1658.6382s')\n",
      "('iter: 8401', 'loss_train: 1.3873', 'acc_train: 0.5130', 'loss_val: 0.6917', 'acc_val: 0.5760', 'time: 1677.7753s')\n",
      "('iter: 8501', 'loss_train: 1.3869', 'acc_train: 0.5080', 'loss_val: 0.6915', 'acc_val: 0.5870', 'time: 1697.0292s')\n",
      "('iter: 8601', 'loss_train: 1.3871', 'acc_train: 0.5110', 'loss_val: 0.6916', 'acc_val: 0.5800', 'time: 1716.3125s')\n",
      "('iter: 8701', 'loss_train: 1.3880', 'acc_train: 0.4950', 'loss_val: 0.6921', 'acc_val: 0.5470', 'time: 1735.4595s')\n",
      "('iter: 8801', 'loss_train: 1.3878', 'acc_train: 0.4890', 'loss_val: 0.6921', 'acc_val: 0.5360', 'time: 1754.6265s')\n",
      "('iter: 8901', 'loss_train: 1.3874', 'acc_train: 0.4910', 'loss_val: 0.6926', 'acc_val: 0.4970', 'time: 1773.8133s')\n",
      "('iter: 9001', 'loss_train: 1.3863', 'acc_train: 0.4940', 'loss_val: 0.6929', 'acc_val: 0.4750', 'time: 1793.1936s')\n",
      "('iter: 9101', 'loss_train: 1.3864', 'acc_train: 0.4930', 'loss_val: 0.6927', 'acc_val: 0.4930', 'time: 1812.5435s')\n",
      "('iter: 9201', 'loss_train: 1.3861', 'acc_train: 0.5140', 'loss_val: 0.6929', 'acc_val: 0.4770', 'time: 1832.0562s')\n",
      "('iter: 9301', 'loss_train: 1.3865', 'acc_train: 0.5180', 'loss_val: 0.6930', 'acc_val: 0.4570', 'time: 1851.3364s')\n",
      "('iter: 9401', 'loss_train: 1.3868', 'acc_train: 0.5120', 'loss_val: 0.6931', 'acc_val: 0.4530', 'time: 1870.6386s')\n",
      "('iter: 9501', 'loss_train: 1.3873', 'acc_train: 0.5010', 'loss_val: 0.6931', 'acc_val: 0.4570', 'time: 1889.9537s')\n",
      "('iter: 9601', 'loss_train: 1.3874', 'acc_train: 0.5060', 'loss_val: 0.6935', 'acc_val: 0.4350', 'time: 1909.8180s')\n",
      "('iter: 9701', 'loss_train: 1.3866', 'acc_train: 0.5010', 'loss_val: 0.6935', 'acc_val: 0.4470', 'time: 1930.9040s')\n",
      "('iter: 9801', 'loss_train: 1.3870', 'acc_train: 0.4810', 'loss_val: 0.6938', 'acc_val: 0.4420', 'time: 1952.0491s')\n",
      "('iter: 9901', 'loss_train: 1.3872', 'acc_train: 0.4730', 'loss_val: 0.6931', 'acc_val: 0.5030', 'time: 1972.8787s')\n",
      "('iter: 10001', 'loss_train: 1.3878', 'acc_train: 0.4810', 'loss_val: 0.6929', 'acc_val: 0.5230', 'time: 1993.5754s')\n",
      "('iter: 10101', 'loss_train: 1.3873', 'acc_train: 0.4850', 'loss_val: 0.6930', 'acc_val: 0.5300', 'time: 2013.0809s')\n",
      "('iter: 10201', 'loss_train: 1.3881', 'acc_train: 0.4780', 'loss_val: 0.6931', 'acc_val: 0.5250', 'time: 2032.2811s')\n",
      "('iter: 10301', 'loss_train: 1.3879', 'acc_train: 0.4880', 'loss_val: 0.6933', 'acc_val: 0.5170', 'time: 2051.4381s')\n",
      "('iter: 10401', 'loss_train: 1.3875', 'acc_train: 0.4920', 'loss_val: 0.6931', 'acc_val: 0.5240', 'time: 2070.6230s')\n",
      "('iter: 10501', 'loss_train: 1.3872', 'acc_train: 0.4900', 'loss_val: 0.6934', 'acc_val: 0.5040', 'time: 2090.0342s')\n",
      "('iter: 10601', 'loss_train: 1.3873', 'acc_train: 0.4870', 'loss_val: 0.6933', 'acc_val: 0.5000', 'time: 2109.2854s')\n",
      "('iter: 10701', 'loss_train: 1.3879', 'acc_train: 0.4910', 'loss_val: 0.6934', 'acc_val: 0.4900', 'time: 2128.4279s')\n",
      "('iter: 10801', 'loss_train: 1.3867', 'acc_train: 0.5090', 'loss_val: 0.6931', 'acc_val: 0.5060', 'time: 2148.5032s')\n",
      "('iter: 10901', 'loss_train: 1.3867', 'acc_train: 0.5050', 'loss_val: 0.6932', 'acc_val: 0.4900', 'time: 2168.1972s')\n",
      "('iter: 11001', 'loss_train: 1.3864', 'acc_train: 0.5080', 'loss_val: 0.6930', 'acc_val: 0.5010', 'time: 2187.3395s')\n",
      "('iter: 11101', 'loss_train: 1.3861', 'acc_train: 0.5040', 'loss_val: 0.6934', 'acc_val: 0.4870', 'time: 2206.7775s')\n",
      "('iter: 11201', 'loss_train: 1.3851', 'acc_train: 0.5110', 'loss_val: 0.6935', 'acc_val: 0.4760', 'time: 2227.1257s')\n",
      "('iter: 11301', 'loss_train: 1.3850', 'acc_train: 0.4990', 'loss_val: 0.6934', 'acc_val: 0.4870', 'time: 2246.9053s')\n",
      "('iter: 11401', 'loss_train: 1.3854', 'acc_train: 0.5050', 'loss_val: 0.6936', 'acc_val: 0.4820', 'time: 2266.2330s')\n",
      "('iter: 11501', 'loss_train: 1.3846', 'acc_train: 0.5150', 'loss_val: 0.6929', 'acc_val: 0.5110', 'time: 2285.8101s')\n",
      "('iter: 11601', 'loss_train: 1.3851', 'acc_train: 0.5090', 'loss_val: 0.6930', 'acc_val: 0.5150', 'time: 2305.4519s')\n",
      "('iter: 11701', 'loss_train: 1.3857', 'acc_train: 0.4960', 'loss_val: 0.6930', 'acc_val: 0.5160', 'time: 2324.6670s')\n",
      "('iter: 11801', 'loss_train: 1.3869', 'acc_train: 0.4870', 'loss_val: 0.6929', 'acc_val: 0.5260', 'time: 2343.8487s')\n",
      "('iter: 11901', 'loss_train: 1.3866', 'acc_train: 0.4900', 'loss_val: 0.6928', 'acc_val: 0.5610', 'time: 2363.1649s')\n",
      "('iter: 12001', 'loss_train: 1.3869', 'acc_train: 0.4800', 'loss_val: 0.6932', 'acc_val: 0.5280', 'time: 2382.4223s')\n",
      "('iter: 12101', 'loss_train: 1.3877', 'acc_train: 0.4840', 'loss_val: 0.6931', 'acc_val: 0.5310', 'time: 2401.6735s')\n",
      "('iter: 12201', 'loss_train: 1.3884', 'acc_train: 0.4890', 'loss_val: 0.6928', 'acc_val: 0.5510', 'time: 2420.8825s')\n",
      "('iter: 12301', 'loss_train: 1.3879', 'acc_train: 0.5020', 'loss_val: 0.6927', 'acc_val: 0.5590', 'time: 2440.2025s')\n",
      "('iter: 12401', 'loss_train: 1.3881', 'acc_train: 0.4940', 'loss_val: 0.6925', 'acc_val: 0.5610', 'time: 2459.4041s')\n",
      "('iter: 12501', 'loss_train: 1.3889', 'acc_train: 0.4930', 'loss_val: 0.6929', 'acc_val: 0.5680', 'time: 2478.6128s')\n",
      "('iter: 12601', 'loss_train: 1.3885', 'acc_train: 0.4870', 'loss_val: 0.6928', 'acc_val: 0.5610', 'time: 2497.8091s')\n",
      "('iter: 12701', 'loss_train: 1.3880', 'acc_train: 0.4840', 'loss_val: 0.6928', 'acc_val: 0.5470', 'time: 2517.1089s')\n",
      "('iter: 12801', 'loss_train: 1.3872', 'acc_train: 0.4970', 'loss_val: 0.6927', 'acc_val: 0.5510', 'time: 2536.3392s')\n",
      "('iter: 12901', 'loss_train: 1.3872', 'acc_train: 0.5150', 'loss_val: 0.6931', 'acc_val: 0.5150', 'time: 2555.5373s')\n",
      "('iter: 13001', 'loss_train: 1.3869', 'acc_train: 0.5280', 'loss_val: 0.6930', 'acc_val: 0.5360', 'time: 2574.9552s')\n",
      "('iter: 13101', 'loss_train: 1.3866', 'acc_train: 0.5300', 'loss_val: 0.6928', 'acc_val: 0.5470', 'time: 2594.8846s')\n",
      "('iter: 13201', 'loss_train: 1.3869', 'acc_train: 0.5350', 'loss_val: 0.6931', 'acc_val: 0.5200', 'time: 2615.1345s')\n",
      "('iter: 13301', 'loss_train: 1.3869', 'acc_train: 0.5290', 'loss_val: 0.6930', 'acc_val: 0.5160', 'time: 2635.4291s')\n",
      "('iter: 13401', 'loss_train: 1.3868', 'acc_train: 0.5170', 'loss_val: 0.6931', 'acc_val: 0.5140', 'time: 2655.8361s')\n",
      "('iter: 13501', 'loss_train: 1.3867', 'acc_train: 0.5040', 'loss_val: 0.6933', 'acc_val: 0.4910', 'time: 2676.1164s')\n",
      "('iter: 13601', 'loss_train: 1.3863', 'acc_train: 0.5080', 'loss_val: 0.6930', 'acc_val: 0.5160', 'time: 2696.3962s')\n",
      "('iter: 13701', 'loss_train: 1.3859', 'acc_train: 0.5060', 'loss_val: 0.6929', 'acc_val: 0.5320', 'time: 2716.8852s')\n",
      "('iter: 13801', 'loss_train: 1.3859', 'acc_train: 0.5040', 'loss_val: 0.6929', 'acc_val: 0.5230', 'time: 2741.5467s')\n",
      "('iter: 13901', 'loss_train: 1.3863', 'acc_train: 0.5040', 'loss_val: 0.6931', 'acc_val: 0.5090', 'time: 2776.3350s')\n",
      "('iter: 14001', 'loss_train: 1.3871', 'acc_train: 0.4890', 'loss_val: 0.6931', 'acc_val: 0.5080', 'time: 2810.7964s')\n",
      "('iter: 14101', 'loss_train: 1.3871', 'acc_train: 0.4910', 'loss_val: 0.6931', 'acc_val: 0.5130', 'time: 2845.5249s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 14201', 'loss_train: 1.3870', 'acc_train: 0.4900', 'loss_val: 0.6933', 'acc_val: 0.4970', 'time: 2880.2474s')\n",
      "('iter: 14301', 'loss_train: 1.3871', 'acc_train: 0.4800', 'loss_val: 0.6934', 'acc_val: 0.5040', 'time: 2909.9726s')\n",
      "('iter: 14401', 'loss_train: 1.3872', 'acc_train: 0.4800', 'loss_val: 0.6934', 'acc_val: 0.4990', 'time: 2929.1637s')\n",
      "('iter: 14501', 'loss_train: 1.3870', 'acc_train: 0.4890', 'loss_val: 0.6933', 'acc_val: 0.5150', 'time: 2948.4127s')\n",
      "('iter: 14601', 'loss_train: 1.3872', 'acc_train: 0.4930', 'loss_val: 0.6934', 'acc_val: 0.5110', 'time: 2967.6139s')\n",
      "('iter: 14701', 'loss_train: 1.3872', 'acc_train: 0.5040', 'loss_val: 0.6930', 'acc_val: 0.5380', 'time: 2986.8131s')\n",
      "('iter: 14801', 'loss_train: 1.3872', 'acc_train: 0.5160', 'loss_val: 0.6933', 'acc_val: 0.5290', 'time: 3006.0529s')\n",
      "('iter: 14901', 'loss_train: 1.3871', 'acc_train: 0.5140', 'loss_val: 0.6928', 'acc_val: 0.5690', 'time: 3025.4974s')\n",
      "('iter: 15001', 'loss_train: 1.3864', 'acc_train: 0.5210', 'loss_val: 0.6929', 'acc_val: 0.5530', 'time: 3044.7296s')\n",
      "('iter: 15101', 'loss_train: 1.3862', 'acc_train: 0.5220', 'loss_val: 0.6928', 'acc_val: 0.5500', 'time: 3064.0492s')\n",
      "('iter: 15201', 'loss_train: 1.3861', 'acc_train: 0.5130', 'loss_val: 0.6924', 'acc_val: 0.5940', 'time: 3083.4186s')\n",
      "('iter: 15301', 'loss_train: 1.3865', 'acc_train: 0.4920', 'loss_val: 0.6923', 'acc_val: 0.5810', 'time: 3102.7050s')\n",
      "('iter: 15401', 'loss_train: 1.3863', 'acc_train: 0.5030', 'loss_val: 0.6923', 'acc_val: 0.5870', 'time: 3121.9556s')\n",
      "('iter: 15501', 'loss_train: 1.3864', 'acc_train: 0.5090', 'loss_val: 0.6925', 'acc_val: 0.5730', 'time: 3141.2345s')\n",
      "('iter: 15601', 'loss_train: 1.3866', 'acc_train: 0.5000', 'loss_val: 0.6926', 'acc_val: 0.5410', 'time: 3160.5609s')\n",
      "('iter: 15701', 'loss_train: 1.3868', 'acc_train: 0.5040', 'loss_val: 0.6930', 'acc_val: 0.5030', 'time: 3179.8062s')\n",
      "('iter: 15801', 'loss_train: 1.3871', 'acc_train: 0.5170', 'loss_val: 0.6929', 'acc_val: 0.5080', 'time: 3199.1382s')\n",
      "('iter: 15901', 'loss_train: 1.3871', 'acc_train: 0.5080', 'loss_val: 0.6932', 'acc_val: 0.4880', 'time: 3218.4451s')\n",
      "('iter: 16001', 'loss_train: 1.3874', 'acc_train: 0.5030', 'loss_val: 0.6931', 'acc_val: 0.4910', 'time: 3237.8924s')\n",
      "('iter: 16101', 'loss_train: 1.3874', 'acc_train: 0.4990', 'loss_val: 0.6933', 'acc_val: 0.4850', 'time: 3257.1715s')\n",
      "('iter: 16201', 'loss_train: 1.3874', 'acc_train: 0.4970', 'loss_val: 0.6935', 'acc_val: 0.4530', 'time: 3277.0443s')\n",
      "('iter: 16301', 'loss_train: 1.3869', 'acc_train: 0.4920', 'loss_val: 0.6937', 'acc_val: 0.4490', 'time: 3297.3384s')\n",
      "('iter: 16401', 'loss_train: 1.3869', 'acc_train: 0.4900', 'loss_val: 0.6936', 'acc_val: 0.4540', 'time: 3317.0924s')\n",
      "('iter: 16501', 'loss_train: 1.3868', 'acc_train: 0.4890', 'loss_val: 0.6936', 'acc_val: 0.4560', 'time: 3336.3271s')\n",
      "('iter: 16601', 'loss_train: 1.3869', 'acc_train: 0.4850', 'loss_val: 0.6933', 'acc_val: 0.4870', 'time: 3355.4995s')\n",
      "('iter: 16701', 'loss_train: 1.3871', 'acc_train: 0.4800', 'loss_val: 0.6933', 'acc_val: 0.5040', 'time: 3374.7761s')\n",
      "('iter: 16801', 'loss_train: 1.3869', 'acc_train: 0.4820', 'loss_val: 0.6934', 'acc_val: 0.4960', 'time: 3393.9608s')\n",
      "('iter: 16901', 'loss_train: 1.3868', 'acc_train: 0.4930', 'loss_val: 0.6932', 'acc_val: 0.5070', 'time: 3413.1667s')\n",
      "('iter: 17001', 'loss_train: 1.3867', 'acc_train: 0.4980', 'loss_val: 0.6932', 'acc_val: 0.5090', 'time: 3432.4776s')\n",
      "('iter: 17101', 'loss_train: 1.3865', 'acc_train: 0.5170', 'loss_val: 0.6934', 'acc_val: 0.4800', 'time: 3451.8776s')\n",
      "('iter: 17201', 'loss_train: 1.3866', 'acc_train: 0.5160', 'loss_val: 0.6933', 'acc_val: 0.4950', 'time: 3471.1133s')\n",
      "('iter: 17301', 'loss_train: 1.3864', 'acc_train: 0.5220', 'loss_val: 0.6931', 'acc_val: 0.5120', 'time: 3490.5198s')\n",
      "('iter: 17401', 'loss_train: 1.3866', 'acc_train: 0.5040', 'loss_val: 0.6932', 'acc_val: 0.5000', 'time: 3510.6345s')\n",
      "('iter: 17501', 'loss_train: 1.3865', 'acc_train: 0.4930', 'loss_val: 0.6930', 'acc_val: 0.5080', 'time: 3529.8445s')\n",
      "('iter: 17601', 'loss_train: 1.3863', 'acc_train: 0.4840', 'loss_val: 0.6933', 'acc_val: 0.4710', 'time: 3549.8895s')\n",
      "('iter: 17701', 'loss_train: 1.3861', 'acc_train: 0.4870', 'loss_val: 0.6933', 'acc_val: 0.4610', 'time: 3570.3024s')\n",
      "('iter: 17801', 'loss_train: 1.3863', 'acc_train: 0.4820', 'loss_val: 0.6933', 'acc_val: 0.4660', 'time: 3589.5451s')\n",
      "('iter: 17901', 'loss_train: 1.3864', 'acc_train: 0.4910', 'loss_val: 0.6936', 'acc_val: 0.4270', 'time: 3608.8002s')\n",
      "('iter: 18001', 'loss_train: 1.3862', 'acc_train: 0.5070', 'loss_val: 0.6936', 'acc_val: 0.4430', 'time: 3628.6425s')\n",
      "('iter: 18101', 'loss_train: 1.3863', 'acc_train: 0.5030', 'loss_val: 0.6934', 'acc_val: 0.4780', 'time: 3647.8632s')\n",
      "('iter: 18201', 'loss_train: 1.3861', 'acc_train: 0.5140', 'loss_val: 0.6934', 'acc_val: 0.4710', 'time: 3667.0887s')\n",
      "('iter: 18301', 'loss_train: 1.3864', 'acc_train: 0.5090', 'loss_val: 0.6937', 'acc_val: 0.4540', 'time: 3686.2766s')\n",
      "('iter: 18401', 'loss_train: 1.3864', 'acc_train: 0.5010', 'loss_val: 0.6936', 'acc_val: 0.4670', 'time: 3705.5754s')\n",
      "('iter: 18501', 'loss_train: 1.3862', 'acc_train: 0.4950', 'loss_val: 0.6939', 'acc_val: 0.4560', 'time: 3724.8641s')\n",
      "('iter: 18601', 'loss_train: 1.3863', 'acc_train: 0.4980', 'loss_val: 0.6939', 'acc_val: 0.4700', 'time: 3744.1847s')\n",
      "('iter: 18701', 'loss_train: 1.3862', 'acc_train: 0.4920', 'loss_val: 0.6940', 'acc_val: 0.4610', 'time: 3763.4689s')\n",
      "('iter: 18801', 'loss_train: 1.3859', 'acc_train: 0.5060', 'loss_val: 0.6938', 'acc_val: 0.4860', 'time: 3782.7786s')\n",
      "('iter: 18901', 'loss_train: 1.3859', 'acc_train: 0.5070', 'loss_val: 0.6938', 'acc_val: 0.4910', 'time: 3802.0509s')\n",
      "('iter: 19001', 'loss_train: 1.3864', 'acc_train: 0.5000', 'loss_val: 0.6940', 'acc_val: 0.4580', 'time: 3823.3635s')\n",
      "('iter: 19101', 'loss_train: 1.3868', 'acc_train: 0.4980', 'loss_val: 0.6942', 'acc_val: 0.4430', 'time: 3847.9142s')\n",
      "('iter: 19201', 'loss_train: 1.3871', 'acc_train: 0.4940', 'loss_val: 0.6942', 'acc_val: 0.4360', 'time: 3871.0881s')\n",
      "('iter: 19301', 'loss_train: 1.3873', 'acc_train: 0.4800', 'loss_val: 0.6940', 'acc_val: 0.4670', 'time: 3894.5846s')\n",
      "('iter: 19401', 'loss_train: 1.3871', 'acc_train: 0.4890', 'loss_val: 0.6938', 'acc_val: 0.4820', 'time: 3917.8906s')\n",
      "('iter: 19501', 'loss_train: 1.3876', 'acc_train: 0.4840', 'loss_val: 0.6937', 'acc_val: 0.5070', 'time: 3941.2100s')\n",
      "('iter: 19601', 'loss_train: 1.3872', 'acc_train: 0.4960', 'loss_val: 0.6936', 'acc_val: 0.5070', 'time: 3964.5274s')\n",
      "('iter: 19701', 'loss_train: 1.3872', 'acc_train: 0.4960', 'loss_val: 0.6936', 'acc_val: 0.4970', 'time: 3987.6849s')\n",
      "('iter: 19801', 'loss_train: 1.3875', 'acc_train: 0.5010', 'loss_val: 0.6937', 'acc_val: 0.4910', 'time: 4011.3953s')\n",
      "('iter: 19901', 'loss_train: 1.3873', 'acc_train: 0.4980', 'loss_val: 0.6933', 'acc_val: 0.5210', 'time: 4034.9233s')\n",
      "('iter: 20001', 'loss_train: 1.3872', 'acc_train: 0.5050', 'loss_val: 0.6930', 'acc_val: 0.5550', 'time: 4058.3625s')\n",
      "('iter: 20101', 'loss_train: 1.3867', 'acc_train: 0.4960', 'loss_val: 0.6928', 'acc_val: 0.5680', 'time: 4082.1545s')\n",
      "('iter: 20201', 'loss_train: 1.3865', 'acc_train: 0.5100', 'loss_val: 0.6928', 'acc_val: 0.5670', 'time: 4105.8901s')\n",
      "('iter: 20301', 'loss_train: 1.3861', 'acc_train: 0.5180', 'loss_val: 0.6929', 'acc_val: 0.5370', 'time: 4129.2705s')\n",
      "('iter: 20401', 'loss_train: 1.3858', 'acc_train: 0.5220', 'loss_val: 0.6925', 'acc_val: 0.5380', 'time: 4152.6927s')\n",
      "('iter: 20501', 'loss_train: 1.3855', 'acc_train: 0.5330', 'loss_val: 0.6932', 'acc_val: 0.5250', 'time: 4176.2467s')\n",
      "('iter: 20601', 'loss_train: 1.3861', 'acc_train: 0.5310', 'loss_val: 0.6933', 'acc_val: 0.5340', 'time: 4199.5641s')\n",
      "('iter: 20701', 'loss_train: 1.3865', 'acc_train: 0.5080', 'loss_val: 0.6930', 'acc_val: 0.5860', 'time: 4223.0696s')\n",
      "('iter: 20801', 'loss_train: 1.3861', 'acc_train: 0.5010', 'loss_val: 0.6931', 'acc_val: 0.5780', 'time: 4246.3214s')\n",
      "('iter: 20901', 'loss_train: 1.3863', 'acc_train: 0.4880', 'loss_val: 0.6932', 'acc_val: 0.5620', 'time: 4269.6270s')\n",
      "('iter: 21001', 'loss_train: 1.3866', 'acc_train: 0.4700', 'loss_val: 0.6934', 'acc_val: 0.5420', 'time: 4292.9743s')\n",
      "('iter: 21101', 'loss_train: 1.3866', 'acc_train: 0.4790', 'loss_val: 0.6935', 'acc_val: 0.5330', 'time: 4316.5269s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 21201', 'loss_train: 1.3868', 'acc_train: 0.4850', 'loss_val: 0.6934', 'acc_val: 0.5320', 'time: 4340.1002s')\n",
      "('iter: 21301', 'loss_train: 1.3866', 'acc_train: 0.4950', 'loss_val: 0.6934', 'acc_val: 0.5360', 'time: 4363.6942s')\n",
      "('iter: 21401', 'loss_train: 1.3870', 'acc_train: 0.5100', 'loss_val: 0.6940', 'acc_val: 0.5080', 'time: 4387.4436s')\n",
      "('iter: 21501', 'loss_train: 1.3845', 'acc_train: 0.5400', 'loss_val: 0.6932', 'acc_val: 0.4950', 'time: 4411.2327s')\n",
      "('iter: 21601', 'loss_train: 1.3796', 'acc_train: 0.5600', 'loss_val: 0.6905', 'acc_val: 0.4950', 'time: 4434.8402s')\n",
      "('iter: 21701', 'loss_train: 1.3758', 'acc_train: 0.5810', 'loss_val: 0.6903', 'acc_val: 0.4470', 'time: 4459.5475s')\n",
      "('iter: 21801', 'loss_train: 1.3761', 'acc_train: 0.5810', 'loss_val: 0.6884', 'acc_val: 0.4260', 'time: 4483.4564s')\n",
      "('iter: 21901', 'loss_train: 1.3749', 'acc_train: 0.5860', 'loss_val: 0.6871', 'acc_val: 0.4190', 'time: 4508.4862s')\n",
      "('iter: 22001', 'loss_train: 1.3723', 'acc_train: 0.5780', 'loss_val: 0.6880', 'acc_val: 0.4080', 'time: 4532.3697s')\n",
      "('iter: 22101', 'loss_train: 1.3696', 'acc_train: 0.5710', 'loss_val: 0.6882', 'acc_val: 0.3980', 'time: 4555.9698s')\n",
      "('iter: 22201', 'loss_train: 1.3649', 'acc_train: 0.5750', 'loss_val: 0.6871', 'acc_val: 0.4010', 'time: 4580.6166s')\n",
      "('iter: 22301', 'loss_train: 1.3654', 'acc_train: 0.5710', 'loss_val: 0.6835', 'acc_val: 0.3850', 'time: 4606.1616s')\n",
      "('iter: 22401', 'loss_train: 1.3651', 'acc_train: 0.5680', 'loss_val: 0.6833', 'acc_val: 0.3780', 'time: 4630.3729s')\n",
      "('iter: 22501', 'loss_train: 1.3662', 'acc_train: 0.5650', 'loss_val: 0.6840', 'acc_val: 0.3710', 'time: 4653.8977s')\n",
      "('iter: 22601', 'loss_train: 1.3644', 'acc_train: 0.5740', 'loss_val: 0.6859', 'acc_val: 0.3620', 'time: 4678.4107s')\n",
      "('iter: 22701', 'loss_train: 1.3642', 'acc_train: 0.5720', 'loss_val: 0.6825', 'acc_val: 0.3700', 'time: 4703.5599s')\n",
      "('iter: 22801', 'loss_train: 1.3612', 'acc_train: 0.5830', 'loss_val: 0.6834', 'acc_val: 0.3680', 'time: 4727.6875s')\n",
      "('iter: 22901', 'loss_train: 1.3615', 'acc_train: 0.5870', 'loss_val: 0.6809', 'acc_val: 0.3740', 'time: 4751.7349s')\n",
      "('iter: 23001', 'loss_train: 1.3621', 'acc_train: 0.5870', 'loss_val: 0.6775', 'acc_val: 0.3780', 'time: 4779.2146s')\n",
      "('iter: 23101', 'loss_train: 1.3585', 'acc_train: 0.5870', 'loss_val: 0.6805', 'acc_val: 0.3760', 'time: 4803.0611s')\n",
      "('iter: 23201', 'loss_train: 1.3607', 'acc_train: 0.5850', 'loss_val: 0.6775', 'acc_val: 0.3740', 'time: 4827.0383s')\n",
      "('iter: 23301', 'loss_train: 1.3566', 'acc_train: 0.5860', 'loss_val: 0.6788', 'acc_val: 0.3790', 'time: 4851.2161s')\n",
      "('iter: 23401', 'loss_train: 1.3566', 'acc_train: 0.5840', 'loss_val: 0.6748', 'acc_val: 0.3840', 'time: 4878.1393s')\n",
      "('iter: 23501', 'loss_train: 1.3581', 'acc_train: 0.5760', 'loss_val: 0.6716', 'acc_val: 0.3830', 'time: 4908.1398s')\n",
      "('iter: 23601', 'loss_train: 1.3644', 'acc_train: 0.5560', 'loss_val: 0.6717', 'acc_val: 0.3780', 'time: 4933.8712s')\n",
      "('iter: 23701', 'loss_train: 1.3644', 'acc_train: 0.5580', 'loss_val: 0.6751', 'acc_val: 0.3640', 'time: 4957.6077s')\n",
      "('iter: 23801', 'loss_train: 1.3654', 'acc_train: 0.5530', 'loss_val: 0.6762', 'acc_val: 0.3530', 'time: 4981.7914s')\n",
      "('iter: 23901', 'loss_train: 1.3642', 'acc_train: 0.5580', 'loss_val: 0.6832', 'acc_val: 0.3280', 'time: 5005.8809s')\n",
      "('iter: 24001', 'loss_train: 1.3649', 'acc_train: 0.5640', 'loss_val: 0.6834', 'acc_val: 0.3260', 'time: 5029.6891s')\n",
      "('iter: 24101', 'loss_train: 1.3687', 'acc_train: 0.5730', 'loss_val: 0.6798', 'acc_val: 0.3290', 'time: 5053.9061s')\n",
      "('iter: 24201', 'loss_train: 1.3640', 'acc_train: 0.5790', 'loss_val: 0.6870', 'acc_val: 0.3120', 'time: 5077.7543s')\n",
      "('iter: 24301', 'loss_train: 1.3672', 'acc_train: 0.5770', 'loss_val: 0.6865', 'acc_val: 0.3090', 'time: 5101.7221s')\n",
      "('iter: 24401', 'loss_train: 1.3652', 'acc_train: 0.5780', 'loss_val: 0.6901', 'acc_val: 0.3000', 'time: 5125.6496s')\n",
      "('iter: 24501', 'loss_train: 1.3631', 'acc_train: 0.5800', 'loss_val: 0.6925', 'acc_val: 0.2950', 'time: 5149.5991s')\n",
      "('iter: 24601', 'loss_train: 1.3566', 'acc_train: 0.5890', 'loss_val: 0.6939', 'acc_val: 0.2950', 'time: 5173.3162s')\n",
      "('iter: 24701', 'loss_train: 1.3557', 'acc_train: 0.5840', 'loss_val: 0.6930', 'acc_val: 0.3030', 'time: 5197.2540s')\n",
      "('iter: 24801', 'loss_train: 1.3572', 'acc_train: 0.5820', 'loss_val: 0.6901', 'acc_val: 0.3170', 'time: 5221.3410s')\n",
      "('iter: 24901', 'loss_train: 1.3566', 'acc_train: 0.5810', 'loss_val: 0.6841', 'acc_val: 0.3300', 'time: 5245.3250s')\n",
      "('iter: 25001', 'loss_train: 1.3565', 'acc_train: 0.5790', 'loss_val: 0.6862', 'acc_val: 0.3250', 'time: 5269.5842s')\n",
      "('iter: 25101', 'loss_train: 1.3590', 'acc_train: 0.5610', 'loss_val: 0.6865', 'acc_val: 0.3190', 'time: 5293.7920s')\n",
      "('iter: 25201', 'loss_train: 1.3612', 'acc_train: 0.5640', 'loss_val: 0.6846', 'acc_val: 0.3260', 'time: 5318.3030s')\n",
      "('iter: 25301', 'loss_train: 1.3586', 'acc_train: 0.5710', 'loss_val: 0.6869', 'acc_val: 0.3260', 'time: 5342.7420s')\n",
      "('iter: 25401', 'loss_train: 1.3591', 'acc_train: 0.5700', 'loss_val: 0.6871', 'acc_val: 0.3260', 'time: 5366.4312s')\n",
      "('iter: 25501', 'loss_train: 1.3617', 'acc_train: 0.5650', 'loss_val: 0.6839', 'acc_val: 0.3350', 'time: 5390.6745s')\n",
      "('iter: 25601', 'loss_train: 1.3681', 'acc_train: 0.5650', 'loss_val: 0.6821', 'acc_val: 0.3350', 'time: 5414.9510s')\n",
      "('iter: 25701', 'loss_train: 1.3715', 'acc_train: 0.5540', 'loss_val: 0.6837', 'acc_val: 0.3380', 'time: 5438.6101s')\n",
      "('iter: 25801', 'loss_train: 1.3685', 'acc_train: 0.5580', 'loss_val: 0.6848', 'acc_val: 0.3410', 'time: 5462.4357s')\n",
      "('iter: 25901', 'loss_train: 1.3671', 'acc_train: 0.5660', 'loss_val: 0.6895', 'acc_val: 0.3430', 'time: 5486.3843s')\n",
      "('iter: 26001', 'loss_train: 1.3631', 'acc_train: 0.5830', 'loss_val: 0.6911', 'acc_val: 0.3450', 'time: 5510.2086s')\n",
      "('iter: 26101', 'loss_train: 1.3639', 'acc_train: 0.5840', 'loss_val: 0.6894', 'acc_val: 0.3570', 'time: 5534.1602s')\n",
      "('iter: 26201', 'loss_train: 1.3681', 'acc_train: 0.5800', 'loss_val: 0.6873', 'acc_val: 0.3650', 'time: 5558.1265s')\n",
      "('iter: 26301', 'loss_train: 1.3699', 'acc_train: 0.5730', 'loss_val: 0.6834', 'acc_val: 0.3840', 'time: 5582.0826s')\n",
      "('iter: 26401', 'loss_train: 1.3717', 'acc_train: 0.5570', 'loss_val: 0.6814', 'acc_val: 0.3990', 'time: 5606.1224s')\n",
      "('iter: 26501', 'loss_train: 1.3706', 'acc_train: 0.5420', 'loss_val: 0.6823', 'acc_val: 0.4090', 'time: 5630.2214s')\n",
      "('iter: 26601', 'loss_train: 1.3666', 'acc_train: 0.5590', 'loss_val: 0.6799', 'acc_val: 0.4290', 'time: 5654.3047s')\n",
      "('iter: 26701', 'loss_train: 1.3647', 'acc_train: 0.5680', 'loss_val: 0.6767', 'acc_val: 0.4340', 'time: 5678.3685s')\n",
      "('iter: 26801', 'loss_train: 1.3652', 'acc_train: 0.5730', 'loss_val: 0.6762', 'acc_val: 0.4400', 'time: 5702.2068s')\n",
      "('iter: 26901', 'loss_train: 1.3659', 'acc_train: 0.5870', 'loss_val: 0.6699', 'acc_val: 0.4610', 'time: 5726.2940s')\n",
      "('iter: 27001', 'loss_train: 1.3674', 'acc_train: 0.5990', 'loss_val: 0.6691', 'acc_val: 0.4970', 'time: 5753.6875s')\n",
      "('iter: 27101', 'loss_train: 1.3645', 'acc_train: 0.5910', 'loss_val: 0.6724', 'acc_val: 0.5080', 'time: 5777.4467s')\n",
      "('iter: 27201', 'loss_train: 1.3610', 'acc_train: 0.5950', 'loss_val: 0.6709', 'acc_val: 0.5330', 'time: 5801.8394s')\n",
      "('iter: 27301', 'loss_train: 1.3597', 'acc_train: 0.5950', 'loss_val: 0.6757', 'acc_val: 0.5330', 'time: 5826.0304s')\n",
      "('iter: 27401', 'loss_train: 1.3582', 'acc_train: 0.5890', 'loss_val: 0.6787', 'acc_val: 0.5390', 'time: 5849.6933s')\n",
      "('iter: 27501', 'loss_train: 1.3556', 'acc_train: 0.5880', 'loss_val: 0.6801', 'acc_val: 0.5470', 'time: 5873.7363s')\n",
      "('iter: 27601', 'loss_train: 1.3520', 'acc_train: 0.6020', 'loss_val: 0.6802', 'acc_val: 0.5540', 'time: 5897.3739s')\n",
      "('iter: 27701', 'loss_train: 1.3493', 'acc_train: 0.6050', 'loss_val: 0.6863', 'acc_val: 0.5600', 'time: 5921.6838s')\n",
      "('iter: 27801', 'loss_train: 1.3485', 'acc_train: 0.6080', 'loss_val: 0.6861', 'acc_val: 0.5750', 'time: 5945.7030s')\n",
      "('iter: 27901', 'loss_train: 1.3483', 'acc_train: 0.6150', 'loss_val: 0.6876', 'acc_val: 0.5840', 'time: 5969.4445s')\n",
      "('iter: 28001', 'loss_train: 1.3541', 'acc_train: 0.5970', 'loss_val: 0.6843', 'acc_val: 0.5800', 'time: 5993.7335s')\n",
      "('iter: 28101', 'loss_train: 1.3536', 'acc_train: 0.5850', 'loss_val: 0.6832', 'acc_val: 0.5800', 'time: 6017.8790s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 28201', 'loss_train: 1.3580', 'acc_train: 0.5660', 'loss_val: 0.6849', 'acc_val: 0.5710', 'time: 6041.9623s')\n",
      "('iter: 28301', 'loss_train: 1.3582', 'acc_train: 0.5620', 'loss_val: 0.6853', 'acc_val: 0.5750', 'time: 6066.0473s')\n",
      "('iter: 28401', 'loss_train: 1.3605', 'acc_train: 0.5440', 'loss_val: 0.6838', 'acc_val: 0.5770', 'time: 6089.9737s')\n",
      "('iter: 28501', 'loss_train: 1.3587', 'acc_train: 0.5710', 'loss_val: 0.6848', 'acc_val: 0.5720', 'time: 6114.0787s')\n",
      "('iter: 28601', 'loss_train: 1.3655', 'acc_train: 0.5650', 'loss_val: 0.6877', 'acc_val: 0.5660', 'time: 6138.2190s')\n",
      "('iter: 28701', 'loss_train: 1.3695', 'acc_train: 0.5740', 'loss_val: 0.6813', 'acc_val: 0.5750', 'time: 6162.1740s')\n",
      "('iter: 28801', 'loss_train: 1.3702', 'acc_train: 0.5760', 'loss_val: 0.6831', 'acc_val: 0.5690', 'time: 6186.2228s')\n",
      "('iter: 28901', 'loss_train: 1.3727', 'acc_train: 0.5850', 'loss_val: 0.6838', 'acc_val: 0.5620', 'time: 6209.9967s')\n",
      "('iter: 29001', 'loss_train: 1.3648', 'acc_train: 0.5840', 'loss_val: 0.6865', 'acc_val: 0.5520', 'time: 6234.1250s')\n",
      "('iter: 29101', 'loss_train: 1.3692', 'acc_train: 0.5750', 'loss_val: 0.6868', 'acc_val: 0.5510', 'time: 6258.2270s')\n",
      "('iter: 29201', 'loss_train: 1.3672', 'acc_train: 0.5750', 'loss_val: 0.6842', 'acc_val: 0.5560', 'time: 6282.7093s')\n",
      "('iter: 29301', 'loss_train: 1.3665', 'acc_train: 0.5750', 'loss_val: 0.6849', 'acc_val: 0.5490', 'time: 6307.1331s')\n",
      "('iter: 29401', 'loss_train: 1.3629', 'acc_train: 0.5800', 'loss_val: 0.6854', 'acc_val: 0.5350', 'time: 6331.1372s')\n",
      "('iter: 29501', 'loss_train: 1.3623', 'acc_train: 0.5760', 'loss_val: 0.6837', 'acc_val: 0.5230', 'time: 6355.3032s')\n",
      "('iter: 29601', 'loss_train: 1.3594', 'acc_train: 0.5920', 'loss_val: 0.6848', 'acc_val: 0.5030', 'time: 6379.6040s')\n",
      "('iter: 29701', 'loss_train: 1.3614', 'acc_train: 0.5860', 'loss_val: 0.6861', 'acc_val: 0.4850', 'time: 6403.8636s')\n",
      "('iter: 29801', 'loss_train: 1.3625', 'acc_train: 0.5820', 'loss_val: 0.6815', 'acc_val: 0.4810', 'time: 6428.1742s')\n",
      "('iter: 29901', 'loss_train: 1.3590', 'acc_train: 0.5870', 'loss_val: 0.6813', 'acc_val: 0.4650', 'time: 6452.0447s')\n",
      "('iter: 30001', 'loss_train: 1.3634', 'acc_train: 0.5760', 'loss_val: 0.6801', 'acc_val: 0.4500', 'time: 6476.3211s')\n",
      "('iter: 30101', 'loss_train: 1.3582', 'acc_train: 0.5750', 'loss_val: 0.6764', 'acc_val: 0.4450', 'time: 6501.0172s')\n",
      "('iter: 30201', 'loss_train: 1.3580', 'acc_train: 0.5800', 'loss_val: 0.6766', 'acc_val: 0.4290', 'time: 6525.2545s')\n",
      "('iter: 30301', 'loss_train: 1.3559', 'acc_train: 0.5880', 'loss_val: 0.6748', 'acc_val: 0.4210', 'time: 6549.8971s')\n",
      "('iter: 30401', 'loss_train: 1.3602', 'acc_train: 0.5710', 'loss_val: 0.6766', 'acc_val: 0.4120', 'time: 6574.7631s')\n",
      "('iter: 30501', 'loss_train: 1.3646', 'acc_train: 0.5700', 'loss_val: 0.6774', 'acc_val: 0.4080', 'time: 6598.5417s')\n",
      "('iter: 30601', 'loss_train: 1.3643', 'acc_train: 0.5730', 'loss_val: 0.6760', 'acc_val: 0.4160', 'time: 6622.3469s')\n",
      "('iter: 30701', 'loss_train: 1.3609', 'acc_train: 0.5770', 'loss_val: 0.6794', 'acc_val: 0.4080', 'time: 6646.4703s')\n",
      "('iter: 30801', 'loss_train: 1.3621', 'acc_train: 0.5640', 'loss_val: 0.6808', 'acc_val: 0.3990', 'time: 6670.7114s')\n",
      "('iter: 30901', 'loss_train: 1.3620', 'acc_train: 0.5810', 'loss_val: 0.6833', 'acc_val: 0.3940', 'time: 6694.9756s')\n",
      "('iter: 31001', 'loss_train: 1.3604', 'acc_train: 0.5870', 'loss_val: 0.6860', 'acc_val: 0.3860', 'time: 6719.1991s')\n",
      "('iter: 31101', 'loss_train: 1.3613', 'acc_train: 0.5820', 'loss_val: 0.6884', 'acc_val: 0.3750', 'time: 6743.3290s')\n",
      "('iter: 31201', 'loss_train: 1.3620', 'acc_train: 0.5780', 'loss_val: 0.6929', 'acc_val: 0.3690', 'time: 6767.4919s')\n",
      "('iter: 31301', 'loss_train: 1.3625', 'acc_train: 0.5890', 'loss_val: 0.6923', 'acc_val: 0.3680', 'time: 6791.4294s')\n",
      "('iter: 31401', 'loss_train: 1.3595', 'acc_train: 0.5800', 'loss_val: 0.6881', 'acc_val: 0.3760', 'time: 6815.9002s')\n",
      "('iter: 31501', 'loss_train: 1.3579', 'acc_train: 0.5790', 'loss_val: 0.6887', 'acc_val: 0.3760', 'time: 6840.5435s')\n",
      "('iter: 31601', 'loss_train: 1.3598', 'acc_train: 0.5780', 'loss_val: 0.6864', 'acc_val: 0.3820', 'time: 6864.0957s')\n",
      "('iter: 31701', 'loss_train: 1.3587', 'acc_train: 0.5850', 'loss_val: 0.6847', 'acc_val: 0.3900', 'time: 6888.7418s')\n",
      "('iter: 31801', 'loss_train: 1.3561', 'acc_train: 0.5820', 'loss_val: 0.6869', 'acc_val: 0.3830', 'time: 6913.1574s')\n",
      "('iter: 31901', 'loss_train: 1.3601', 'acc_train: 0.5810', 'loss_val: 0.6842', 'acc_val: 0.3900', 'time: 6936.6352s')\n",
      "('iter: 32001', 'loss_train: 1.3596', 'acc_train: 0.5840', 'loss_val: 0.6837', 'acc_val: 0.3930', 'time: 6960.5936s')\n",
      "('iter: 32101', 'loss_train: 1.3602', 'acc_train: 0.5830', 'loss_val: 0.6797', 'acc_val: 0.4050', 'time: 6984.4284s')\n",
      "('iter: 32201', 'loss_train: 1.3595', 'acc_train: 0.5760', 'loss_val: 0.6783', 'acc_val: 0.4060', 'time: 7008.4233s')\n",
      "('iter: 32301', 'loss_train: 1.3611', 'acc_train: 0.5750', 'loss_val: 0.6764', 'acc_val: 0.4040', 'time: 7032.1961s')\n",
      "('iter: 32401', 'loss_train: 1.3599', 'acc_train: 0.5800', 'loss_val: 0.6785', 'acc_val: 0.4040', 'time: 7056.4263s')\n",
      "('iter: 32501', 'loss_train: 1.3591', 'acc_train: 0.5780', 'loss_val: 0.6780', 'acc_val: 0.4030', 'time: 7080.6376s')\n",
      "('iter: 32601', 'loss_train: 1.3537', 'acc_train: 0.5910', 'loss_val: 0.6835', 'acc_val: 0.3860', 'time: 7104.3591s')\n",
      "('iter: 32701', 'loss_train: 1.3598', 'acc_train: 0.5830', 'loss_val: 0.6794', 'acc_val: 0.3860', 'time: 7124.6040s')\n",
      "('iter: 32801', 'loss_train: 1.3643', 'acc_train: 0.5700', 'loss_val: 0.6793', 'acc_val: 0.3880', 'time: 7144.4340s')\n",
      "('iter: 32901', 'loss_train: 1.3623', 'acc_train: 0.5700', 'loss_val: 0.6810', 'acc_val: 0.3770', 'time: 7163.7140s')\n",
      "('iter: 33001', 'loss_train: 1.3634', 'acc_train: 0.5680', 'loss_val: 0.6819', 'acc_val: 0.3770', 'time: 7182.9960s')\n",
      "('iter: 33101', 'loss_train: 1.3638', 'acc_train: 0.5530', 'loss_val: 0.6845', 'acc_val: 0.3670', 'time: 7202.5333s')\n",
      "('iter: 33201', 'loss_train: 1.3635', 'acc_train: 0.5620', 'loss_val: 0.6842', 'acc_val: 0.3670', 'time: 7221.9946s')\n",
      "('iter: 33301', 'loss_train: 1.3629', 'acc_train: 0.5780', 'loss_val: 0.6851', 'acc_val: 0.3720', 'time: 7241.3141s')\n",
      "('iter: 33401', 'loss_train: 1.3651', 'acc_train: 0.5700', 'loss_val: 0.6833', 'acc_val: 0.3760', 'time: 7260.6281s')\n",
      "('iter: 33501', 'loss_train: 1.3684', 'acc_train: 0.5620', 'loss_val: 0.6800', 'acc_val: 0.3860', 'time: 7279.9152s')\n",
      "('iter: 33601', 'loss_train: 1.3730', 'acc_train: 0.5700', 'loss_val: 0.6760', 'acc_val: 0.3950', 'time: 7299.1958s')\n",
      "('iter: 33701', 'loss_train: 1.3709', 'acc_train: 0.5630', 'loss_val: 0.6794', 'acc_val: 0.3880', 'time: 7318.4855s')\n",
      "('iter: 33801', 'loss_train: 1.3691', 'acc_train: 0.5520', 'loss_val: 0.6803', 'acc_val: 0.3900', 'time: 7337.7990s')\n",
      "('iter: 33901', 'loss_train: 1.3708', 'acc_train: 0.5520', 'loss_val: 0.6802', 'acc_val: 0.3930', 'time: 7357.3340s')\n",
      "('iter: 34001', 'loss_train: 1.3700', 'acc_train: 0.5630', 'loss_val: 0.6773', 'acc_val: 0.3970', 'time: 7376.6256s')\n",
      "('iter: 34101', 'loss_train: 1.3703', 'acc_train: 0.5540', 'loss_val: 0.6774', 'acc_val: 0.4000', 'time: 7395.9062s')\n",
      "('iter: 34201', 'loss_train: 1.3716', 'acc_train: 0.5560', 'loss_val: 0.6745', 'acc_val: 0.4110', 'time: 7415.2189s')\n",
      "('iter: 34301', 'loss_train: 1.3710', 'acc_train: 0.5680', 'loss_val: 0.6744', 'acc_val: 0.4060', 'time: 7434.5131s')\n",
      "('iter: 34401', 'loss_train: 1.3654', 'acc_train: 0.5850', 'loss_val: 0.6751', 'acc_val: 0.4020', 'time: 7453.9458s')\n",
      "('iter: 34501', 'loss_train: 1.3654', 'acc_train: 0.5780', 'loss_val: 0.6810', 'acc_val: 0.3910', 'time: 7473.2602s')\n",
      "('iter: 34601', 'loss_train: 1.3674', 'acc_train: 0.5780', 'loss_val: 0.6835', 'acc_val: 0.3860', 'time: 7492.7694s')\n",
      "('iter: 34701', 'loss_train: 1.3683', 'acc_train: 0.5710', 'loss_val: 0.6823', 'acc_val: 0.3850', 'time: 7512.2013s')\n",
      "('iter: 34801', 'loss_train: 1.3686', 'acc_train: 0.5580', 'loss_val: 0.6817', 'acc_val: 0.3850', 'time: 7531.8874s')\n",
      "('iter: 34901', 'loss_train: 1.3675', 'acc_train: 0.5460', 'loss_val: 0.6801', 'acc_val: 0.3920', 'time: 7552.1778s')\n",
      "('iter: 35001', 'loss_train: 1.3700', 'acc_train: 0.5440', 'loss_val: 0.6792', 'acc_val: 0.3980', 'time: 7578.1411s')\n",
      "('iter: 35101', 'loss_train: 1.3687', 'acc_train: 0.5490', 'loss_val: 0.6796', 'acc_val: 0.3960', 'time: 7600.1253s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 35201', 'loss_train: 1.3663', 'acc_train: 0.5640', 'loss_val: 0.6786', 'acc_val: 0.3950', 'time: 7619.7122s')\n",
      "('iter: 35301', 'loss_train: 1.3688', 'acc_train: 0.5700', 'loss_val: 0.6772', 'acc_val: 0.4030', 'time: 7639.5431s')\n",
      "('iter: 35401', 'loss_train: 1.3710', 'acc_train: 0.5760', 'loss_val: 0.6770', 'acc_val: 0.4060', 'time: 7660.1917s')\n",
      "('iter: 35501', 'loss_train: 1.3703', 'acc_train: 0.5790', 'loss_val: 0.6731', 'acc_val: 0.4120', 'time: 7684.1300s')\n",
      "('iter: 35601', 'loss_train: 1.3675', 'acc_train: 0.5830', 'loss_val: 0.6688', 'acc_val: 0.4230', 'time: 7708.7637s')\n",
      "('iter: 35701', 'loss_train: 1.3663', 'acc_train: 0.5760', 'loss_val: 0.6731', 'acc_val: 0.4200', 'time: 7732.6731s')\n",
      "('iter: 35801', 'loss_train: 1.3628', 'acc_train: 0.5830', 'loss_val: 0.6715', 'acc_val: 0.4250', 'time: 7756.7825s')\n",
      "('iter: 35901', 'loss_train: 1.3636', 'acc_train: 0.5750', 'loss_val: 0.6737', 'acc_val: 0.4200', 'time: 7780.0941s')\n",
      "('iter: 36001', 'loss_train: 1.3625', 'acc_train: 0.5760', 'loss_val: 0.6755', 'acc_val: 0.4150', 'time: 7803.6736s')\n",
      "('iter: 36101', 'loss_train: 1.3621', 'acc_train: 0.5730', 'loss_val: 0.6767', 'acc_val: 0.4110', 'time: 7827.4829s')\n",
      "('iter: 36201', 'loss_train: 1.3642', 'acc_train: 0.5740', 'loss_val: 0.6810', 'acc_val: 0.4050', 'time: 7851.2598s')\n",
      "('iter: 36301', 'loss_train: 1.3645', 'acc_train: 0.5660', 'loss_val: 0.6830', 'acc_val: 0.4040', 'time: 7875.0037s')\n",
      "('iter: 36401', 'loss_train: 1.3697', 'acc_train: 0.5560', 'loss_val: 0.6850', 'acc_val: 0.3960', 'time: 7898.6960s')\n",
      "('iter: 36501', 'loss_train: 1.3678', 'acc_train: 0.5620', 'loss_val: 0.6846', 'acc_val: 0.4010', 'time: 7922.3727s')\n",
      "('iter: 36601', 'loss_train: 1.3692', 'acc_train: 0.5610', 'loss_val: 0.6866', 'acc_val: 0.4040', 'time: 7946.0719s')\n",
      "('iter: 36701', 'loss_train: 1.3655', 'acc_train: 0.5710', 'loss_val: 0.6855', 'acc_val: 0.4140', 'time: 7969.9158s')\n",
      "('iter: 36801', 'loss_train: 1.3673', 'acc_train: 0.5730', 'loss_val: 0.6914', 'acc_val: 0.4000', 'time: 7993.6211s')\n",
      "('iter: 36901', 'loss_train: 1.3660', 'acc_train: 0.5870', 'loss_val: 0.6913', 'acc_val: 0.3990', 'time: 8017.3849s')\n",
      "('iter: 37001', 'loss_train: 1.3640', 'acc_train: 0.5860', 'loss_val: 0.6892', 'acc_val: 0.3980', 'time: 8041.0995s')\n",
      "('iter: 37101', 'loss_train: 1.3664', 'acc_train: 0.5800', 'loss_val: 0.6871', 'acc_val: 0.4020', 'time: 8065.0795s')\n",
      "('iter: 37201', 'loss_train: 1.3622', 'acc_train: 0.5830', 'loss_val: 0.6857', 'acc_val: 0.4040', 'time: 8088.9069s')\n",
      "('iter: 37301', 'loss_train: 1.3622', 'acc_train: 0.5820', 'loss_val: 0.6884', 'acc_val: 0.3970', 'time: 8113.0087s')\n",
      "('iter: 37401', 'loss_train: 1.3582', 'acc_train: 0.5820', 'loss_val: 0.6870', 'acc_val: 0.4000', 'time: 8137.0410s')\n",
      "('iter: 37501', 'loss_train: 1.3594', 'acc_train: 0.5770', 'loss_val: 0.6902', 'acc_val: 0.3910', 'time: 8161.1871s')\n",
      "('iter: 37601', 'loss_train: 1.3557', 'acc_train: 0.5930', 'loss_val: 0.6898', 'acc_val: 0.3870', 'time: 8184.8643s')\n",
      "('iter: 37701', 'loss_train: 1.3610', 'acc_train: 0.5740', 'loss_val: 0.6877', 'acc_val: 0.3880', 'time: 8208.6214s')\n",
      "('iter: 37801', 'loss_train: 1.3626', 'acc_train: 0.5690', 'loss_val: 0.6832', 'acc_val: 0.3980', 'time: 8232.3967s')\n",
      "('iter: 37901', 'loss_train: 1.3590', 'acc_train: 0.5800', 'loss_val: 0.6836', 'acc_val: 0.4020', 'time: 8256.3519s')\n",
      "('iter: 38001', 'loss_train: 1.3606', 'acc_train: 0.5810', 'loss_val: 0.6836', 'acc_val: 0.4050', 'time: 8280.4821s')\n",
      "('iter: 38101', 'loss_train: 1.3592', 'acc_train: 0.5700', 'loss_val: 0.6854', 'acc_val: 0.4070', 'time: 8304.7896s')\n",
      "('iter: 38201', 'loss_train: 1.3630', 'acc_train: 0.5770', 'loss_val: 0.6834', 'acc_val: 0.4080', 'time: 8328.6127s')\n",
      "('iter: 38301', 'loss_train: 1.3615', 'acc_train: 0.5850', 'loss_val: 0.6849', 'acc_val: 0.4010', 'time: 8352.5258s')\n",
      "('iter: 38401', 'loss_train: 1.3617', 'acc_train: 0.5740', 'loss_val: 0.6848', 'acc_val: 0.4030', 'time: 8376.4967s')\n",
      "('iter: 38501', 'loss_train: 1.3599', 'acc_train: 0.5780', 'loss_val: 0.6789', 'acc_val: 0.4190', 'time: 8400.6334s')\n",
      "('iter: 38601', 'loss_train: 1.3621', 'acc_train: 0.5810', 'loss_val: 0.6749', 'acc_val: 0.4200', 'time: 8425.5031s')\n",
      "('iter: 38701', 'loss_train: 1.3604', 'acc_train: 0.5790', 'loss_val: 0.6762', 'acc_val: 0.4180', 'time: 8449.4646s')\n",
      "('iter: 38801', 'loss_train: 1.3585', 'acc_train: 0.5780', 'loss_val: 0.6740', 'acc_val: 0.4250', 'time: 8473.8522s')\n",
      "('iter: 38901', 'loss_train: 1.3647', 'acc_train: 0.5690', 'loss_val: 0.6739', 'acc_val: 0.4200', 'time: 8498.0364s')\n",
      "('iter: 39001', 'loss_train: 1.3641', 'acc_train: 0.5670', 'loss_val: 0.6737', 'acc_val: 0.4190', 'time: 8522.0184s')\n",
      "('iter: 39101', 'loss_train: 1.3610', 'acc_train: 0.5720', 'loss_val: 0.6770', 'acc_val: 0.4090', 'time: 8546.4999s')\n",
      "('iter: 39201', 'loss_train: 1.3621', 'acc_train: 0.5710', 'loss_val: 0.6782', 'acc_val: 0.4090', 'time: 8571.0446s')\n",
      "('iter: 39301', 'loss_train: 1.3629', 'acc_train: 0.5700', 'loss_val: 0.6745', 'acc_val: 0.4200', 'time: 8595.1260s')\n",
      "('iter: 39401', 'loss_train: 1.3633', 'acc_train: 0.5780', 'loss_val: 0.6760', 'acc_val: 0.4140', 'time: 8619.5280s')\n",
      "('iter: 39501', 'loss_train: 1.3643', 'acc_train: 0.5760', 'loss_val: 0.6803', 'acc_val: 0.3980', 'time: 8644.0833s')\n",
      "('iter: 39601', 'loss_train: 1.3660', 'acc_train: 0.5680', 'loss_val: 0.6844', 'acc_val: 0.3930', 'time: 8668.5325s')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-114c2ba2b5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#     val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, acc, val_loss, val_acc, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f\\n' % (n_iter, loss, acc, val_loss, val_acc)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 100 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "\n",
    "acc_q = deque(maxlen=1000)\n",
    "loss_q = deque(maxlen=1000)\n",
    "val_acc_q = deque(maxlen=1000)\n",
    "val_loss_q = deque(maxlen=1000)\n",
    "criterion = nn.BCELoss()\n",
    "# \n",
    "model = net\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "#\n",
    "interval = 100\n",
    "t = time.time()\n",
    "print 'start training.'\n",
    "best_acc  = 0\n",
    "best_loss = float('inf')\n",
    "for i in range(1,1000000):\n",
    "    with open('text_log.txt', 'a') as f:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "    #     positive\n",
    "        q,k = next(pos_G)\n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        output = model(q.cuda(), k.cuda())\n",
    "        acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        pos_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "\n",
    "#         negative\n",
    "        q,k = next(neg_G)\n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        \n",
    "        output = model(q.cuda(), k.cuda())\n",
    "        acc = 1 if output.flatten().item() < 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        neg_loss = criterion(output, torch.FloatTensor([[0]]).cuda())\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss_q.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #     val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_i = i % val_Q.shape[0]\n",
    "            q,k = val_Q[val_i,:], val_K[val_i,:]\n",
    "            q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        \n",
    "            output = model(q.cuda(), k.cuda())\n",
    "            val_acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "            val_acc_q.append(val_acc)\n",
    "\n",
    "            val_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "            val_loss_q.append(val_loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        acc = float(np.mean(acc_q))\n",
    "        loss = float(np.mean(loss_q))\n",
    "        val_acc = float(np.mean(val_acc_q))\n",
    "        val_loss = float(np.mean(val_loss_q))\n",
    "\n",
    "        if i % interval == 0:\n",
    "            print('iter: {:04d}'.format(i+1),\n",
    "                  'loss_train: {:.4f}'.format(loss),\n",
    "                  'acc_train: {:.4f}'.format(acc),\n",
    "                  'loss_val: {:.4f}'.format(val_loss),\n",
    "                  'acc_val: {:.4f}'.format(val_acc),\n",
    "                  'time: {:.4f}s'.format((time.time() - t)))\n",
    "        if i > 100:\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model, './text_best_acc.pt')\n",
    "                with open('./text_best.txt', 'a') as g:\n",
    "                    g.write('best acc at %d with %.5f\\n' % (i+1, best_acc))\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model, './text_best_loss.pt')\n",
    "                with open('./text_best.txt', 'a') as g:\n",
    "                    g.write('best loss at %d with %.5f\\n' % (i+1, best_loss))\n",
    "            \n",
    "        dump_log(model, i+1, loss, acc, val_loss, val_acc, f, './text_tmp.pt')\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# batch_size = 128\n",
    "# # xml_id_map[113].shape\n",
    "# def positive_bootsrap_generator(edges, xml_id_map):\n",
    "#     num_edge = len(edges)\n",
    "        \n",
    "#     while True:\n",
    "#         for idx in np.random.permutation(num_edge):\n",
    "#             src, dst = edges[idx, :]\n",
    "#             Q = xml_id_map[dst]\n",
    "#             K = xml_id_map[src]\n",
    "#             yield Q, K\n",
    "# def negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list):\n",
    "#     exist_node_list = xml_id_map.keys()\n",
    "#     exist_N = len(training_node_list)\n",
    "        \n",
    "#     while True:\n",
    "#         src = training_node_list[np.random.randint(exist_N)]\n",
    "#         dst = training_node_list[np.random.randint(exist_N)]\n",
    "#         while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "#             dst = training_node_list[np.random.randint(exist_N)]\n",
    "#         Q = xml_id_map[dst]\n",
    "#         K = xml_id_map[src]\n",
    "#         yield Q, K\n",
    "# def val_data(edges, xml_id_map):\n",
    "#     Q, K = [],[]\n",
    "    \n",
    "#     for idx in range(edges.shape[0]):\n",
    "#         src, dst = edges[idx, :]\n",
    "#         q = xml_id_map[dst]\n",
    "#         k = xml_id_map[src]\n",
    "#         Q.append(q)\n",
    "#         K.append(k)\n",
    "#     Q = np.vstack(Q)\n",
    "#     K = np.vstack(K)\n",
    "    \n",
    "#     return Q, K\n",
    "    \n",
    "# N = edges.shape[0]\n",
    "# idx = np.random.permutation(N)\n",
    "# train_idx = idx[N//10:]\n",
    "# val_idx = idx[:N//10]\n",
    "\n",
    "# pos_G = positive_bootsrap_generator(edges[train_idx,:], xml_id_map)\n",
    "# training_node_list = list(set(edges[train_idx,:].flatten().tolist()))\n",
    "# neg_G = negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list)\n",
    "# val_Q, val_K = val_data(edges[val_idx,:], xml_id_map)\n",
    "# q,k = next(pos_G)\n",
    "# print(q.shape,k.shape)\n",
    "# q,k = next(neg_G)\n",
    "# print(q.shape,k.shape)\n",
    "# print(val_Q.shape,val_K.shape)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12(virtualenv)",
   "language": "python",
   "name": "python2.7.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
