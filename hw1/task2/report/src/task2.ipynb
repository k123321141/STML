{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate fake link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 86682\n",
      "(6.940667787653135, 8.743005782827575)\n",
      "generate fake link done.\n",
      "after"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/15902 [00:00<04:02, 65.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170023 73210.16382416527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 10332/15902 [02:40<01:27, 63.46it/s]"
     ]
    }
   ],
   "source": [
    "# randomly sample test link\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "def get_node_set(path):\n",
    "    # training data\n",
    "    edges_unordered = np.genfromtxt(path,\n",
    "                                    dtype=np.int32)\n",
    "    id_set = set(edges_unordered.flatten().tolist())\n",
    "    return id_set\n",
    "\n",
    "data_path = join('./','kaggle')\n",
    "# training data\n",
    "train_node_set = get_node_set(join(data_path,'t2-train.txt'))\n",
    "test_node_set = get_node_set(join(data_path,'t2-test.txt'))\n",
    "node_set = set.union(train_node_set, test_node_set)\n",
    "idx_map = {k:i for i,k in enumerate(list(node_set))}\n",
    "\n",
    "N = len(node_set)\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "\n",
    "with open(join(data_path,'t2-train.txt')) as f:\n",
    "    ls = f.readlines()\n",
    "for l in ls:\n",
    "    buf = l.strip().split(' ')\n",
    "    src, dst = int(buf[0]), int(buf[1])\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "print 'before', np.sum(adj_mat)\n",
    "out_degree = np.sum(adj_mat, axis=1).flatten()\n",
    "train_idx = np.array([idx_map[idx] for idx in list(train_node_set)])\n",
    "train_out_degree = out_degree[train_idx]\n",
    "mean, std = np.mean(train_out_degree), np.std(train_out_degree)\n",
    "print(mean, std)\n",
    "for node_id in list(test_node_set):\n",
    "    i = idx_map[node_id]\n",
    "    d = int(np.round(np.random.normal(loc=mean, scale=std)))\n",
    "    d = d if d >= 0 else 0\n",
    "    train_node_list = list(train_node_set)\n",
    "    for j in range(d):\n",
    "        idx = np.random.randint(len(train_node_list))\n",
    "        dst = idx_map[train_node_list[idx]]\n",
    "        while adj_mat[i, dst] == 1 or dst == i:\n",
    "            dst = np.random.randint(N)\n",
    "        adj_mat[i, dst] = 1\n",
    "print('generate fake link done.')\n",
    "rev_map = {v:k for k,v in idx_map.items()}\n",
    "print 'after', np.sum(adj_mat),len(test_node_set)*mean\n",
    "with tqdm(total=N) as pbar:\n",
    "    with open(join(data_path,'t2-fake.txt'), 'w') as f:\n",
    "        for src in range(N):\n",
    "            for dst in range(N):\n",
    "                if adj_mat[src, dst] == 1:\n",
    "                    s = '%d %d\\n' % (rev_map[src], rev_map[dst])\n",
    "                    f.write(s)\n",
    "            pbar.update(1)\n",
    "    \n",
    "print 'done', np.sum(adj_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all 17500 xml files.\n",
      "Found 82709 unique tokens.\n",
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from os.path import join\n",
    "import os\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from constants import MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def quote_title_abstract(xml_path):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    soup = BS(data)\n",
    "    title, abstract = soup.find('title').text, soup.find('abstract').text\n",
    "    return title.strip(), abstract.strip()\n",
    "\n",
    "# text preprocessing\n",
    "data_path = join('./','kaggle/')\n",
    "xml_dir = join(data_path, 't2-doc')\n",
    "xml_list = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "# print(len(xml_list))\n",
    "\n",
    "\n",
    "texts = []\n",
    "\n",
    "for xml in xml_list:\n",
    "    path = join(xml_dir,xml)\n",
    "    title, abstract = quote_title_abstract(path)\n",
    "    text = title + '' + abstract\n",
    "    texts.append(text)\n",
    "#     texts.append(title)\n",
    "#     texts.append(abstract)\n",
    "print('read all %d xml files.' % len(xml_list))\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=True, split=' ', char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "xml_id_map = {}\n",
    "for i,xml in enumerate(xml_list):\n",
    "    node_id = int(xml.replace('.xml',''))\n",
    "    xml_id_map[node_id] = data[i,:]\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r', encoding='utf8') as f:\n",
    "with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('./','t2_weak2.emb')) as f:\n",
    "    num_nodes, D = f.readline().strip().split(' ')\n",
    "    num_nodes = int(num_nodes)\n",
    "    D = int(D)\n",
    "    \n",
    "    ls = f.readlines()\n",
    "node_emb_dict = {}\n",
    "for l in ls:\n",
    "    buf = l.strip().split(' ')\n",
    "    node_id, emb = int(buf[0]), buf[1:]\n",
    "    x = np.asarray([float(i) for i in emb], dtype=np.float32)\n",
    "    node_emb_dict[node_id] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([1, 1])\n",
      "4263425\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "# environment\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\" if with_gpu else \"cpu\")\n",
    "\n",
    "def positional_encoding(pos):\n",
    "    assert D_MODEL % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,D_MODEL], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "def get_pos_mat(length):\n",
    "    if length > MAX_SEQUENCE_LENGTH:\n",
    "        print('sequence length reach PE_MAT_CACHE. %d ' % length)\n",
    "        ret = torch.cat([positional_encoding(i) for i in range(length)], dim=0).to(device)\n",
    "        ret.requires_grad = False\n",
    "        global PE_CACHE_MATRIX\n",
    "        PE_CACHE_MATRIX = ret\n",
    "        return ret\n",
    "    else:\n",
    "        return PE_CACHE_MATRIX[:length]\n",
    "    \n",
    "PE_CACHE_MATRIX = torch.cat([positional_encoding(i) for i in range(0,MAX_SEQUENCE_LENGTH)], dim=0).to(device)\n",
    "PE_CACHE_MATRIX.requires_grad = False\n",
    "\n",
    "# construct neuron network\n",
    "\n",
    "def scaled_dot_attention(Q, K, V, mask=None):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    out = torch.matmul(Q,K.t()) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out = out.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "        self.output_linear = nn.Linear(3*dm, 1)\n",
    "\n",
    "    def forward(self, Q, K, Q_fea, K_fea):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        \n",
    "        \n",
    "        summary = scaled_dot_attention(self.summary_weight, de_out, de_out)\n",
    "        x = torch.cat([summary, Q_fea.view([1,-1]), K_fea.view([1,-1])], dim=-1)\n",
    "        out = self.output_linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "class Word_Embedding(nn.Module):\n",
    "    def __init__(self, emb_matrix):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.emb = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, padding_idx=0)\n",
    "        self.emb.weight = nn.parameter.Parameter(torch.FloatTensor(emb_matrix))\n",
    "        self.emb.weight.requires_grad_(False)\n",
    "        \n",
    "        self.linear = nn.Linear(EMBEDDING_DIM, D_MODEL, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K               \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.attention_norm_lay = nn.LayerNorm([dm,])\n",
    "        self.att_drop = nn.Dropout(P_DROP)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "        att_out = self.attention_norm_lay(K + attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(att_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "        out = self.ff_norm_lay(att_out + linear_out)\n",
    "        out = att_out + linear_out\n",
    "    \n",
    "        return out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        Q_len, d = Q.size()\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out, mask=None)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Decoder, self).__init__()\n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.Q_att_drop = nn.Dropout(P_DROP)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.QK_att_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out, mask):\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = self.Q_attention_norm_lay(Q + Q_attention_out)\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = self.QK_attention_norm_lay(Q_att_out + QK_attention_out)\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = self.ff_norm_lay(QK_att_out + linear_out)\n",
    "        return out\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask=None):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "            \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len,_ = x.size()\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# encoder = Stack_Encoder(6, 64,64,20,8)\n",
    "# # print net\n",
    "Q = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "V = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "Q_fea = torch.rand([D_MODEL,]).to(device)\n",
    "K_fea = torch.rand([D_MODEL,]).to(device)\n",
    "net = Transformer(STACKED_NUM, DK, DV, D_MODEL, H, embedding_matrix).to(device)\n",
    "print(Q.dtype)\n",
    "o = net(Q, V, Q_fea, K_fea)\n",
    "# print t\n",
    "print(o.size())\n",
    "# print o\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight done\n"
     ]
    }
   ],
   "source": [
    "tmp_m = torch.load('./bak/best_acc.pt')\n",
    "net.load_state_dict(tmp_m.state_dict())\n",
    "torch.nn.init.xavier_uniform_(net.output_linear.weight)\n",
    "print 'load weight done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_set(path):\n",
    "    # training data\n",
    "    edges_unordered = np.genfromtxt(path,\n",
    "                                    dtype=np.int32)\n",
    "    id_set = set(edges_unordered.flatten().tolist())\n",
    "    return id_set, edges_unordered\n",
    "\n",
    "node_set, edges = get_node_set(join(data_path,'t2-fake.txt'))\n",
    "idx_map = {k:i for i,k in enumerate(list(node_set))}\n",
    "N = len(node_set)\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "\n",
    "with open(join(data_path,'t2-fake.txt')) as f:\n",
    "    ls = f.readlines()\n",
    "for l in ls:\n",
    "    buf = l.strip().split(' ')\n",
    "    src, dst = int(buf[0]), int(buf[1])\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,), (128,), (128,))\n",
      "((150,), (150,), (128,), (128,))\n",
      "((17087, 150), (17087, 150), (17087, 128), (17087, 128))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# xml_id_map[113].shape\n",
    "def positive_bootsrap_generator(edges, xml_id_map, node_emb_dict):\n",
    "    num_edge = len(edges)\n",
    "        \n",
    "    while True:\n",
    "        for idx in np.random.permutation(num_edge):\n",
    "            src, dst = edges[idx, :]\n",
    "            Q = xml_id_map[dst]\n",
    "            K = xml_id_map[src]\n",
    "            Q_fea = node_emb_dict[dst]\n",
    "            K_fea = node_emb_dict[src]\n",
    "            yield Q, K, Q_fea, K_fea\n",
    "def negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list, node_emb_dict):\n",
    "    exist_node_list = xml_id_map.keys()\n",
    "    exist_N = len(training_node_list)\n",
    "        \n",
    "    while True:\n",
    "        src = training_node_list[np.random.randint(exist_N)]\n",
    "        dst = training_node_list[np.random.randint(exist_N)]\n",
    "        while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "            dst = training_node_list[np.random.randint(exist_N)]\n",
    "        Q = xml_id_map[dst]\n",
    "        K = xml_id_map[src]\n",
    "        Q_fea = node_emb_dict[dst]\n",
    "        K_fea = node_emb_dict[src]\n",
    "        yield Q, K, Q_fea, K_fea\n",
    "\n",
    "def val_data(edges, xml_id_map):\n",
    "    Q, K = [],[]\n",
    "    Q_f, K_f = [],[]\n",
    "    \n",
    "    for idx in range(edges.shape[0]):\n",
    "        src, dst = edges[idx, :]\n",
    "        q = xml_id_map[dst]\n",
    "        k = xml_id_map[src]\n",
    "        q_fea = node_emb_dict[dst]\n",
    "        k_fea = node_emb_dict[src]\n",
    "        \n",
    "        Q.append(q)\n",
    "        K.append(k)\n",
    "        Q_f.append(q_fea)\n",
    "        K_f.append(k_fea)\n",
    "        \n",
    "    Q = np.vstack(Q)\n",
    "    K = np.vstack(K)\n",
    "    Q_fea = np.vstack(Q_f)\n",
    "    K_fea = np.vstack(K_f)\n",
    "    \n",
    "    return Q, K, Q_fea, K_fea\n",
    "    \n",
    "N = edges.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "train_idx = idx[N//10:]\n",
    "val_idx = idx[:N//10]\n",
    "\n",
    "pos_G = positive_bootsrap_generator(edges[train_idx,:], xml_id_map, node_emb_dict)\n",
    "training_node_list = list(set(edges[train_idx,:].flatten().tolist()))\n",
    "neg_G = negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list, node_emb_dict)\n",
    "val_Q, val_K, val_Q_fea, val_K_fea = val_data(edges[val_idx,:], xml_id_map)\n",
    "q,k,q_f,k_f = next(pos_G)\n",
    "print(q.shape,k.shape, q_f.shape, k_f.shape)\n",
    "q,k,q_f,k_f = next(neg_G)\n",
    "print(q.shape,k.shape, q_f.shape, k_f.shape)\n",
    "print(val_Q.shape,val_K.shape, val_Q_fea.shape, val_K_fea.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Transformer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Word_Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Multi_Head_attention_layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type PositionwiseFeedForward. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 0101', 'loss_train: 1.3865', 'acc_train: 0.4800', 'loss_val: 0.6951', 'acc_val: 0.4500', 'time: 16.6295s')\n",
      "('iter: 0201', 'loss_train: 1.3856', 'acc_train: 0.5000', 'loss_val: 0.6933', 'acc_val: 0.4750', 'time: 32.0074s')\n",
      "('iter: 0301', 'loss_train: 1.3852', 'acc_train: 0.5017', 'loss_val: 0.6907', 'acc_val: 0.5133', 'time: 47.3843s')\n",
      "('iter: 0401', 'loss_train: 1.3836', 'acc_train: 0.5138', 'loss_val: 0.6917', 'acc_val: 0.4850', 'time: 62.8140s')\n",
      "('iter: 0501', 'loss_train: 1.3848', 'acc_train: 0.5100', 'loss_val: 0.6911', 'acc_val: 0.4900', 'time: 78.2313s')\n",
      "('iter: 0601', 'loss_train: 1.3845', 'acc_train: 0.5160', 'loss_val: 0.6906', 'acc_val: 0.4983', 'time: 93.7061s')\n",
      "('iter: 0701', 'loss_train: 1.3811', 'acc_train: 0.5410', 'loss_val: 0.6916', 'acc_val: 0.4814', 'time: 109.2394s')\n",
      "('iter: 0801', 'loss_train: 1.3808', 'acc_train: 0.5470', 'loss_val: 0.6901', 'acc_val: 0.4950', 'time: 124.6351s')\n",
      "('iter: 0901', 'loss_train: 1.3797', 'acc_train: 0.5510', 'loss_val: 0.6899', 'acc_val: 0.4989', 'time: 140.0695s')\n",
      "('iter: 1001', 'loss_train: 1.3783', 'acc_train: 0.5700', 'loss_val: 0.6887', 'acc_val: 0.5090', 'time: 155.5051s')\n",
      "('iter: 1101', 'loss_train: 1.3763', 'acc_train: 0.5870', 'loss_val: 0.6881', 'acc_val: 0.5090', 'time: 170.9999s')\n",
      "('iter: 1201', 'loss_train: 1.3738', 'acc_train: 0.5660', 'loss_val: 0.6869', 'acc_val: 0.5110', 'time: 186.3997s')\n",
      "('iter: 1301', 'loss_train: 1.3722', 'acc_train: 0.5720', 'loss_val: 0.6865', 'acc_val: 0.5070', 'time: 201.8196s')\n",
      "('iter: 1401', 'loss_train: 1.3702', 'acc_train: 0.5780', 'loss_val: 0.6855', 'acc_val: 0.5140', 'time: 217.2121s')\n",
      "('iter: 1501', 'loss_train: 1.3675', 'acc_train: 0.5750', 'loss_val: 0.6846', 'acc_val: 0.5160', 'time: 232.6963s')\n",
      "('iter: 1601', 'loss_train: 1.3657', 'acc_train: 0.5730', 'loss_val: 0.6839', 'acc_val: 0.5070', 'time: 248.0869s')\n",
      "('iter: 1701', 'loss_train: 1.3634', 'acc_train: 0.5930', 'loss_val: 0.6804', 'acc_val: 0.5250', 'time: 263.4755s')\n",
      "('iter: 1801', 'loss_train: 1.3599', 'acc_train: 0.6020', 'loss_val: 0.6791', 'acc_val: 0.5320', 'time: 278.8915s')\n",
      "('iter: 1901', 'loss_train: 1.3569', 'acc_train: 0.6030', 'loss_val: 0.6762', 'acc_val: 0.5360', 'time: 294.2792s')\n",
      "('iter: 2001', 'loss_train: 1.3551', 'acc_train: 0.6120', 'loss_val: 0.6758', 'acc_val: 0.5300', 'time: 309.6807s')\n",
      "('iter: 2101', 'loss_train: 1.3514', 'acc_train: 0.6220', 'loss_val: 0.6730', 'acc_val: 0.5440', 'time: 325.0740s')\n",
      "('iter: 2201', 'loss_train: 1.3495', 'acc_train: 0.6130', 'loss_val: 0.6716', 'acc_val: 0.5480', 'time: 340.4598s')\n",
      "('iter: 2301', 'loss_train: 1.3493', 'acc_train: 0.6040', 'loss_val: 0.6705', 'acc_val: 0.5520', 'time: 355.8759s')\n",
      "('iter: 2401', 'loss_train: 1.3495', 'acc_train: 0.5910', 'loss_val: 0.6685', 'acc_val: 0.5610', 'time: 371.3505s')\n",
      "('iter: 2501', 'loss_train: 1.3475', 'acc_train: 0.5880', 'loss_val: 0.6678', 'acc_val: 0.5570', 'time: 386.7445s')\n",
      "('iter: 2601', 'loss_train: 1.3456', 'acc_train: 0.5840', 'loss_val: 0.6660', 'acc_val: 0.5680', 'time: 402.1420s')\n",
      "('iter: 2701', 'loss_train: 1.3441', 'acc_train: 0.5880', 'loss_val: 0.6667', 'acc_val: 0.5670', 'time: 417.5356s')\n",
      "('iter: 2801', 'loss_train: 1.3433', 'acc_train: 0.5940', 'loss_val: 0.6678', 'acc_val: 0.5550', 'time: 432.9204s')\n",
      "('iter: 2901', 'loss_train: 1.3423', 'acc_train: 0.6040', 'loss_val: 0.6689', 'acc_val: 0.5490', 'time: 448.5176s')\n",
      "('iter: 3001', 'loss_train: 1.3422', 'acc_train: 0.6010', 'loss_val: 0.6680', 'acc_val: 0.5440', 'time: 463.9692s')\n",
      "('iter: 3101', 'loss_train: 1.3420', 'acc_train: 0.6050', 'loss_val: 0.6665', 'acc_val: 0.5510', 'time: 479.5209s')\n",
      "('iter: 3201', 'loss_train: 1.3419', 'acc_train: 0.6030', 'loss_val: 0.6680', 'acc_val: 0.5470', 'time: 494.9953s')\n",
      "('iter: 3301', 'loss_train: 1.3373', 'acc_train: 0.5990', 'loss_val: 0.6641', 'acc_val: 0.5530', 'time: 510.4945s')\n",
      "('iter: 3401', 'loss_train: 1.3365', 'acc_train: 0.5930', 'loss_val: 0.6635', 'acc_val: 0.5570', 'time: 526.0104s')\n",
      "('iter: 3501', 'loss_train: 1.3353', 'acc_train: 0.5950', 'loss_val: 0.6624', 'acc_val: 0.5610', 'time: 541.4894s')\n",
      "('iter: 3601', 'loss_train: 1.3324', 'acc_train: 0.5900', 'loss_val: 0.6639', 'acc_val: 0.5540', 'time: 556.9932s')\n",
      "('iter: 3701', 'loss_train: 1.3336', 'acc_train: 0.5920', 'loss_val: 0.6640', 'acc_val: 0.5500', 'time: 572.4567s')\n",
      "('iter: 3801', 'loss_train: 1.3327', 'acc_train: 0.6030', 'loss_val: 0.6608', 'acc_val: 0.5530', 'time: 587.9266s')\n",
      "('iter: 3901', 'loss_train: 1.3304', 'acc_train: 0.6160', 'loss_val: 0.6621', 'acc_val: 0.5460', 'time: 603.4836s')\n",
      "('iter: 4001', 'loss_train: 1.3275', 'acc_train: 0.6150', 'loss_val: 0.6612', 'acc_val: 0.5460', 'time: 618.9632s')\n",
      "('iter: 4101', 'loss_train: 1.3282', 'acc_train: 0.6150', 'loss_val: 0.6618', 'acc_val: 0.5370', 'time: 634.4348s')\n",
      "('iter: 4201', 'loss_train: 1.3270', 'acc_train: 0.6080', 'loss_val: 0.6594', 'acc_val: 0.5400', 'time: 649.8765s')\n",
      "('iter: 4301', 'loss_train: 1.3305', 'acc_train: 0.5970', 'loss_val: 0.6594', 'acc_val: 0.5410', 'time: 665.3233s')\n",
      "('iter: 4401', 'loss_train: 1.3284', 'acc_train: 0.5840', 'loss_val: 0.6609', 'acc_val: 0.5330', 'time: 680.7887s')\n",
      "('iter: 4501', 'loss_train: 1.3279', 'acc_train: 0.5830', 'loss_val: 0.6617', 'acc_val: 0.5310', 'time: 696.2299s')\n",
      "('iter: 4601', 'loss_train: 1.3280', 'acc_train: 0.5770', 'loss_val: 0.6558', 'acc_val: 0.5530', 'time: 711.7076s')\n",
      "('iter: 4701', 'loss_train: 1.3247', 'acc_train: 0.5930', 'loss_val: 0.6539', 'acc_val: 0.5650', 'time: 727.2900s')\n",
      "('iter: 4801', 'loss_train: 1.3253', 'acc_train: 0.5970', 'loss_val: 0.6543', 'acc_val: 0.5670', 'time: 743.2914s')\n",
      "('iter: 4901', 'loss_train: 1.3248', 'acc_train: 0.6120', 'loss_val: 0.6507', 'acc_val: 0.5820', 'time: 760.7777s')\n",
      "('iter: 5001', 'loss_train: 1.3221', 'acc_train: 0.6210', 'loss_val: 0.6503', 'acc_val: 0.5850', 'time: 776.4354s')\n",
      "('iter: 5101', 'loss_train: 1.3195', 'acc_train: 0.6290', 'loss_val: 0.6506', 'acc_val: 0.5840', 'time: 791.9782s')\n",
      "('iter: 5201', 'loss_train: 1.3150', 'acc_train: 0.6290', 'loss_val: 0.6487', 'acc_val: 0.5940', 'time: 807.4043s')\n",
      "('iter: 5301', 'loss_train: 1.3073', 'acc_train: 0.6390', 'loss_val: 0.6503', 'acc_val: 0.5860', 'time: 822.8056s')\n",
      "('iter: 5401', 'loss_train: 1.3065', 'acc_train: 0.6370', 'loss_val: 0.6491', 'acc_val: 0.5800', 'time: 838.1900s')\n",
      "('iter: 5501', 'loss_train: 1.3067', 'acc_train: 0.6310', 'loss_val: 0.6488', 'acc_val: 0.5830', 'time: 853.6557s')\n",
      "('iter: 5601', 'loss_train: 1.3031', 'acc_train: 0.6290', 'loss_val: 0.6518', 'acc_val: 0.5630', 'time: 869.0327s')\n",
      "('iter: 5701', 'loss_train: 1.3066', 'acc_train: 0.6220', 'loss_val: 0.6550', 'acc_val: 0.5450', 'time: 884.3905s')\n",
      "('iter: 5801', 'loss_train: 1.3024', 'acc_train: 0.6140', 'loss_val: 0.6572', 'acc_val: 0.5350', 'time: 899.7701s')\n",
      "('iter: 5901', 'loss_train: 1.3007', 'acc_train: 0.6110', 'loss_val: 0.6583', 'acc_val: 0.5290', 'time: 915.1640s')\n",
      "('iter: 6001', 'loss_train: 1.3049', 'acc_train: 0.6060', 'loss_val: 0.6562', 'acc_val: 0.5360', 'time: 930.5833s')\n",
      "('iter: 6101', 'loss_train: 1.3018', 'acc_train: 0.6100', 'loss_val: 0.6536', 'acc_val: 0.5410', 'time: 945.9572s')\n",
      "('iter: 6201', 'loss_train: 1.3052', 'acc_train: 0.6030', 'loss_val: 0.6545', 'acc_val: 0.5320', 'time: 961.3790s')\n",
      "('iter: 6301', 'loss_train: 1.3068', 'acc_train: 0.6040', 'loss_val: 0.6544', 'acc_val: 0.5290', 'time: 976.7521s')\n",
      "('iter: 6401', 'loss_train: 1.3044', 'acc_train: 0.6030', 'loss_val: 0.6537', 'acc_val: 0.5390', 'time: 992.2167s')\n",
      "('iter: 6501', 'loss_train: 1.3026', 'acc_train: 0.6150', 'loss_val: 0.6524', 'acc_val: 0.5410', 'time: 1007.6491s')\n",
      "('iter: 6601', 'loss_train: 1.3030', 'acc_train: 0.6180', 'loss_val: 0.6534', 'acc_val: 0.5360', 'time: 1023.0629s')\n",
      "('iter: 6701', 'loss_train: 1.2984', 'acc_train: 0.6240', 'loss_val: 0.6472', 'acc_val: 0.5500', 'time: 1038.7022s')\n",
      "('iter: 6801', 'loss_train: 1.3038', 'acc_train: 0.6200', 'loss_val: 0.6452', 'acc_val: 0.5630', 'time: 1054.1839s')\n",
      "('iter: 6901', 'loss_train: 1.3067', 'acc_train: 0.6110', 'loss_val: 0.6450', 'acc_val: 0.5650', 'time: 1069.8378s')\n",
      "('iter: 7001', 'loss_train: 1.3030', 'acc_train: 0.6020', 'loss_val: 0.6439', 'acc_val: 0.5700', 'time: 1085.3079s')\n",
      "('iter: 7101', 'loss_train: 1.3027', 'acc_train: 0.5950', 'loss_val: 0.6422', 'acc_val: 0.5780', 'time: 1101.0237s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 7201', 'loss_train: 1.2974', 'acc_train: 0.5990', 'loss_val: 0.6403', 'acc_val: 0.5830', 'time: 1116.4980s')\n",
      "('iter: 7301', 'loss_train: 1.2985', 'acc_train: 0.6070', 'loss_val: 0.6375', 'acc_val: 0.5940', 'time: 1131.9730s')\n",
      "('iter: 7401', 'loss_train: 1.2955', 'acc_train: 0.6230', 'loss_val: 0.6367', 'acc_val: 0.5930', 'time: 1147.4472s')\n",
      "('iter: 7501', 'loss_train: 1.2927', 'acc_train: 0.6230', 'loss_val: 0.6375', 'acc_val: 0.5870', 'time: 1162.9119s')\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, acc, val_loss, val_acc, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f\\n' % (n_iter, loss, acc, val_loss, val_acc)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 100 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "\n",
    "acc_q = deque(maxlen=1000)\n",
    "loss_q = deque(maxlen=1000)\n",
    "val_acc_q = deque(maxlen=1000)\n",
    "val_loss_q = deque(maxlen=1000)\n",
    "criterion = nn.BCELoss()\n",
    "# \n",
    "model = net\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "#\n",
    "interval = 100\n",
    "t = time.time()\n",
    "print 'start training.'\n",
    "best_acc = best_loss = 0\n",
    "for i in range(1,1000000):\n",
    "    with open('log.txt', 'a') as f:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "    #     positive\n",
    "        q,k,q_f,k_f = next(pos_G)\n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "        output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda())\n",
    "        acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        pos_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "\n",
    "#         negative\n",
    "        q,k,q_f,k_f = next(neg_G)\n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "        \n",
    "        output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda())\n",
    "        acc = 1 if output.flatten().item() < 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        neg_loss = criterion(output, torch.FloatTensor([[0]]).cuda())\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss_q.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #     val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_i = i % val_Q.shape[0]\n",
    "            q,k = val_Q[val_i,:], val_K[val_i,:]\n",
    "            q_f,k_f = val_Q_fea[val_i,:], val_K_fea[val_i,:]\n",
    "            q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "            q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "        \n",
    "            output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda())\n",
    "            val_acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "            val_acc_q.append(val_acc)\n",
    "\n",
    "            val_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "            val_loss_q.append(val_loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        acc = float(np.mean(acc_q))\n",
    "        loss = float(np.mean(loss_q))\n",
    "        val_acc = float(np.mean(val_acc_q))\n",
    "        val_loss = float(np.mean(val_loss_q))\n",
    "\n",
    "        if i % interval == 0:\n",
    "            print('iter: {:04d}'.format(i+1),\n",
    "                  'loss_train: {:.4f}'.format(loss),\n",
    "                  'acc_train: {:.4f}'.format(acc),\n",
    "                  'loss_val: {:.4f}'.format(val_loss),\n",
    "                  'acc_val: {:.4f}'.format(val_acc),\n",
    "                  'time: {:.4f}s'.format((time.time() - t)))\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model, './best_acc.pt')\n",
    "            with open('./best.txt', 'a') as g:\n",
    "                g.write('best acc at %d with %.5f\\n' % (i+1, best_acc))\n",
    "                \n",
    "        if val_loss > best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model, './best_loss.pt')\n",
    "            with open('./best.txt', 'a') as g:\n",
    "                g.write('best loss at %d with %.5f\\n' % (i+1, best_loss))\n",
    "            \n",
    "        dump_log(model, i+1, loss, acc, val_loss, val_acc, f, './tmp.pt')\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "edges_unordered = np.genfromtxt('./kaggle/t2-test.txt', dtype=np.int32)\n",
    "with torch.no_grad():\n",
    "    with open('pred.txt.csv', 'w') as f:\n",
    "        f.write('query_id,prediction\\n')\n",
    "        for i in range(edges_unordered.shape[0]):\n",
    "            src, dst = edges_unordered[i, :]\n",
    "            if src not in node_emb_dict or dst not in node_emb_dict:\n",
    "                f.write('%d,%d\\n' % (1 + i, out))\n",
    "                continue\n",
    "            q = xml_id_map[dst]\n",
    "            k = xml_id_map[src]\n",
    "            q_f = node_emb_dict[dst]\n",
    "            k_f = node_emb_dict[src]\n",
    "\n",
    "            q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "            q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "\n",
    "            output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda()).flatten().item()\n",
    "\n",
    "            out = 1 if output >= 0.5 else 0\n",
    "            f.write('%d,%d\\n' % (1 + i, out))\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# batch_size = 128\n",
    "# # xml_id_map[113].shape\n",
    "# def positive_bootsrap_generator(edges, xml_id_map):\n",
    "#     num_edge = len(edges)\n",
    "        \n",
    "#     while True:\n",
    "#         for idx in np.random.permutation(num_edge):\n",
    "#             src, dst = edges[idx, :]\n",
    "#             Q = xml_id_map[dst]\n",
    "#             K = xml_id_map[src]\n",
    "#             yield Q, K\n",
    "# def negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list):\n",
    "#     exist_node_list = xml_id_map.keys()\n",
    "#     exist_N = len(training_node_list)\n",
    "        \n",
    "#     while True:\n",
    "#         src = training_node_list[np.random.randint(exist_N)]\n",
    "#         dst = training_node_list[np.random.randint(exist_N)]\n",
    "#         while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "#             dst = training_node_list[np.random.randint(exist_N)]\n",
    "#         Q = xml_id_map[dst]\n",
    "#         K = xml_id_map[src]\n",
    "#         yield Q, K\n",
    "# def val_data(edges, xml_id_map):\n",
    "#     Q, K = [],[]\n",
    "    \n",
    "#     for idx in range(edges.shape[0]):\n",
    "#         src, dst = edges[idx, :]\n",
    "#         q = xml_id_map[dst]\n",
    "#         k = xml_id_map[src]\n",
    "#         Q.append(q)\n",
    "#         K.append(k)\n",
    "#     Q = np.vstack(Q)\n",
    "#     K = np.vstack(K)\n",
    "    \n",
    "#     return Q, K\n",
    "    \n",
    "# N = edges.shape[0]\n",
    "# idx = np.random.permutation(N)\n",
    "# train_idx = idx[N//10:]\n",
    "# val_idx = idx[:N//10]\n",
    "\n",
    "# pos_G = positive_bootsrap_generator(edges[train_idx,:], xml_id_map)\n",
    "# training_node_list = list(set(edges[train_idx,:].flatten().tolist()))\n",
    "# neg_G = negative_bootsrap_generator(adj_mat, idx_map, xml_id_map, training_node_list)\n",
    "# val_Q, val_K = val_data(edges[val_idx,:], xml_id_map)\n",
    "# q,k = next(pos_G)\n",
    "# print(q.shape,k.shape)\n",
    "# q,k = next(neg_G)\n",
    "# print(q.shape,k.shape)\n",
    "# print(val_Q.shape,val_K.shape)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12(virtualenv)",
   "language": "python",
   "name": "python2.7.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
