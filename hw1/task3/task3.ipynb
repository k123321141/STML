{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate fake link with time info\n",
    "## execute next block first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 64710/108630 [00:00<00:00, 647099.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.03980042] [87.40132677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110594it [00:01, 108481.73it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 110585\n",
      "9 3411\n"
     ]
    }
   ],
   "source": [
    "# randomly sample test link\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "np.random.seed(1337)\n",
    "def get_node_set(path):\n",
    "    # training data\n",
    "    edges_unordered = np.genfromtxt(path,\n",
    "                                    dtype=np.int32)\n",
    "    id_set = set(edges_unordered.flatten().tolist())\n",
    "    return id_set\n",
    "\n",
    "data_path = join('./','kaggle')\n",
    "# training data\n",
    "train_node_set = get_node_set(join(data_path,'t3-train.txt'))\n",
    "test_node_set = get_node_set(join(data_path,'t3-test.txt')).difference(train_node_set)\n",
    "node_set = set.union(train_node_set, test_node_set)\n",
    "idx_map = {k:i for i,k in enumerate(list(node_set))}\n",
    "N = len(node_set)\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "W = []\n",
    "\n",
    "links = np.genfromtxt(join(data_path,'t3-train.txt'), dtype=np.int32)\n",
    "for i in range(links.shape[0]):\n",
    "    src, dst = links[i].tolist()\n",
    "    _,src_weeks =  xml_id_map[src]\n",
    "    _,dst_weeks =  xml_id_map[dst]\n",
    "    \n",
    "    weeks_distance = max(src_weeks - dst_weeks, 1.)\n",
    "    W.append(weeks_distance)\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "\n",
    "out_degree = np.sum(adj_mat, axis=1).flatten()\n",
    "\n",
    "means, std = np.mean(out_degree), np.std(out_degree)\n",
    "w_mean, w_std = np.mean(W), np.std(W)\n",
    "print w_mean, w_std\n",
    "\n",
    "rev_map = {v:k for k,v in idx_map.items()}\n",
    "total_num = links.shape[0] + int(1.2*means * len(test_node_set))\n",
    "c = 0\n",
    "\n",
    "with tqdm(total=total_num) as pbar:\n",
    "    with open(join(data_path,'t3-fake.txt'), 'w') as f:\n",
    "        for i in range(links.shape[0]):\n",
    "            src, dst = links[i].tolist()\n",
    "            s = '%d %d\\n' % (src, dst)\n",
    "            f.write(s)\n",
    "            pbar.update(1)\n",
    "        train_node_list = list(train_node_set)\n",
    "        for node_id in list(test_node_set):\n",
    "            _,src_weeks =  xml_id_map[node_id]\n",
    "                \n",
    "            i = idx_map[node_id]\n",
    "            d = int(np.round(np.random.normal(means, std)))\n",
    "            d = max(1, d)\n",
    "            \n",
    "            for j in range(d):\n",
    "                \n",
    "                idx = np.random.randint(len(train_node_list))\n",
    "                dst = idx_map[train_node_list[idx]]\n",
    "                _,dst_weeks =  xml_id_map[train_node_list[idx]]\n",
    "                w_d = src_weeks-dst_weeks\n",
    "                k = 0\n",
    "                while adj_mat[i, dst] == 1 or dst == i or src_weeks < dst_weeks or abs(abs(w_d)- w_mean) > 2*w_std:\n",
    "                    idx = np.random.randint(len(train_node_list))\n",
    "                    dst = idx_map[train_node_list[idx]]\n",
    "                    _,dst_weeks =  xml_id_map[train_node_list[idx]]\n",
    "                    w_d = src_weeks-dst_weeks\n",
    "#                     print '%.2f -> %.2f' %(src_weeks, dst_weeks),(adj_mat[i, dst] == 1 or dst == i), src_weeks < dst_weeks\n",
    "                    k+=1\n",
    "                    if k > 10000 and src_weeks < avg_w/2:\n",
    "                        c +=1\n",
    "                        break\n",
    "#                         print k,node_id, train_node_list[idx],'%.2f -> %.2f' %(src_weeks, dst_weeks), src_weeks < dst_weeks,(adj_mat[i, dst] == 1 or dst == i), abs(abs(w_d)- w_mean) > 2*w_std\n",
    "                if k > 10000 and src_weeks < avg_w/2:\n",
    "                    pbar.update(1)\n",
    "                    continue \n",
    "                if node_id == 17493:\n",
    "                    print node_id, dst, src_weeks, dst_weeks\n",
    "                adj_mat[i, dst] = 1\n",
    "                s = '%d %d\\n' % (rev_map[i], rev_map[dst])\n",
    "                f.write(s)\n",
    "            \n",
    "                pbar.update(1)\n",
    "#             print c,len (test_node_set)\n",
    "    \n",
    "print 'done', np.sum(adj_mat)\n",
    "print c, len(test_node_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process text info and time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|██████████| 17500/17500 [00:07<00:00, 2289.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all 17500 xml files.\n",
      "error count 0\n",
      "min weeks in training set : 68, avg weeks : 396\n",
      "Found 82615 unique tokens.\n",
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from os.path import join\n",
    "import os\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from constants import MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "np.random.seed(1337)\n",
    "def replace_timezone_fn(s):\n",
    "    return re.sub('(\\d){2}:(\\d){2}:(\\d){2} [A-Z]{3}', _sub_tz, s)\n",
    "def _sub_tz(matched):\n",
    "    return re.sub('[A-Za-z]{3}', 'GMT', matched.group(0))\n",
    "     \n",
    "def retrive_date(pat_obj_1, pat_obj_2, pat_obj_3, s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    match_1 = pat_obj_1.search(s)\n",
    "    match_2 = None\n",
    "    match_3 = None\n",
    "    \n",
    "    if match_1 is None:\n",
    "        match_2 = pat_obj_2.search(s)\n",
    "    if match_2 is None:\n",
    "        match_3 = pat_obj_3.search(s)\n",
    "    assert (match_1 is not None) | (match_2 is not None) | (match_3 is not None)\n",
    "    \n",
    "        \n",
    "    if match_1 is not None:\n",
    "        days, months, years = match_1.groups()\n",
    "        date_str = '%s %s %s' % (days, months, years)\n",
    "    if match_2 is not None:\n",
    "        days, months, years = match_2.groups()\n",
    "        date_str = '%s %s 19%s' % (days, months, years)\n",
    "    if match_3 is not None:\n",
    "        months, days, years = match_3.groups()\n",
    "        date_str = '%s %s %s' % (days, months, years)\n",
    "    \n",
    "    if len(months) > 3:\n",
    "        return datetime.strptime(date_str, '%d %B %Y')\n",
    "    else:\n",
    "        return datetime.strptime(date_str, '%d %b %Y')\n",
    "    \n",
    "\n",
    "def prep_date(date):\n",
    "#     min date in training set 1991-12-31\n",
    "    secs = (date - datetime.strptime('1990-9-9', '%Y-%m-%d')).total_seconds()\n",
    "    weeks = np.round(secs // (60*60*24*7))\n",
    "    return weeks\n",
    "\n",
    "def quote_title_date_abstract(xml_path):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    soup = BS(data)\n",
    "    title, abstract, date = soup.find('title').text, soup.find('abstract').text, soup.find('date').text\n",
    "    \n",
    "    return title.strip(), abstract.strip(), date.strip()\n",
    "\n",
    "# text preprocessing\n",
    "data_path = join('./','kaggle/')\n",
    "xml_dir = join(data_path, 't3-doc')\n",
    "xml_list = [f for f in os.listdir(xml_dir) if f.endswith('.xml')]\n",
    "# print(len(xml_list))\n",
    "\n",
    "\n",
    "texts = []\n",
    "weeks = []\n",
    "c = 0\n",
    "# \n",
    "month_pattern = '(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)'\n",
    "pat_obj_1 = re.compile('([0-9]+) %s ([0-9]{4}|20[0-9]{3})' % month_pattern)\n",
    "pat_obj_2 = re.compile('([0-9]+) %s (9[0-9])' % month_pattern)\n",
    "pat_obj_3 = re.compile('%s ([0-9]+) .* ([0-9]{4}|20[0-9]{3})' % month_pattern)\n",
    "# \n",
    "\n",
    "with tqdm(total=len(xml_list)) as pbar:\n",
    "    for xml in xml_list:\n",
    "        \n",
    "        \n",
    "        path = join(xml_dir,xml)\n",
    "        title, abstract, date_str = quote_title_date_abstract(path)\n",
    "        text = title + '' + abstract\n",
    "#         date special case\n",
    "#         01/01/93 13:35:33 GMT+0100 12330.xml\n",
    "        if xml == '12330.xml':\n",
    "            date_str = '1 Jan 93'\n",
    "\n",
    "        try :\n",
    "            date = retrive_date(pat_obj_1, pat_obj_2, pat_obj_3, date_str)\n",
    "        except AssertionError:\n",
    "            print date_str, xml\n",
    "            c+=1 \n",
    "            continue\n",
    "        texts.append(text)\n",
    "        weeks.append(prep_date(date))\n",
    "        pbar.update(1)\n",
    "print('read all %d xml files.' % len(xml_list))\n",
    "print 'error count %d' % c\n",
    "min_w, avg_w, std_w = (min(weeks), np.mean(weeks), np.std(weeks))\n",
    "print 'min weeks in training set : %.0f, avg weeks : %.0f' % (min_w, avg_w)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ',\n",
    "                                   lower=True, split=' ', char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "xml_id_map = {}\n",
    "for i,xml in enumerate(xml_list):\n",
    "    node_id = int(xml.replace('.xml',''))\n",
    "    w = float(weeks[i] - avg_w)/std_w \n",
    "    w = np.array([w,])\n",
    "    xml_id_map[node_id] = (data[i,:], w)\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "embeddings_index = {}\n",
    "# with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r', encoding='utf8') as f:\n",
    "with open(os.path.join('./','glove', 'glove.6B.%dd.txt' % EMBEDDING_DIM), 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb\n",
    "buf = np.genfromtxt('./t3.emb', skip_header=1, dtype=np.float32)\n",
    "nodes = buf[:,0].astype(np.int32)\n",
    "emb = buf[:,1:]\n",
    "\n",
    "node_emb_dict = {}\n",
    "for i in range(emb.shape[0]):\n",
    "    node_id = nodes[i]\n",
    "    x = emb[i,:]\n",
    "    node_emb_dict[node_id] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.Size([1, 1])\n",
      "5649409\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_normal_\n",
    "from constants import D_MODEL, STACKED_NUM,DK, DV, H, P_DROP, D_FF, MAX_SEQUENCE_LENGTH, MAX_NUM_WORDS, EMBEDDING_DIM\n",
    "# environment\n",
    "with_gpu = torch.cuda.is_available()\n",
    "# with_gpu = False\n",
    "device = torch.device(\"cuda:0\" if with_gpu else \"cpu\")\n",
    "\n",
    "def positional_encoding(pos):\n",
    "    assert D_MODEL % 2 == 0\n",
    "    pos = torch.tensor(pos, dtype=torch.float32, requires_grad=False)\n",
    "    pe = torch.zeros([1,D_MODEL], dtype=torch.float32, requires_grad=False)\n",
    "    for i in range(D_MODEL//2):\n",
    "        a = torch.tensor(10000, dtype=torch.float32, requires_grad=False)\n",
    "        b = torch.tensor(2.*i/float(D_MODEL), dtype=torch.float32, requires_grad=False)\n",
    "        c = pos / torch.pow(a, b)\n",
    "        pe[0, 2*i] = torch.sin(c)\n",
    "        pe[0, 2*i+1] = torch.cos(c)\n",
    "    return pe\n",
    "def get_pos_mat(length):\n",
    "    if length > MAX_SEQUENCE_LENGTH:\n",
    "        print('sequence length reach PE_MAT_CACHE. %d ' % length)\n",
    "        ret = torch.cat([positional_encoding(i) for i in range(length)], dim=0).to(device)\n",
    "        ret.requires_grad = False\n",
    "        global PE_CACHE_MATRIX\n",
    "        PE_CACHE_MATRIX = ret\n",
    "        return ret\n",
    "    else:\n",
    "        return PE_CACHE_MATRIX[:length]\n",
    "    \n",
    "PE_CACHE_MATRIX = torch.cat([positional_encoding(i) for i in range(0,MAX_SEQUENCE_LENGTH)], dim=0).to(device)\n",
    "PE_CACHE_MATRIX.requires_grad = False\n",
    "\n",
    "# construct neuron network\n",
    "\n",
    "def scaled_dot_attention(Q, K, V, mask=None):\n",
    "    assert Q.size()[-1] == K.size()[-1]\n",
    "    dk = torch.tensor(K.size()[-1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    out = torch.matmul(Q,K.t()) / torch.sqrt(dk) \n",
    "    if mask is not None:\n",
    "        out = out.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "    return torch.matmul(F.softmax(out, dim=-1), V)\n",
    "                            \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_num, dk, dv, dm, h, emb_matrix):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.emb = Word_Embedding(emb_matrix)\n",
    "        \n",
    "        self.emb_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "        self.encoder = Stack_Encoder(layer_num, dk, dv, dm, h)\n",
    "        self.decoder = Stack_Decoder(layer_num, dk, dv, dm, h)\n",
    "        self.summary_decoder = Stack_Decoder(2, dk, dv, dm, h)\n",
    "        \n",
    "        self.summary_weight = nn.Parameter(torch.FloatTensor(1, dm))\n",
    "        torch.nn.init.xavier_uniform_(self.summary_weight)\n",
    "        \n",
    "#         self.q_weeks_linear = nn.Linear(1, dm//2)\n",
    "#         self.k_weeks_linear = nn.Linear(1, dm//2)\n",
    "        self.output_linear = nn.Linear(3*dm+2, dm)\n",
    "        self.output_linear2 = nn.Linear(dm, dm)\n",
    "        self.output_linear3 = nn.Linear(dm, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K, Q_fea, K_fea, Q_w, K_w):\n",
    "        \n",
    "#         encoder\n",
    "        K = self.emb(K)\n",
    "#         print(K.size(), get_pos_mat(MAX_SEQUENCE_LENGTH).size())\n",
    "        K = K + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        K = self.emb_drop(K)\n",
    "        \n",
    "        en_out = self.encoder(K)\n",
    "        \n",
    "#         decoder\n",
    "        Q = self.emb(Q)\n",
    "        seq_len, d = Q.size()\n",
    "        \n",
    "        Q = Q + get_pos_mat(MAX_SEQUENCE_LENGTH)\n",
    "        Q = self.emb_drop(Q)\n",
    "        \n",
    "        de_out = self.decoder(Q, en_out)\n",
    "        summary = self.summary_decoder(self.summary_weight, de_out)\n",
    "\n",
    "#         q_w_out = F.selu(self.q_weeks_linear(Q_w))\n",
    "#         k_w_out = F.selu(self.k_weeks_linear(K_w))\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([summary, Q_fea.view([1,-1]), K_fea.view([1,-1]), q_w_out.view([1,-1]), k_w_out.view([1,-1])], dim=-1)\n",
    "        x = torch.cat([summary, Q_fea.view([1,-1]), K_fea.view([1,-1]), Q_w.view([1,-1]), K_w.view([1,-1])], dim=-1)\n",
    "        out = self.output_linear(x)\n",
    "        \n",
    "        out = self.output_linear2(F.selu(out))\n",
    "        out = self.output_linear3(F.selu(out))\n",
    "        \n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "class Word_Embedding(nn.Module):\n",
    "    def __init__(self, emb_matrix):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.emb = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, padding_idx=0)\n",
    "        self.emb.weight = nn.parameter.Parameter(torch.FloatTensor(emb_matrix))\n",
    "        self.emb.weight.requires_grad_(False)\n",
    "        \n",
    "        self.linear = nn.Linear(EMBEDDING_DIM, D_MODEL, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Stack_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Encoder, self).__init__()\n",
    "        self.encoders = nn.ModuleList([Encoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "\n",
    "    def forward(self, K):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for lay in self.encoders:\n",
    "            K = lay(K)\n",
    "        return K               \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Encoder, self).__init__()\n",
    "#         attention residual block\n",
    "        self.multi_head_attention_layer = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.attention_norm_lay = nn.LayerNorm([dm,])\n",
    "        self.att_drop = nn.Dropout(P_DROP)\n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        \n",
    "\n",
    "    def forward(self, K):\n",
    "#         attention\n",
    "        attention_out = self.multi_head_attention_layer(K, K, K)\n",
    "        attention_out = self.att_drop(attention_out)\n",
    "        att_out = self.attention_norm_lay(K + attention_out)\n",
    "#         feed forward\n",
    "        linear_out = self.fcn(att_out)\n",
    "        linear_out = self.linear_drop(linear_out)\n",
    "        out = self.ff_norm_lay(att_out + linear_out)\n",
    "        out = att_out + linear_out\n",
    "    \n",
    "        return out\n",
    "class Stack_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_num, dk, dv, dm, h):\n",
    "        super(Stack_Decoder, self).__init__()\n",
    "        self.decoders = nn.ModuleList([Decoder(dk, dv, dm, h) for i in range(layer_num)])\n",
    "        \n",
    "        \n",
    "    def forward(self, Q, encoder_out):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        Q_len, d = Q.size()\n",
    "        for lay in self.decoders:\n",
    "            Q = lay(Q, encoder_out, mask=None)\n",
    "        return Q           \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Decoder, self).__init__()\n",
    "#         query attention residual block\n",
    "        self.Q_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.Q_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.Q_att_drop = nn.Dropout(P_DROP)\n",
    "    \n",
    "#         query key attention residual block\n",
    "        self.QK_attention_lay = Multi_Head_attention_layer(dk, dv, dm, h)\n",
    "        self.QK_attention_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.QK_att_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "    \n",
    "#         feed forward residual block\n",
    "        self.fcn = PositionwiseFeedForward(D_MODEL, D_FF)\n",
    "        self.ff_norm_lay = nn.LayerNorm([dm, ])\n",
    "        self.linear_drop = nn.Dropout(P_DROP)\n",
    "        \n",
    "\n",
    "    def forward(self, Q, encoder_out, mask):\n",
    "#         query attention\n",
    "        Q_attention_out = self.Q_attention_lay(Q, Q, Q, mask)\n",
    "        Q_attention_out = self.Q_att_drop(Q_attention_out)\n",
    "        Q_att_out = self.Q_attention_norm_lay(Q + Q_attention_out)\n",
    "#         query key attention\n",
    "        QK_attention_out = self.QK_attention_lay(Q_att_out, encoder_out, encoder_out)\n",
    "        QK_attention_out = self.QK_att_drop(QK_attention_out)\n",
    "        QK_att_out = self.QK_attention_norm_lay(Q_att_out + QK_attention_out)\n",
    "        \n",
    "#         feed forward\n",
    "        linear_out = self.fcn(QK_att_out)\n",
    "        out = self.ff_norm_lay(QK_att_out + linear_out)\n",
    "        return out\n",
    "\n",
    "class Multi_Head_attention_layer(nn.Module):\n",
    "    def __init__(self, dk, dv, dm, h):\n",
    "        super(Multi_Head_attention_layer, self).__init__()\n",
    "        self.Q_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.K_linears = nn.ModuleList([nn.Linear(dm, dk) for i in range(h)])\n",
    "        self.V_linears = nn.ModuleList([nn.Linear(dm, dv) for i in range(h)])\n",
    "        self.output_linear = nn.Linear(h*dv, dm)\n",
    "                            \n",
    "\n",
    "    def forward(self, Q_input, K_input, V_input, mask=None):\n",
    "        buf = []\n",
    "        for Q_linear, K_linear, V_linear in zip(self.Q_linears, self.K_linears, self.V_linears):\n",
    "            Q = Q_linear(Q_input)\n",
    "            K = K_linear(K_input)\n",
    "            V = V_linear(V_input)\n",
    "            buf.append(scaled_dot_attention(Q, K, V, mask))\n",
    "            \n",
    "        buf = torch.cat(buf,dim=-1)\n",
    "        out = self.output_linear(buf)\n",
    "        \n",
    "        return out      \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, d_ff, 1)\n",
    "        self.cnn2 = nn.Conv1d(d_ff, d_model, 1)\n",
    "                            \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len,_ = x.size()\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = x.squeeze(0)\n",
    "        \n",
    "        return x      \n",
    "    \n",
    "# encoder = Stack_Encoder(6, 64,64,20,8)\n",
    "# # print net\n",
    "Q = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "V = torch.randint(10000,[MAX_SEQUENCE_LENGTH,], dtype=torch.long).to(device)\n",
    "Q_fea = torch.rand([D_MODEL,]).to(device)\n",
    "K_fea = torch.rand([D_MODEL,]).to(device)\n",
    "Q_w = torch.rand([1,]).to(device)\n",
    "K_w = torch.rand([1,]).to(device)\n",
    "\n",
    "\n",
    "net = Transformer(STACKED_NUM, DK, DV, D_MODEL, H, embedding_matrix).to(device)\n",
    "print(Q.dtype)\n",
    "o = net(Q, V, Q_fea, K_fea, Q_w, K_w)\n",
    "# print t\n",
    "print(o.size())\n",
    "# print o\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_m = torch.load('../task2/best_loss.pt')\n",
    "# net.decoder.load_state_dict(tmp_m.decoder.state_dict())\n",
    "# net.encoder.load_state_dict(tmp_m.encoder.state_dict())\n",
    "# print 'load weight done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "links = np.genfromtxt(join(data_path,'t3-fake.txt'), dtype=np.int32)\n",
    "idx_map = {node:idx for idx, node in enumerate(list(set(links.flatten().tolist())))}\n",
    "N = links.shape[0]\n",
    "adj_mat = np.zeros([N,N], dtype=np.uint8)\n",
    "for i in range(links.shape[0]):\n",
    "    src, dst = links[i].tolist()\n",
    "    adj_mat[idx_map[src], idx_map[dst]] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,), (128,), (128,), (1,), (1,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 880464/880464 [00:02<00:00, 319909.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((150,), (150,), (128,), (128,), (1,), (1,))\n",
      "((11058, 150), (11058, 150), (11058, 128), (11058, 128), (11058, 1), (11058, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def positive_bootsrap_generator(edges, xml_id_map, node_emb_dict):\n",
    "    num_edge = len(edges)\n",
    "        \n",
    "    while True:\n",
    "        for idx in np.random.permutation(num_edge):\n",
    "            src, dst = edges[idx, :]\n",
    "            Q, Q_w = xml_id_map[dst]\n",
    "            K, K_w = xml_id_map[src]\n",
    "            Q_fea = node_emb_dict[dst]\n",
    "            K_fea = node_emb_dict[src]\n",
    "            yield Q, K, Q_fea, K_fea, Q_w, K_w\n",
    "def negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list, node_emb_dict, neighbor_link_rate=0.8):\n",
    "    \n",
    "    \n",
    "    exist_node_list = xml_id_map.keys()\n",
    "    exist_N = len(training_node_list)\n",
    "    N = adj_mat.shape[0]\n",
    "    \n",
    "#     adj mat\n",
    "    links = np.array(list(map(idx_map.get, links.flatten())),\n",
    "                     dtype=np.int32).reshape(links.shape)\n",
    "    \n",
    "    adj_sp = sp.coo_matrix((np.ones(links.shape[0]), (links[:, 0], links[:, 1])),\n",
    "                        shape=(N, N),\n",
    "                        dtype=np.uint8)\n",
    "    adj_sp_2 = (sp.coo_matrix.dot(adj_sp,adj_sp) + adj_sp).tocoo()\n",
    "    \n",
    "    rev_map = {v:k for k,v in idx_map.items()}\n",
    "    adj_map = {i:[] for i in range(N)}\n",
    "    with tqdm(total=len(adj_sp_2.row)) as pbar:\n",
    "        for i,j,v in zip(adj_sp_2.row, adj_sp_2.col, adj_sp_2.data):\n",
    "            if adj_mat[i, j] != 1 and v == 1:\n",
    "                adj_map[i].append(j)\n",
    "            pbar.update(1)\n",
    "#             print i,N\n",
    "                \n",
    "    while True:\n",
    "        src = training_node_list[np.random.randint(exist_N)]\n",
    "        \n",
    "#         choose neighbor link\n",
    "        if np.random.rand(1) <= neighbor_link_rate:\n",
    "        \n",
    "            i = idx_map[src]\n",
    "            high = len(adj_map[i])\n",
    "            while high == 0:\n",
    "                src = training_node_list[np.random.randint(exist_N)]\n",
    "                i = idx_map[src]\n",
    "                high = len(adj_map[i])\n",
    "                \n",
    "            idx = np.random.randint(high)\n",
    "            dst = adj_map[i][idx]\n",
    "            dst = rev_map[dst]\n",
    "        else:\n",
    "            dst = training_node_list[np.random.randint(exist_N)]\n",
    "            while adj_mat[idx_map[src], idx_map[dst]] == 1:\n",
    "                dst = training_node_list[np.random.randint(exist_N)]\n",
    "        Q, Q_w = xml_id_map[dst]\n",
    "        K, K_w = xml_id_map[src]\n",
    "        Q_fea = node_emb_dict[dst]\n",
    "        K_fea = node_emb_dict[src]\n",
    "        yield Q, K, Q_fea, K_fea, Q_w, K_w\n",
    "\n",
    "def val_data(edges, xml_id_map):\n",
    "    Q, K = [],[]\n",
    "    Q_f, K_f = [],[]\n",
    "    Q_w, K_w = [],[]\n",
    "    \n",
    "    for idx in range(edges.shape[0]):\n",
    "        src, dst = edges[idx, :]\n",
    "        q, q_w = xml_id_map[dst]\n",
    "        k, k_w = xml_id_map[src]\n",
    "        q_fea = node_emb_dict[dst]\n",
    "        k_fea = node_emb_dict[src]\n",
    "        \n",
    "        Q.append(q)\n",
    "        K.append(k)\n",
    "        Q_f.append(q_fea)\n",
    "        K_f.append(k_fea)\n",
    "        Q_w.append(q_w)\n",
    "        K_w.append(k_w)\n",
    "        \n",
    "        \n",
    "    Q = np.vstack(Q)\n",
    "    K = np.vstack(K)\n",
    "    Q_fea = np.vstack(Q_f)\n",
    "    K_fea = np.vstack(K_f)\n",
    "    Q_w = np.vstack(Q_w)\n",
    "    K_w = np.vstack(K_w)\n",
    "    \n",
    "    return Q, K, Q_fea, K_fea, Q_w, K_w\n",
    "    \n",
    "N = links.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "train_idx = idx[N//10:]\n",
    "val_idx = idx[:N//10]\n",
    "\n",
    "pos_G = positive_bootsrap_generator(links[train_idx,:], xml_id_map, node_emb_dict)\n",
    "training_node_list = list(set(links[train_idx,:].flatten().tolist()))\n",
    "neg_G = negative_bootsrap_generator(adj_mat, links, idx_map, xml_id_map, training_node_list, node_emb_dict)\n",
    "val_Q, val_K, val_Q_fea, val_K_fea, val_Q_w, val_K_w = val_data(links[val_idx,:], xml_id_map)\n",
    "q,k,q_f,k_f,q_w,k_w = next(pos_G)\n",
    "print(q.shape,k.shape, q_f.shape, k_f.shape, q_w.shape, k_w.shape)\n",
    "\n",
    "q,k,q_f,k_f,q_w,k_w = next(neg_G)\n",
    "print(q.shape,k.shape, q_f.shape, k_f.shape, q_w.shape, k_w.shape)\n",
    "print(val_Q.shape,val_K.shape, val_Q_fea.shape, val_K_fea.shape, val_Q_w.shape, val_K_w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Transformer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Word_Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Multi_Head_attention_layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type PositionwiseFeedForward. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Stack_Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/k123/env/python2.7.12/local/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 0101', 'loss_train: 1.3737', 'acc_train: 0.5300', 'loss_val: 0.6818', 'acc_val: 0.6000', 'time: 19.8478s')\n",
      "('iter: 0201', 'loss_train: 1.3782', 'acc_train: 0.5200', 'loss_val: 0.6827', 'acc_val: 0.5850', 'time: 39.8184s')\n",
      "('iter: 0301', 'loss_train: 1.3742', 'acc_train: 0.5333', 'loss_val: 0.6866', 'acc_val: 0.5533', 'time: 59.6018s')\n",
      "('iter: 0401', 'loss_train: 1.3659', 'acc_train: 0.5500', 'loss_val: 0.6788', 'acc_val: 0.5925', 'time: 80.2137s')\n",
      "('iter: 0501', 'loss_train: 1.3675', 'acc_train: 0.5400', 'loss_val: 0.6766', 'acc_val: 0.5920', 'time: 101.4449s')\n",
      "('iter: 0601', 'loss_train: 1.3658', 'acc_train: 0.5475', 'loss_val: 0.6770', 'acc_val: 0.6033', 'time: 124.9052s')\n",
      "('iter: 0701', 'loss_train: 1.3614', 'acc_train: 0.5536', 'loss_val: 0.6770', 'acc_val: 0.6057', 'time: 144.6061s')\n",
      "('iter: 0801', 'loss_train: 1.3600', 'acc_train: 0.5550', 'loss_val: 0.6825', 'acc_val: 0.5913', 'time: 164.4921s')\n",
      "('iter: 0901', 'loss_train: 1.3611', 'acc_train: 0.5589', 'loss_val: 0.6814', 'acc_val: 0.6011', 'time: 184.2896s')\n",
      "('iter: 1001', 'loss_train: 1.3571', 'acc_train: 0.5625', 'loss_val: 0.6782', 'acc_val: 0.6100', 'time: 204.4229s')\n",
      "('iter: 1101', 'loss_train: 1.3533', 'acc_train: 0.5714', 'loss_val: 0.6749', 'acc_val: 0.6191', 'time: 227.7850s')\n",
      "('iter: 1201', 'loss_train: 1.3536', 'acc_train: 0.5717', 'loss_val: 0.6730', 'acc_val: 0.6225', 'time: 249.8247s')\n",
      "('iter: 1301', 'loss_train: 1.3496', 'acc_train: 0.5765', 'loss_val: 0.6731', 'acc_val: 0.6238', 'time: 271.3078s')\n",
      "('iter: 1401', 'loss_train: 1.3493', 'acc_train: 0.5786', 'loss_val: 0.6750', 'acc_val: 0.6250', 'time: 292.5127s')\n",
      "('iter: 1501', 'loss_train: 1.3461', 'acc_train: 0.5813', 'loss_val: 0.6774', 'acc_val: 0.6273', 'time: 312.8352s')\n",
      "('iter: 1601', 'loss_train: 1.3457', 'acc_train: 0.5841', 'loss_val: 0.6810', 'acc_val: 0.6250', 'time: 333.1914s')\n",
      "('iter: 1701', 'loss_train: 1.3397', 'acc_train: 0.5897', 'loss_val: 0.6769', 'acc_val: 0.6300', 'time: 353.9983s')\n",
      "('iter: 1801', 'loss_train: 1.3392', 'acc_train: 0.5906', 'loss_val: 0.6768', 'acc_val: 0.6328', 'time: 375.1957s')\n",
      "('iter: 1901', 'loss_train: 1.3417', 'acc_train: 0.5903', 'loss_val: 0.6759', 'acc_val: 0.6342', 'time: 396.2682s')\n",
      "('iter: 2001', 'loss_train: 1.3422', 'acc_train: 0.5905', 'loss_val: 0.6744', 'acc_val: 0.6365', 'time: 417.0782s')\n",
      "('iter: 2101', 'loss_train: 1.3431', 'acc_train: 0.5900', 'loss_val: 0.6733', 'acc_val: 0.6395', 'time: 439.2101s')\n",
      "('iter: 2201', 'loss_train: 1.3420', 'acc_train: 0.5905', 'loss_val: 0.6734', 'acc_val: 0.6405', 'time: 460.0969s')\n",
      "('iter: 2301', 'loss_train: 1.3396', 'acc_train: 0.5922', 'loss_val: 0.6729', 'acc_val: 0.6417', 'time: 480.9161s')\n",
      "('iter: 2401', 'loss_train: 1.3386', 'acc_train: 0.5927', 'loss_val: 0.6720', 'acc_val: 0.6421', 'time: 501.1677s')\n",
      "('iter: 2501', 'loss_train: 1.3397', 'acc_train: 0.5930', 'loss_val: 0.6723', 'acc_val: 0.6448', 'time: 522.6709s')\n",
      "('iter: 2601', 'loss_train: 1.3393', 'acc_train: 0.5938', 'loss_val: 0.6722', 'acc_val: 0.6446', 'time: 544.2121s')\n",
      "('iter: 2701', 'loss_train: 1.3419', 'acc_train: 0.5909', 'loss_val: 0.6708', 'acc_val: 0.6467', 'time: 567.7795s')\n",
      "('iter: 2801', 'loss_train: 1.3401', 'acc_train: 0.5921', 'loss_val: 0.6707', 'acc_val: 0.6475', 'time: 588.1387s')\n",
      "('iter: 2901', 'loss_train: 1.3395', 'acc_train: 0.5931', 'loss_val: 0.6719', 'acc_val: 0.6452', 'time: 609.3646s')\n",
      "('iter: 3001', 'loss_train: 1.3355', 'acc_train: 0.5957', 'loss_val: 0.6724', 'acc_val: 0.6457', 'time: 629.1554s')\n",
      "('iter: 3101', 'loss_train: 1.3355', 'acc_train: 0.5950', 'loss_val: 0.6731', 'acc_val: 0.6432', 'time: 648.9282s')\n",
      "('iter: 3201', 'loss_train: 1.3335', 'acc_train: 0.5972', 'loss_val: 0.6721', 'acc_val: 0.6434', 'time: 668.8034s')\n",
      "('iter: 3301', 'loss_train: 1.3332', 'acc_train: 0.5958', 'loss_val: 0.6716', 'acc_val: 0.6445', 'time: 688.5968s')\n",
      "('iter: 3401', 'loss_train: 1.3319', 'acc_train: 0.5968', 'loss_val: 0.6705', 'acc_val: 0.6456', 'time: 708.7589s')\n",
      "('iter: 3501', 'loss_train: 1.3324', 'acc_train: 0.5964', 'loss_val: 0.6685', 'acc_val: 0.6491', 'time: 735.0247s')\n",
      "('iter: 3601', 'loss_train: 1.3314', 'acc_train: 0.5976', 'loss_val: 0.6666', 'acc_val: 0.6533', 'time: 770.6707s')\n",
      "('iter: 3701', 'loss_train: 1.3326', 'acc_train: 0.5964', 'loss_val: 0.6673', 'acc_val: 0.6516', 'time: 790.4724s')\n",
      "('iter: 3801', 'loss_train: 1.3325', 'acc_train: 0.5968', 'loss_val: 0.6661', 'acc_val: 0.6537', 'time: 811.1715s')\n",
      "('iter: 3901', 'loss_train: 1.3326', 'acc_train: 0.5969', 'loss_val: 0.6664', 'acc_val: 0.6531', 'time: 831.1004s')\n",
      "('iter: 4001', 'loss_train: 1.3315', 'acc_train: 0.5971', 'loss_val: 0.6660', 'acc_val: 0.6540', 'time: 851.3645s')\n",
      "('iter: 4101', 'loss_train: 1.3300', 'acc_train: 0.5979', 'loss_val: 0.6659', 'acc_val: 0.6549', 'time: 875.4362s')\n",
      "('iter: 4201', 'loss_train: 1.3300', 'acc_train: 0.5980', 'loss_val: 0.6660', 'acc_val: 0.6538', 'time: 896.0374s')\n",
      "('iter: 4301', 'loss_train: 1.3302', 'acc_train: 0.5977', 'loss_val: 0.6647', 'acc_val: 0.6565', 'time: 920.3698s')\n",
      "('iter: 4401', 'loss_train: 1.3302', 'acc_train: 0.5969', 'loss_val: 0.6642', 'acc_val: 0.6566', 'time: 942.5528s')\n",
      "('iter: 4501', 'loss_train: 1.3308', 'acc_train: 0.5967', 'loss_val: 0.6650', 'acc_val: 0.6562', 'time: 965.2327s')\n",
      "('iter: 5201', 'loss_train: 1.3280', 'acc_train: 0.6028', 'loss_val: 0.6641', 'acc_val: 0.6575', 'time: 1105.5630s')\n",
      "('iter: 5301', 'loss_train: 1.3264', 'acc_train: 0.6053', 'loss_val: 0.6632', 'acc_val: 0.6585', 'time: 1134.2901s')\n",
      "('iter: 5401', 'loss_train: 1.3256', 'acc_train: 0.6068', 'loss_val: 0.6624', 'acc_val: 0.6596', 'time: 1157.6749s')\n",
      "('iter: 5501', 'loss_train: 1.3243', 'acc_train: 0.6100', 'loss_val: 0.6627', 'acc_val: 0.6596', 'time: 1178.3884s')\n",
      "('iter: 5601', 'loss_train: 1.3249', 'acc_train: 0.6095', 'loss_val: 0.6622', 'acc_val: 0.6600', 'time: 1200.4230s')\n",
      "('iter: 5701', 'loss_train: 1.3233', 'acc_train: 0.6110', 'loss_val: 0.6608', 'acc_val: 0.6621', 'time: 1229.7553s')\n",
      "('iter: 5801', 'loss_train: 1.3239', 'acc_train: 0.6117', 'loss_val: 0.6617', 'acc_val: 0.6607', 'time: 1249.5368s')\n",
      "('iter: 5901', 'loss_train: 1.3232', 'acc_train: 0.6122', 'loss_val: 0.6621', 'acc_val: 0.6600', 'time: 1269.2991s')\n",
      "('iter: 6001', 'loss_train: 1.3225', 'acc_train: 0.6134', 'loss_val: 0.6615', 'acc_val: 0.6610', 'time: 1289.0991s')\n",
      "('iter: 6101', 'loss_train: 1.3229', 'acc_train: 0.6119', 'loss_val: 0.6608', 'acc_val: 0.6613', 'time: 1308.8924s')\n",
      "('iter: 6201', 'loss_train: 1.3227', 'acc_train: 0.6124', 'loss_val: 0.6614', 'acc_val: 0.6602', 'time: 1328.6574s')\n",
      "('iter: 6301', 'loss_train: 1.3228', 'acc_train: 0.6121', 'loss_val: 0.6608', 'acc_val: 0.6608', 'time: 1348.3766s')\n",
      "('iter: 6401', 'loss_train: 1.3233', 'acc_train: 0.6122', 'loss_val: 0.6601', 'acc_val: 0.6617', 'time: 1369.4817s')\n",
      "('iter: 6501', 'loss_train: 1.3225', 'acc_train: 0.6132', 'loss_val: 0.6604', 'acc_val: 0.6611', 'time: 1389.6964s')\n",
      "('iter: 6601', 'loss_train: 1.3230', 'acc_train: 0.6126', 'loss_val: 0.6594', 'acc_val: 0.6623', 'time: 1412.1498s')\n",
      "('iter: 6701', 'loss_train: 1.3229', 'acc_train: 0.6113', 'loss_val: 0.6587', 'acc_val: 0.6633', 'time: 1440.1448s')\n",
      "('iter: 6801', 'loss_train: 1.3230', 'acc_train: 0.6112', 'loss_val: 0.6591', 'acc_val: 0.6618', 'time: 1460.4898s')\n",
      "('iter: 6901', 'loss_train: 1.3228', 'acc_train: 0.6123', 'loss_val: 0.6587', 'acc_val: 0.6622', 'time: 1480.2560s')\n",
      "('iter: 7001', 'loss_train: 1.3232', 'acc_train: 0.6121', 'loss_val: 0.6588', 'acc_val: 0.6617', 'time: 1500.0947s')\n",
      "('iter: 7101', 'loss_train: 1.3233', 'acc_train: 0.6135', 'loss_val: 0.6587', 'acc_val: 0.6623', 'time: 1519.9022s')\n",
      "('iter: 7201', 'loss_train: 1.3232', 'acc_train: 0.6143', 'loss_val: 0.6587', 'acc_val: 0.6626', 'time: 1540.2740s')\n",
      "('iter: 7301', 'loss_train: 1.3234', 'acc_train: 0.6136', 'loss_val: 0.6585', 'acc_val: 0.6627', 'time: 1562.0777s')\n",
      "('iter: 7401', 'loss_train: 1.3240', 'acc_train: 0.6127', 'loss_val: 0.6582', 'acc_val: 0.6632', 'time: 1583.3968s')\n",
      "('iter: 7501', 'loss_train: 1.3239', 'acc_train: 0.6131', 'loss_val: 0.6585', 'acc_val: 0.6628', 'time: 1603.8503s')\n",
      "('iter: 7601', 'loss_train: 1.3232', 'acc_train: 0.6141', 'loss_val: 0.6583', 'acc_val: 0.6634', 'time: 1624.4332s')\n",
      "('iter: 7701', 'loss_train: 1.3236', 'acc_train: 0.6155', 'loss_val: 0.6581', 'acc_val: 0.6643', 'time: 1646.5199s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 7801', 'loss_train: 1.3228', 'acc_train: 0.6167', 'loss_val: 0.6574', 'acc_val: 0.6659', 'time: 1678.1083s')\n",
      "('iter: 7901', 'loss_train: 1.3225', 'acc_train: 0.6172', 'loss_val: 0.6566', 'acc_val: 0.6665', 'time: 1704.9600s')\n",
      "('iter: 8001', 'loss_train: 1.3230', 'acc_train: 0.6159', 'loss_val: 0.6567', 'acc_val: 0.6666', 'time: 1725.0678s')\n",
      "('iter: 8101', 'loss_train: 1.3224', 'acc_train: 0.6174', 'loss_val: 0.6568', 'acc_val: 0.6669', 'time: 1748.1393s')\n",
      "('iter: 8201', 'loss_train: 1.3216', 'acc_train: 0.6172', 'loss_val: 0.6562', 'acc_val: 0.6678', 'time: 1772.1571s')\n",
      "('iter: 8301', 'loss_train: 1.3223', 'acc_train: 0.6182', 'loss_val: 0.6564', 'acc_val: 0.6672', 'time: 1795.1672s')\n",
      "('iter: 8401', 'loss_train: 1.3230', 'acc_train: 0.6173', 'loss_val: 0.6561', 'acc_val: 0.6670', 'time: 1814.9661s')\n",
      "('iter: 8501', 'loss_train: 1.3230', 'acc_train: 0.6182', 'loss_val: 0.6557', 'acc_val: 0.6681', 'time: 1836.4558s')\n",
      "('iter: 8601', 'loss_train: 1.3233', 'acc_train: 0.6177', 'loss_val: 0.6555', 'acc_val: 0.6687', 'time: 1859.9843s')\n",
      "('iter: 8701', 'loss_train: 1.3234', 'acc_train: 0.6182', 'loss_val: 0.6555', 'acc_val: 0.6691', 'time: 1880.9796s')\n",
      "('iter: 8801', 'loss_train: 1.3233', 'acc_train: 0.6190', 'loss_val: 0.6551', 'acc_val: 0.6697', 'time: 1905.5495s')\n",
      "('iter: 8901', 'loss_train: 1.3225', 'acc_train: 0.6213', 'loss_val: 0.6552', 'acc_val: 0.6696', 'time: 1930.2602s')\n",
      "('iter: 9001', 'loss_train: 1.3218', 'acc_train: 0.6222', 'loss_val: 0.6555', 'acc_val: 0.6688', 'time: 1950.1821s')\n",
      "('iter: 9101', 'loss_train: 1.3217', 'acc_train: 0.6226', 'loss_val: 0.6553', 'acc_val: 0.6688', 'time: 1970.2468s')\n",
      "('iter: 9201', 'loss_train: 1.3216', 'acc_train: 0.6231', 'loss_val: 0.6557', 'acc_val: 0.6684', 'time: 1990.0991s')\n",
      "('iter: 9301', 'loss_train: 1.3218', 'acc_train: 0.6235', 'loss_val: 0.6557', 'acc_val: 0.6682', 'time: 2009.9936s')\n",
      "('iter: 9401', 'loss_train: 1.3219', 'acc_train: 0.6244', 'loss_val: 0.6558', 'acc_val: 0.6676', 'time: 2029.8550s')\n",
      "('iter: 9501', 'loss_train: 1.3210', 'acc_train: 0.6267', 'loss_val: 0.6556', 'acc_val: 0.6681', 'time: 2049.7383s')\n",
      "('iter: 9601', 'loss_train: 1.3208', 'acc_train: 0.6276', 'loss_val: 0.6549', 'acc_val: 0.6694', 'time: 2069.7887s')\n",
      "('iter: 9701', 'loss_train: 1.3206', 'acc_train: 0.6281', 'loss_val: 0.6550', 'acc_val: 0.6697', 'time: 2091.5384s')\n",
      "('iter: 9801', 'loss_train: 1.3207', 'acc_train: 0.6269', 'loss_val: 0.6548', 'acc_val: 0.6702', 'time: 2112.6804s')\n",
      "('iter: 9901', 'loss_train: 1.3205', 'acc_train: 0.6256', 'loss_val: 0.6541', 'acc_val: 0.6708', 'time: 2135.8446s')\n",
      "('iter: 10001', 'loss_train: 1.3197', 'acc_train: 0.6273', 'loss_val: 0.6530', 'acc_val: 0.6723', 'time: 2172.7330s')\n",
      "('iter: 10101', 'loss_train: 1.3192', 'acc_train: 0.6273', 'loss_val: 0.6528', 'acc_val: 0.6732', 'time: 2195.8416s')\n",
      "('iter: 10201', 'loss_train: 1.3181', 'acc_train: 0.6284', 'loss_val: 0.6522', 'acc_val: 0.6744', 'time: 2221.0940s')\n",
      "('iter: 10301', 'loss_train: 1.3177', 'acc_train: 0.6270', 'loss_val: 0.6522', 'acc_val: 0.6763', 'time: 2244.2051s')\n",
      "('iter: 10401', 'loss_train: 1.3176', 'acc_train: 0.6254', 'loss_val: 0.6527', 'acc_val: 0.6751', 'time: 2264.8153s')\n",
      "('iter: 10501', 'loss_train: 1.3167', 'acc_train: 0.6249', 'loss_val: 0.6519', 'acc_val: 0.6770', 'time: 2286.5239s')\n",
      "('iter: 10601', 'loss_train: 1.3157', 'acc_train: 0.6269', 'loss_val: 0.6511', 'acc_val: 0.6776', 'time: 2310.2648s')\n",
      "('iter: 10701', 'loss_train: 1.3150', 'acc_train: 0.6260', 'loss_val: 0.6510', 'acc_val: 0.6780', 'time: 2336.8815s')\n",
      "('iter: 10801', 'loss_train: 1.3145', 'acc_train: 0.6265', 'loss_val: 0.6500', 'acc_val: 0.6803', 'time: 2361.5155s')\n",
      "('iter: 10901', 'loss_train: 1.3135', 'acc_train: 0.6275', 'loss_val: 0.6496', 'acc_val: 0.6802', 'time: 2382.7293s')\n",
      "('iter: 11001', 'loss_train: 1.3127', 'acc_train: 0.6278', 'loss_val: 0.6499', 'acc_val: 0.6798', 'time: 2402.6882s')\n",
      "('iter: 11101', 'loss_train: 1.3130', 'acc_train: 0.6283', 'loss_val: 0.6500', 'acc_val: 0.6791', 'time: 2422.6095s')\n",
      "('iter: 11201', 'loss_train: 1.3121', 'acc_train: 0.6292', 'loss_val: 0.6497', 'acc_val: 0.6792', 'time: 2442.4736s')\n",
      "('iter: 11301', 'loss_train: 1.3115', 'acc_train: 0.6299', 'loss_val: 0.6494', 'acc_val: 0.6794', 'time: 2463.3062s')\n",
      "('iter: 11401', 'loss_train: 1.3112', 'acc_train: 0.6301', 'loss_val: 0.6492', 'acc_val: 0.6793', 'time: 2484.2540s')\n",
      "('iter: 11501', 'loss_train: 1.3108', 'acc_train: 0.6295', 'loss_val: 0.6477', 'acc_val: 0.6805', 'time: 2508.3194s')\n",
      "('iter: 11601', 'loss_train: 1.3103', 'acc_train: 0.6307', 'loss_val: 0.6472', 'acc_val: 0.6809', 'time: 2531.2894s')\n",
      "('iter: 11701', 'loss_train: 1.3115', 'acc_train: 0.6300', 'loss_val: 0.6481', 'acc_val: 0.6799', 'time: 2552.9313s')\n",
      "('iter: 11801', 'loss_train: 1.3107', 'acc_train: 0.6311', 'loss_val: 0.6479', 'acc_val: 0.6796', 'time: 2572.9045s')\n",
      "('iter: 11901', 'loss_train: 1.3100', 'acc_train: 0.6309', 'loss_val: 0.6476', 'acc_val: 0.6801', 'time: 2592.8019s')\n",
      "('iter: 12001', 'loss_train: 1.3097', 'acc_train: 0.6315', 'loss_val: 0.6477', 'acc_val: 0.6799', 'time: 2612.6958s')\n",
      "('iter: 12101', 'loss_train: 1.3082', 'acc_train: 0.6320', 'loss_val: 0.6469', 'acc_val: 0.6807', 'time: 2633.3197s')\n",
      "('iter: 12201', 'loss_train: 1.3074', 'acc_train: 0.6324', 'loss_val: 0.6465', 'acc_val: 0.6805', 'time: 2654.9279s')\n",
      "('iter: 12301', 'loss_train: 1.3073', 'acc_train: 0.6334', 'loss_val: 0.6466', 'acc_val: 0.6802', 'time: 2675.2629s')\n",
      "('iter: 12401', 'loss_train: 1.3063', 'acc_train: 0.6357', 'loss_val: 0.6462', 'acc_val: 0.6807', 'time: 2696.3586s')\n",
      "('iter: 12501', 'loss_train: 1.3060', 'acc_train: 0.6355', 'loss_val: 0.6458', 'acc_val: 0.6801', 'time: 2717.4377s')\n",
      "('iter: 12601', 'loss_train: 1.3057', 'acc_train: 0.6347', 'loss_val: 0.6467', 'acc_val: 0.6797', 'time: 2737.5142s')\n",
      "('iter: 12701', 'loss_train: 1.3043', 'acc_train: 0.6360', 'loss_val: 0.6471', 'acc_val: 0.6789', 'time: 2757.4664s')\n",
      "('iter: 12801', 'loss_train: 1.3045', 'acc_train: 0.6346', 'loss_val: 0.6468', 'acc_val: 0.6787', 'time: 2777.4283s')\n",
      "('iter: 12901', 'loss_train: 1.3044', 'acc_train: 0.6349', 'loss_val: 0.6459', 'acc_val: 0.6797', 'time: 2797.3784s')\n",
      "('iter: 13001', 'loss_train: 1.3052', 'acc_train: 0.6356', 'loss_val: 0.6452', 'acc_val: 0.6800', 'time: 2818.8187s')\n",
      "('iter: 13101', 'loss_train: 1.3048', 'acc_train: 0.6349', 'loss_val: 0.6448', 'acc_val: 0.6807', 'time: 2840.5803s')\n",
      "('iter: 13201', 'loss_train: 1.3047', 'acc_train: 0.6349', 'loss_val: 0.6450', 'acc_val: 0.6805', 'time: 2860.8250s')\n",
      "('iter: 13301', 'loss_train: 1.3045', 'acc_train: 0.6347', 'loss_val: 0.6445', 'acc_val: 0.6810', 'time: 2881.7110s')\n",
      "('iter: 13401', 'loss_train: 1.3046', 'acc_train: 0.6361', 'loss_val: 0.6448', 'acc_val: 0.6806', 'time: 2902.0461s')\n",
      "('iter: 13501', 'loss_train: 1.3043', 'acc_train: 0.6363', 'loss_val: 0.6455', 'acc_val: 0.6788', 'time: 2922.5018s')\n",
      "('iter: 13601', 'loss_train: 1.3042', 'acc_train: 0.6362', 'loss_val: 0.6456', 'acc_val: 0.6780', 'time: 2942.7126s')\n",
      "('iter: 13701', 'loss_train: 1.3028', 'acc_train: 0.6391', 'loss_val: 0.6451', 'acc_val: 0.6789', 'time: 2962.7102s')\n",
      "('iter: 13801', 'loss_train: 1.3026', 'acc_train: 0.6379', 'loss_val: 0.6449', 'acc_val: 0.6790', 'time: 2982.6789s')\n",
      "('iter: 13901', 'loss_train: 1.3016', 'acc_train: 0.6365', 'loss_val: 0.6448', 'acc_val: 0.6787', 'time: 3002.7359s')\n",
      "('iter: 14001', 'loss_train: 1.3019', 'acc_train: 0.6361', 'loss_val: 0.6453', 'acc_val: 0.6776', 'time: 3022.7167s')\n",
      "('iter: 14101', 'loss_train: 1.3023', 'acc_train: 0.6354', 'loss_val: 0.6453', 'acc_val: 0.6772', 'time: 3042.6826s')\n",
      "('iter: 14201', 'loss_train: 1.3020', 'acc_train: 0.6351', 'loss_val: 0.6450', 'acc_val: 0.6774', 'time: 3062.6401s')\n",
      "('iter: 14301', 'loss_train: 1.3012', 'acc_train: 0.6355', 'loss_val: 0.6458', 'acc_val: 0.6755', 'time: 3082.6297s')\n",
      "('iter: 14401', 'loss_train: 1.3010', 'acc_train: 0.6357', 'loss_val: 0.6458', 'acc_val: 0.6757', 'time: 3102.6424s')\n",
      "('iter: 14501', 'loss_train: 1.3003', 'acc_train: 0.6346', 'loss_val: 0.6453', 'acc_val: 0.6760', 'time: 3122.6244s')\n",
      "('iter: 14601', 'loss_train: 1.2999', 'acc_train: 0.6356', 'loss_val: 0.6441', 'acc_val: 0.6772', 'time: 3143.0568s')\n",
      "('iter: 14701', 'loss_train: 1.2991', 'acc_train: 0.6366', 'loss_val: 0.6438', 'acc_val: 0.6776', 'time: 3165.1001s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 14801', 'loss_train: 1.2987', 'acc_train: 0.6376', 'loss_val: 0.6443', 'acc_val: 0.6769', 'time: 3184.9736s')\n",
      "('iter: 14901', 'loss_train: 1.2988', 'acc_train: 0.6388', 'loss_val: 0.6436', 'acc_val: 0.6772', 'time: 3206.0012s')\n",
      "('iter: 15001', 'loss_train: 1.2981', 'acc_train: 0.6381', 'loss_val: 0.6432', 'acc_val: 0.6770', 'time: 3227.2217s')\n",
      "('iter: 15101', 'loss_train: 1.2981', 'acc_train: 0.6385', 'loss_val: 0.6435', 'acc_val: 0.6769', 'time: 3247.2020s')\n",
      "('iter: 15201', 'loss_train: 1.2977', 'acc_train: 0.6381', 'loss_val: 0.6439', 'acc_val: 0.6760', 'time: 3267.1077s')\n",
      "('iter: 15301', 'loss_train: 1.2984', 'acc_train: 0.6379', 'loss_val: 0.6445', 'acc_val: 0.6751', 'time: 3286.9840s')\n",
      "('iter: 15401', 'loss_train: 1.2980', 'acc_train: 0.6391', 'loss_val: 0.6442', 'acc_val: 0.6752', 'time: 3306.8589s')\n",
      "('iter: 15501', 'loss_train: 1.2987', 'acc_train: 0.6392', 'loss_val: 0.6442', 'acc_val: 0.6746', 'time: 3326.7503s')\n",
      "('iter: 15601', 'loss_train: 1.2980', 'acc_train: 0.6388', 'loss_val: 0.6446', 'acc_val: 0.6739', 'time: 3346.7015s')\n",
      "('iter: 15701', 'loss_train: 1.2987', 'acc_train: 0.6385', 'loss_val: 0.6449', 'acc_val: 0.6728', 'time: 3366.6748s')\n",
      "('iter: 15801', 'loss_train: 1.2980', 'acc_train: 0.6387', 'loss_val: 0.6443', 'acc_val: 0.6736', 'time: 3386.5776s')\n",
      "('iter: 15901', 'loss_train: 1.2977', 'acc_train: 0.6389', 'loss_val: 0.6441', 'acc_val: 0.6736', 'time: 3406.4407s')\n",
      "('iter: 16001', 'loss_train: 1.2977', 'acc_train: 0.6379', 'loss_val: 0.6446', 'acc_val: 0.6724', 'time: 3426.2909s')\n",
      "('iter: 16101', 'loss_train: 1.2960', 'acc_train: 0.6398', 'loss_val: 0.6442', 'acc_val: 0.6726', 'time: 3446.1361s')\n",
      "('iter: 16201', 'loss_train: 1.2960', 'acc_train: 0.6395', 'loss_val: 0.6436', 'acc_val: 0.6733', 'time: 3465.9821s')\n",
      "('iter: 16301', 'loss_train: 1.2959', 'acc_train: 0.6386', 'loss_val: 0.6440', 'acc_val: 0.6721', 'time: 3485.8215s')\n",
      "('iter: 16401', 'loss_train: 1.2953', 'acc_train: 0.6391', 'loss_val: 0.6438', 'acc_val: 0.6720', 'time: 3505.6727s')\n",
      "('iter: 16501', 'loss_train: 1.2949', 'acc_train: 0.6400', 'loss_val: 0.6434', 'acc_val: 0.6721', 'time: 3525.6097s')\n",
      "('iter: 16601', 'loss_train: 1.2944', 'acc_train: 0.6384', 'loss_val: 0.6437', 'acc_val: 0.6718', 'time: 3545.4567s')\n",
      "('iter: 16701', 'loss_train: 1.2946', 'acc_train: 0.6390', 'loss_val: 0.6434', 'acc_val: 0.6714', 'time: 3565.2974s')\n",
      "('iter: 16801', 'loss_train: 1.2937', 'acc_train: 0.6392', 'loss_val: 0.6427', 'acc_val: 0.6725', 'time: 3585.9807s')\n",
      "('iter: 16901', 'loss_train: 1.2928', 'acc_train: 0.6395', 'loss_val: 0.6429', 'acc_val: 0.6721', 'time: 3605.8001s')\n",
      "('iter: 17001', 'loss_train: 1.2922', 'acc_train: 0.6397', 'loss_val: 0.6423', 'acc_val: 0.6724', 'time: 3626.7699s')\n",
      "('iter: 17101', 'loss_train: 1.2916', 'acc_train: 0.6387', 'loss_val: 0.6420', 'acc_val: 0.6724', 'time: 3648.2929s')\n",
      "('iter: 17201', 'loss_train: 1.2912', 'acc_train: 0.6389', 'loss_val: 0.6421', 'acc_val: 0.6712', 'time: 3668.2182s')\n",
      "('iter: 17301', 'loss_train: 1.2904', 'acc_train: 0.6396', 'loss_val: 0.6420', 'acc_val: 0.6708', 'time: 3688.3007s')\n",
      "('iter: 17401', 'loss_train: 1.2902', 'acc_train: 0.6379', 'loss_val: 0.6417', 'acc_val: 0.6701', 'time: 3709.0307s')\n",
      "('iter: 17501', 'loss_train: 1.2893', 'acc_train: 0.6392', 'loss_val: 0.6413', 'acc_val: 0.6703', 'time: 3729.8222s')\n",
      "('iter: 17601', 'loss_train: 1.2890', 'acc_train: 0.6402', 'loss_val: 0.6415', 'acc_val: 0.6693', 'time: 3749.7264s')\n",
      "('iter: 17701', 'loss_train: 1.2884', 'acc_train: 0.6398', 'loss_val: 0.6410', 'acc_val: 0.6687', 'time: 3772.1354s')\n",
      "('iter: 17801', 'loss_train: 1.2880', 'acc_train: 0.6408', 'loss_val: 0.6412', 'acc_val: 0.6671', 'time: 3791.9587s')\n",
      "('iter: 17901', 'loss_train: 1.2881', 'acc_train: 0.6395', 'loss_val: 0.6419', 'acc_val: 0.6659', 'time: 3811.7871s')\n",
      "('iter: 18001', 'loss_train: 1.2871', 'acc_train: 0.6402', 'loss_val: 0.6417', 'acc_val: 0.6655', 'time: 3831.6574s')\n",
      "('iter: 18101', 'loss_train: 1.2866', 'acc_train: 0.6411', 'loss_val: 0.6411', 'acc_val: 0.6652', 'time: 3851.5013s')\n",
      "('iter: 18201', 'loss_train: 1.2869', 'acc_train: 0.6408', 'loss_val: 0.6412', 'acc_val: 0.6647', 'time: 3871.4124s')\n",
      "('iter: 18301', 'loss_train: 1.2858', 'acc_train: 0.6427', 'loss_val: 0.6407', 'acc_val: 0.6648', 'time: 3891.4645s')\n",
      "('iter: 18401', 'loss_train: 1.2848', 'acc_train: 0.6423', 'loss_val: 0.6406', 'acc_val: 0.6650', 'time: 3913.4776s')\n",
      "('iter: 18501', 'loss_train: 1.2842', 'acc_train: 0.6425', 'loss_val: 0.6408', 'acc_val: 0.6635', 'time: 3933.3909s')\n",
      "('iter: 18601', 'loss_train: 1.2843', 'acc_train: 0.6415', 'loss_val: 0.6410', 'acc_val: 0.6626', 'time: 3953.2132s')\n",
      "('iter: 18701', 'loss_train: 1.2840', 'acc_train: 0.6393', 'loss_val: 0.6409', 'acc_val: 0.6622', 'time: 3973.1046s')\n",
      "('iter: 18801', 'loss_train: 1.2839', 'acc_train: 0.6399', 'loss_val: 0.6409', 'acc_val: 0.6618', 'time: 3993.0890s')\n",
      "('iter: 18901', 'loss_train: 1.2829', 'acc_train: 0.6414', 'loss_val: 0.6403', 'acc_val: 0.6626', 'time: 4013.1519s')\n",
      "('iter: 19001', 'loss_train: 1.2827', 'acc_train: 0.6422', 'loss_val: 0.6394', 'acc_val: 0.6639', 'time: 4035.6445s')\n",
      "('iter: 19101', 'loss_train: 1.2827', 'acc_train: 0.6430', 'loss_val: 0.6394', 'acc_val: 0.6637', 'time: 4055.5692s')\n",
      "('iter: 19201', 'loss_train: 1.2814', 'acc_train: 0.6452', 'loss_val: 0.6391', 'acc_val: 0.6636', 'time: 4075.5993s')\n",
      "('iter: 19301', 'loss_train: 1.2811', 'acc_train: 0.6453', 'loss_val: 0.6383', 'acc_val: 0.6646', 'time: 4098.7189s')\n",
      "('iter: 19401', 'loss_train: 1.2804', 'acc_train: 0.6450', 'loss_val: 0.6387', 'acc_val: 0.6642', 'time: 4118.8661s')\n",
      "('iter: 19501', 'loss_train: 1.2814', 'acc_train: 0.6445', 'loss_val: 0.6385', 'acc_val: 0.6638', 'time: 4138.8976s')\n",
      "('iter: 19601', 'loss_train: 1.2809', 'acc_train: 0.6440', 'loss_val: 0.6388', 'acc_val: 0.6627', 'time: 4158.9042s')\n",
      "('iter: 19701', 'loss_train: 1.2806', 'acc_train: 0.6425', 'loss_val: 0.6384', 'acc_val: 0.6624', 'time: 4178.9708s')\n",
      "('iter: 19801', 'loss_train: 1.2802', 'acc_train: 0.6412', 'loss_val: 0.6381', 'acc_val: 0.6623', 'time: 4200.6376s')\n",
      "('iter: 20401', 'loss_train: 1.2789', 'acc_train: 0.6424', 'loss_val: 0.6384', 'acc_val: 0.6580', 'time: 4321.0771s')\n",
      "('iter: 20501', 'loss_train: 1.2778', 'acc_train: 0.6438', 'loss_val: 0.6385', 'acc_val: 0.6567', 'time: 4341.0560s')\n",
      "('iter: 20601', 'loss_train: 1.2776', 'acc_train: 0.6446', 'loss_val: 0.6380', 'acc_val: 0.6570', 'time: 4361.4022s')\n",
      "('iter: 20701', 'loss_train: 1.2765', 'acc_train: 0.6471', 'loss_val: 0.6377', 'acc_val: 0.6568', 'time: 4382.0376s')\n",
      "('iter: 20801', 'loss_train: 1.2758', 'acc_train: 0.6486', 'loss_val: 0.6380', 'acc_val: 0.6561', 'time: 4402.1918s')\n",
      "('iter: 20901', 'loss_train: 1.2754', 'acc_train: 0.6484', 'loss_val: 0.6380', 'acc_val: 0.6560', 'time: 4423.0007s')\n",
      "('iter: 21001', 'loss_train: 1.2762', 'acc_train: 0.6482', 'loss_val: 0.6372', 'acc_val: 0.6562', 'time: 4444.5727s')\n",
      "('iter: 21101', 'loss_train: 1.2752', 'acc_train: 0.6475', 'loss_val: 0.6367', 'acc_val: 0.6561', 'time: 4466.5810s')\n",
      "('iter: 21201', 'loss_train: 1.2739', 'acc_train: 0.6494', 'loss_val: 0.6366', 'acc_val: 0.6564', 'time: 4488.6515s')\n",
      "('iter: 21301', 'loss_train: 1.2738', 'acc_train: 0.6508', 'loss_val: 0.6367', 'acc_val: 0.6560', 'time: 4509.5856s')\n",
      "('iter: 21401', 'loss_train: 1.2731', 'acc_train: 0.6520', 'loss_val: 0.6365', 'acc_val: 0.6560', 'time: 4529.7753s')\n",
      "('iter: 21501', 'loss_train: 1.2727', 'acc_train: 0.6516', 'loss_val: 0.6379', 'acc_val: 0.6542', 'time: 4549.7272s')\n",
      "('iter: 21601', 'loss_train: 1.2720', 'acc_train: 0.6533', 'loss_val: 0.6366', 'acc_val: 0.6551', 'time: 4569.6984s')\n",
      "('iter: 21701', 'loss_train: 1.2703', 'acc_train: 0.6544', 'loss_val: 0.6353', 'acc_val: 0.6562', 'time: 4592.0174s')\n",
      "('iter: 21801', 'loss_train: 1.2711', 'acc_train: 0.6535', 'loss_val: 0.6348', 'acc_val: 0.6562', 'time: 4614.1384s')\n",
      "('iter: 21901', 'loss_train: 1.2704', 'acc_train: 0.6540', 'loss_val: 0.6345', 'acc_val: 0.6557', 'time: 4636.6002s')\n",
      "('iter: 22001', 'loss_train: 1.2703', 'acc_train: 0.6537', 'loss_val: 0.6338', 'acc_val: 0.6560', 'time: 4658.5900s')\n",
      "('iter: 22101', 'loss_train: 1.2705', 'acc_train: 0.6547', 'loss_val: 0.6343', 'acc_val: 0.6543', 'time: 4681.3741s')\n",
      "('iter: 22201', 'loss_train: 1.2697', 'acc_train: 0.6551', 'loss_val: 0.6342', 'acc_val: 0.6544', 'time: 4705.2010s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 22301', 'loss_train: 1.2688', 'acc_train: 0.6552', 'loss_val: 0.6333', 'acc_val: 0.6552', 'time: 4730.6681s')\n",
      "('iter: 22401', 'loss_train: 1.2680', 'acc_train: 0.6580', 'loss_val: 0.6328', 'acc_val: 0.6555', 'time: 4754.0004s')\n",
      "('iter: 22501', 'loss_train: 1.2669', 'acc_train: 0.6580', 'loss_val: 0.6327', 'acc_val: 0.6557', 'time: 4774.0279s')\n",
      "('iter: 22601', 'loss_train: 1.2659', 'acc_train: 0.6579', 'loss_val: 0.6307', 'acc_val: 0.6567', 'time: 4799.1397s')\n",
      "('iter: 22701', 'loss_train: 1.2660', 'acc_train: 0.6586', 'loss_val: 0.6302', 'acc_val: 0.6566', 'time: 4822.2062s')\n",
      "('iter: 22801', 'loss_train: 1.2655', 'acc_train: 0.6582', 'loss_val: 0.6307', 'acc_val: 0.6558', 'time: 4842.2470s')\n",
      "('iter: 22901', 'loss_train: 1.2652', 'acc_train: 0.6583', 'loss_val: 0.6312', 'acc_val: 0.6546', 'time: 4862.2176s')\n",
      "('iter: 23001', 'loss_train: 1.2642', 'acc_train: 0.6583', 'loss_val: 0.6315', 'acc_val: 0.6537', 'time: 4882.1784s')\n",
      "('iter: 23101', 'loss_train: 1.2632', 'acc_train: 0.6586', 'loss_val: 0.6306', 'acc_val: 0.6537', 'time: 4902.2461s')\n",
      "('iter: 23201', 'loss_train: 1.2631', 'acc_train: 0.6576', 'loss_val: 0.6297', 'acc_val: 0.6543', 'time: 4922.5779s')\n",
      "('iter: 23301', 'loss_train: 1.2620', 'acc_train: 0.6571', 'loss_val: 0.6306', 'acc_val: 0.6530', 'time: 4942.5228s')\n",
      "('iter: 23401', 'loss_train: 1.2619', 'acc_train: 0.6571', 'loss_val: 0.6304', 'acc_val: 0.6525', 'time: 4962.5095s')\n",
      "('iter: 23501', 'loss_train: 1.2609', 'acc_train: 0.6578', 'loss_val: 0.6296', 'acc_val: 0.6534', 'time: 4982.9650s')\n",
      "('iter: 23601', 'loss_train: 1.2609', 'acc_train: 0.6596', 'loss_val: 0.6302', 'acc_val: 0.6523', 'time: 5002.9251s')\n",
      "('iter: 23701', 'loss_train: 1.2610', 'acc_train: 0.6608', 'loss_val: 0.6304', 'acc_val: 0.6514', 'time: 5022.8906s')\n",
      "('iter: 23801', 'loss_train: 1.2600', 'acc_train: 0.6612', 'loss_val: 0.6310', 'acc_val: 0.6502', 'time: 5042.8593s')\n",
      "('iter: 23901', 'loss_train: 1.2597', 'acc_train: 0.6602', 'loss_val: 0.6306', 'acc_val: 0.6506', 'time: 5062.8808s')\n",
      "('iter: 24001', 'loss_train: 1.2593', 'acc_train: 0.6597', 'loss_val: 0.6296', 'acc_val: 0.6510', 'time: 5082.8875s')\n",
      "('iter: 24101', 'loss_train: 1.2596', 'acc_train: 0.6587', 'loss_val: 0.6290', 'acc_val: 0.6515', 'time: 5105.2561s')\n",
      "('iter: 24201', 'loss_train: 1.2586', 'acc_train: 0.6576', 'loss_val: 0.6291', 'acc_val: 0.6516', 'time: 5126.0619s')\n",
      "('iter: 24301', 'loss_train: 1.2591', 'acc_train: 0.6576', 'loss_val: 0.6284', 'acc_val: 0.6525', 'time: 5147.4413s')\n",
      "('iter: 24401', 'loss_train: 1.2582', 'acc_train: 0.6586', 'loss_val: 0.6280', 'acc_val: 0.6529', 'time: 5167.9377s')\n",
      "('iter: 24501', 'loss_train: 1.2573', 'acc_train: 0.6594', 'loss_val: 0.6271', 'acc_val: 0.6532', 'time: 5190.3080s')\n",
      "('iter: 24601', 'loss_train: 1.2580', 'acc_train: 0.6582', 'loss_val: 0.6289', 'acc_val: 0.6507', 'time: 5210.7214s')\n",
      "('iter: 24701', 'loss_train: 1.2581', 'acc_train: 0.6589', 'loss_val: 0.6282', 'acc_val: 0.6519', 'time: 5230.5708s')\n",
      "('iter: 24801', 'loss_train: 1.2584', 'acc_train: 0.6591', 'loss_val: 0.6270', 'acc_val: 0.6527', 'time: 5250.8122s')\n",
      "('iter: 24901', 'loss_train: 1.2578', 'acc_train: 0.6601', 'loss_val: 0.6273', 'acc_val: 0.6527', 'time: 5270.6735s')\n",
      "('iter: 25001', 'loss_train: 1.2584', 'acc_train: 0.6585', 'loss_val: 0.6280', 'acc_val: 0.6518', 'time: 5290.5775s')\n",
      "('iter: 25101', 'loss_train: 1.2576', 'acc_train: 0.6591', 'loss_val: 0.6274', 'acc_val: 0.6512', 'time: 5310.5243s')\n",
      "('iter: 25201', 'loss_train: 1.2577', 'acc_train: 0.6585', 'loss_val: 0.6276', 'acc_val: 0.6509', 'time: 5330.5042s')\n",
      "('iter: 25301', 'loss_train: 1.2575', 'acc_train: 0.6584', 'loss_val: 0.6270', 'acc_val: 0.6510', 'time: 5350.5978s')\n",
      "('iter: 25401', 'loss_train: 1.2578', 'acc_train: 0.6592', 'loss_val: 0.6265', 'acc_val: 0.6511', 'time: 5372.1080s')\n",
      "('iter: 25501', 'loss_train: 1.2570', 'acc_train: 0.6581', 'loss_val: 0.6258', 'acc_val: 0.6520', 'time: 5394.6151s')\n",
      "('iter: 25601', 'loss_train: 1.2565', 'acc_train: 0.6579', 'loss_val: 0.6247', 'acc_val: 0.6535', 'time: 5418.4627s')\n",
      "('iter: 25701', 'loss_train: 1.2560', 'acc_train: 0.6563', 'loss_val: 0.6239', 'acc_val: 0.6541', 'time: 5441.3674s')\n",
      "('iter: 25801', 'loss_train: 1.2558', 'acc_train: 0.6550', 'loss_val: 0.6239', 'acc_val: 0.6535', 'time: 5461.5080s')\n",
      "('iter: 25901', 'loss_train: 1.2553', 'acc_train: 0.6553', 'loss_val: 0.6236', 'acc_val: 0.6535', 'time: 5482.0311s')\n",
      "('iter: 26001', 'loss_train: 1.2552', 'acc_train: 0.6560', 'loss_val: 0.6230', 'acc_val: 0.6545', 'time: 5503.5439s')\n",
      "('iter: 26101', 'loss_train: 1.2552', 'acc_train: 0.6566', 'loss_val: 0.6232', 'acc_val: 0.6542', 'time: 5524.3350s')\n",
      "('iter: 26201', 'loss_train: 1.2552', 'acc_train: 0.6542', 'loss_val: 0.6233', 'acc_val: 0.6544', 'time: 5544.5948s')\n",
      "('iter: 26301', 'loss_train: 1.2537', 'acc_train: 0.6548', 'loss_val: 0.6227', 'acc_val: 0.6551', 'time: 5564.7095s')\n",
      "('iter: 26401', 'loss_train: 1.2532', 'acc_train: 0.6539', 'loss_val: 0.6229', 'acc_val: 0.6550', 'time: 5584.9205s')\n",
      "('iter: 26501', 'loss_train: 1.2529', 'acc_train: 0.6543', 'loss_val: 0.6227', 'acc_val: 0.6552', 'time: 5606.3667s')\n",
      "('iter: 26601', 'loss_train: 1.2526', 'acc_train: 0.6543', 'loss_val: 0.6230', 'acc_val: 0.6541', 'time: 5626.4580s')\n",
      "('iter: 26701', 'loss_train: 1.2518', 'acc_train: 0.6543', 'loss_val: 0.6232', 'acc_val: 0.6543', 'time: 5646.5951s')\n",
      "('iter: 26801', 'loss_train: 1.2519', 'acc_train: 0.6557', 'loss_val: 0.6238', 'acc_val: 0.6532', 'time: 5666.6234s')\n",
      "('iter: 26901', 'loss_train: 1.2516', 'acc_train: 0.6565', 'loss_val: 0.6240', 'acc_val: 0.6527', 'time: 5686.7810s')\n",
      "('iter: 27001', 'loss_train: 1.2520', 'acc_train: 0.6567', 'loss_val: 0.6252', 'acc_val: 0.6516', 'time: 5706.8117s')\n",
      "('iter: 27101', 'loss_train: 1.2520', 'acc_train: 0.6554', 'loss_val: 0.6250', 'acc_val: 0.6513', 'time: 5726.8332s')\n",
      "('iter: 27201', 'loss_train: 1.2512', 'acc_train: 0.6560', 'loss_val: 0.6242', 'acc_val: 0.6524', 'time: 5746.8379s')\n",
      "('iter: 27301', 'loss_train: 1.2506', 'acc_train: 0.6564', 'loss_val: 0.6237', 'acc_val: 0.6526', 'time: 5766.8621s')\n",
      "('iter: 27401', 'loss_train: 1.2495', 'acc_train: 0.6552', 'loss_val: 0.6230', 'acc_val: 0.6533', 'time: 5787.0199s')\n",
      "('iter: 27501', 'loss_train: 1.2498', 'acc_train: 0.6547', 'loss_val: 0.6230', 'acc_val: 0.6533', 'time: 5807.2746s')\n",
      "('iter: 27601', 'loss_train: 1.2492', 'acc_train: 0.6553', 'loss_val: 0.6220', 'acc_val: 0.6545', 'time: 5829.1837s')\n",
      "('iter: 27701', 'loss_train: 1.2489', 'acc_train: 0.6552', 'loss_val: 0.6223', 'acc_val: 0.6545', 'time: 5850.4668s')\n",
      "('iter: 27801', 'loss_train: 1.2495', 'acc_train: 0.6546', 'loss_val: 0.6222', 'acc_val: 0.6544', 'time: 5871.6390s')\n",
      "('iter: 27901', 'loss_train: 1.2485', 'acc_train: 0.6563', 'loss_val: 0.6219', 'acc_val: 0.6545', 'time: 5905.4181s')\n",
      "('iter: 28001', 'loss_train: 1.2486', 'acc_train: 0.6558', 'loss_val: 0.6217', 'acc_val: 0.6544', 'time: 5931.6787s')\n",
      "('iter: 28101', 'loss_train: 1.2486', 'acc_train: 0.6558', 'loss_val: 0.6216', 'acc_val: 0.6549', 'time: 5951.6242s')\n",
      "('iter: 28201', 'loss_train: 1.2477', 'acc_train: 0.6578', 'loss_val: 0.6206', 'acc_val: 0.6554', 'time: 5974.1200s')\n",
      "('iter: 28301', 'loss_train: 1.2474', 'acc_train: 0.6582', 'loss_val: 0.6218', 'acc_val: 0.6548', 'time: 5994.1907s')\n",
      "('iter: 28401', 'loss_train: 1.2467', 'acc_train: 0.6586', 'loss_val: 0.6218', 'acc_val: 0.6542', 'time: 6018.3710s')\n",
      "('iter: 28501', 'loss_train: 1.2463', 'acc_train: 0.6587', 'loss_val: 0.6211', 'acc_val: 0.6547', 'time: 6047.5277s')\n",
      "('iter: 28601', 'loss_train: 1.2450', 'acc_train: 0.6586', 'loss_val: 0.6204', 'acc_val: 0.6550', 'time: 6077.5583s')\n",
      "('iter: 28701', 'loss_train: 1.2449', 'acc_train: 0.6584', 'loss_val: 0.6198', 'acc_val: 0.6553', 'time: 6109.6693s')\n",
      "('iter: 28801', 'loss_train: 1.2448', 'acc_train: 0.6579', 'loss_val: 0.6199', 'acc_val: 0.6551', 'time: 6139.3419s')\n",
      "('iter: 28901', 'loss_train: 1.2449', 'acc_train: 0.6592', 'loss_val: 0.6204', 'acc_val: 0.6535', 'time: 6168.6876s')\n",
      "('iter: 29001', 'loss_train: 1.2448', 'acc_train: 0.6592', 'loss_val: 0.6205', 'acc_val: 0.6524', 'time: 6197.8938s')\n",
      "('iter: 29101', 'loss_train: 1.2435', 'acc_train: 0.6608', 'loss_val: 0.6202', 'acc_val: 0.6523', 'time: 6227.1486s')\n",
      "('iter: 29201', 'loss_train: 1.2428', 'acc_train: 0.6617', 'loss_val: 0.6191', 'acc_val: 0.6528', 'time: 6259.2073s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 29301', 'loss_train: 1.2413', 'acc_train: 0.6630', 'loss_val: 0.6200', 'acc_val: 0.6513', 'time: 6288.3982s')\n",
      "('iter: 29401', 'loss_train: 1.2413', 'acc_train: 0.6619', 'loss_val: 0.6188', 'acc_val: 0.6523', 'time: 6318.6438s')\n",
      "('iter: 29501', 'loss_train: 1.2398', 'acc_train: 0.6623', 'loss_val: 0.6189', 'acc_val: 0.6517', 'time: 6349.2229s')\n",
      "('iter: 29601', 'loss_train: 1.2387', 'acc_train: 0.6649', 'loss_val: 0.6190', 'acc_val: 0.6511', 'time: 6378.4489s')\n",
      "('iter: 29701', 'loss_train: 1.2379', 'acc_train: 0.6657', 'loss_val: 0.6185', 'acc_val: 0.6514', 'time: 6407.9489s')\n",
      "('iter: 29801', 'loss_train: 1.2376', 'acc_train: 0.6664', 'loss_val: 0.6188', 'acc_val: 0.6504', 'time: 6437.2298s')\n",
      "('iter: 29901', 'loss_train: 1.2367', 'acc_train: 0.6659', 'loss_val: 0.6183', 'acc_val: 0.6504', 'time: 6466.6216s')\n",
      "('iter: 30001', 'loss_train: 1.2375', 'acc_train: 0.6658', 'loss_val: 0.6184', 'acc_val: 0.6507', 'time: 6496.5610s')\n",
      "('iter: 30101', 'loss_train: 1.2370', 'acc_train: 0.6651', 'loss_val: 0.6183', 'acc_val: 0.6501', 'time: 6527.7784s')\n",
      "('iter: 30201', 'loss_train: 1.2368', 'acc_train: 0.6647', 'loss_val: 0.6179', 'acc_val: 0.6504', 'time: 6556.9349s')\n",
      "('iter: 30301', 'loss_train: 1.2365', 'acc_train: 0.6650', 'loss_val: 0.6175', 'acc_val: 0.6506', 'time: 6586.0057s')\n",
      "('iter: 30401', 'loss_train: 1.2349', 'acc_train: 0.6664', 'loss_val: 0.6167', 'acc_val: 0.6512', 'time: 6618.7735s')\n",
      "('iter: 30501', 'loss_train: 1.2354', 'acc_train: 0.6665', 'loss_val: 0.6169', 'acc_val: 0.6511', 'time: 6649.8548s')\n",
      "('iter: 30601', 'loss_train: 1.2343', 'acc_train: 0.6676', 'loss_val: 0.6166', 'acc_val: 0.6506', 'time: 6683.2633s')\n",
      "('iter: 30701', 'loss_train: 1.2343', 'acc_train: 0.6688', 'loss_val: 0.6164', 'acc_val: 0.6512', 'time: 6706.1648s')\n",
      "('iter: 30801', 'loss_train: 1.2350', 'acc_train: 0.6681', 'loss_val: 0.6157', 'acc_val: 0.6518', 'time: 6727.9132s')\n",
      "('iter: 30901', 'loss_train: 1.2346', 'acc_train: 0.6682', 'loss_val: 0.6152', 'acc_val: 0.6519', 'time: 6751.1588s')\n",
      "('iter: 31001', 'loss_train: 1.2328', 'acc_train: 0.6696', 'loss_val: 0.6151', 'acc_val: 0.6520', 'time: 6776.2826s')\n",
      "('iter: 31101', 'loss_train: 1.2334', 'acc_train: 0.6686', 'loss_val: 0.6155', 'acc_val: 0.6518', 'time: 6800.8350s')\n",
      "('iter: 31201', 'loss_train: 1.2342', 'acc_train: 0.6691', 'loss_val: 0.6153', 'acc_val: 0.6516', 'time: 6825.8942s')\n",
      "('iter: 31301', 'loss_train: 1.2336', 'acc_train: 0.6689', 'loss_val: 0.6149', 'acc_val: 0.6520', 'time: 6851.7821s')\n",
      "('iter: 31401', 'loss_train: 1.2333', 'acc_train: 0.6692', 'loss_val: 0.6149', 'acc_val: 0.6519', 'time: 6885.8279s')\n",
      "('iter: 31501', 'loss_train: 1.2328', 'acc_train: 0.6698', 'loss_val: 0.6152', 'acc_val: 0.6519', 'time: 6919.6073s')\n",
      "('iter: 31601', 'loss_train: 1.2329', 'acc_train: 0.6700', 'loss_val: 0.6148', 'acc_val: 0.6522', 'time: 6945.8500s')\n",
      "('iter: 31701', 'loss_train: 1.2327', 'acc_train: 0.6701', 'loss_val: 0.6146', 'acc_val: 0.6521', 'time: 6979.2435s')\n",
      "('iter: 31801', 'loss_train: 1.2312', 'acc_train: 0.6691', 'loss_val: 0.6148', 'acc_val: 0.6524', 'time: 7012.8072s')\n",
      "('iter: 31901', 'loss_train: 1.2316', 'acc_train: 0.6674', 'loss_val: 0.6147', 'acc_val: 0.6527', 'time: 7046.4347s')\n",
      "('iter: 32001', 'loss_train: 1.2312', 'acc_train: 0.6684', 'loss_val: 0.6149', 'acc_val: 0.6524', 'time: 7080.0286s')\n",
      "('iter: 32101', 'loss_train: 1.2310', 'acc_train: 0.6701', 'loss_val: 0.6140', 'acc_val: 0.6537', 'time: 7116.3526s')\n",
      "('iter: 32201', 'loss_train: 1.2320', 'acc_train: 0.6689', 'loss_val: 0.6136', 'acc_val: 0.6539', 'time: 7145.7311s')\n",
      "('iter: 32301', 'loss_train: 1.2330', 'acc_train: 0.6675', 'loss_val: 0.6136', 'acc_val: 0.6539', 'time: 7170.7816s')\n",
      "('iter: 32401', 'loss_train: 1.2337', 'acc_train: 0.6677', 'loss_val: 0.6136', 'acc_val: 0.6533', 'time: 7195.7930s')\n",
      "('iter: 32501', 'loss_train: 1.2336', 'acc_train: 0.6681', 'loss_val: 0.6137', 'acc_val: 0.6527', 'time: 7220.6519s')\n",
      "('iter: 32601', 'loss_train: 1.2337', 'acc_train: 0.6674', 'loss_val: 0.6143', 'acc_val: 0.6525', 'time: 7244.8227s')\n",
      "('iter: 32701', 'loss_train: 1.2324', 'acc_train: 0.6682', 'loss_val: 0.6140', 'acc_val: 0.6531', 'time: 7269.0710s')\n",
      "('iter: 32801', 'loss_train: 1.2322', 'acc_train: 0.6690', 'loss_val: 0.6130', 'acc_val: 0.6543', 'time: 7293.6539s')\n",
      "('iter: 32901', 'loss_train: 1.2321', 'acc_train: 0.6675', 'loss_val: 0.6125', 'acc_val: 0.6552', 'time: 7319.5983s')\n",
      "('iter: 33001', 'loss_train: 1.2322', 'acc_train: 0.6679', 'loss_val: 0.6129', 'acc_val: 0.6546', 'time: 7343.7544s')\n",
      "('iter: 33101', 'loss_train: 1.2325', 'acc_train: 0.6668', 'loss_val: 0.6133', 'acc_val: 0.6548', 'time: 7368.0412s')\n",
      "('iter: 33201', 'loss_train: 1.2329', 'acc_train: 0.6652', 'loss_val: 0.6137', 'acc_val: 0.6550', 'time: 7392.3018s')\n",
      "('iter: 33301', 'loss_train: 1.2332', 'acc_train: 0.6637', 'loss_val: 0.6131', 'acc_val: 0.6556', 'time: 7416.5662s')\n",
      "('iter: 33401', 'loss_train: 1.2318', 'acc_train: 0.6649', 'loss_val: 0.6125', 'acc_val: 0.6570', 'time: 7440.8608s')\n",
      "('iter: 33501', 'loss_train: 1.2319', 'acc_train: 0.6646', 'loss_val: 0.6126', 'acc_val: 0.6571', 'time: 7465.6328s')\n",
      "('iter: 33601', 'loss_train: 1.2305', 'acc_train: 0.6663', 'loss_val: 0.6111', 'acc_val: 0.6587', 'time: 7492.7610s')\n",
      "('iter: 33701', 'loss_train: 1.2296', 'acc_train: 0.6667', 'loss_val: 0.6104', 'acc_val: 0.6597', 'time: 7520.0019s')\n",
      "('iter: 33801', 'loss_train: 1.2302', 'acc_train: 0.6677', 'loss_val: 0.6103', 'acc_val: 0.6597', 'time: 7545.9619s')\n",
      "('iter: 33901', 'loss_train: 1.2301', 'acc_train: 0.6671', 'loss_val: 0.6108', 'acc_val: 0.6591', 'time: 7570.2733s')\n",
      "('iter: 34001', 'loss_train: 1.2290', 'acc_train: 0.6683', 'loss_val: 0.6114', 'acc_val: 0.6589', 'time: 7594.6264s')\n",
      "('iter: 34101', 'loss_train: 1.2278', 'acc_train: 0.6679', 'loss_val: 0.6113', 'acc_val: 0.6592', 'time: 7619.0899s')\n",
      "('iter: 34201', 'loss_train: 1.2277', 'acc_train: 0.6674', 'loss_val: 0.6103', 'acc_val: 0.6608', 'time: 7643.4359s')\n",
      "('iter: 34301', 'loss_train: 1.2264', 'acc_train: 0.6673', 'loss_val: 0.6100', 'acc_val: 0.6612', 'time: 7669.4424s')\n",
      "('iter: 34401', 'loss_train: 1.2259', 'acc_train: 0.6685', 'loss_val: 0.6103', 'acc_val: 0.6606', 'time: 7694.1178s')\n",
      "('iter: 34501', 'loss_train: 1.2256', 'acc_train: 0.6697', 'loss_val: 0.6108', 'acc_val: 0.6602', 'time: 7718.3472s')\n",
      "('iter: 34601', 'loss_train: 1.2229', 'acc_train: 0.6705', 'loss_val: 0.6106', 'acc_val: 0.6603', 'time: 7742.6125s')\n",
      "('iter: 34701', 'loss_train: 1.2234', 'acc_train: 0.6688', 'loss_val: 0.6106', 'acc_val: 0.6608', 'time: 7769.7643s')\n",
      "('iter: 34801', 'loss_train: 1.2226', 'acc_train: 0.6687', 'loss_val: 0.6113', 'acc_val: 0.6598', 'time: 7795.8187s')\n",
      "('iter: 34901', 'loss_train: 1.2222', 'acc_train: 0.6693', 'loss_val: 0.6108', 'acc_val: 0.6600', 'time: 7820.0917s')\n",
      "('iter: 35001', 'loss_train: 1.2208', 'acc_train: 0.6708', 'loss_val: 0.6101', 'acc_val: 0.6612', 'time: 7844.4938s')\n",
      "('iter: 35101', 'loss_train: 1.2204', 'acc_train: 0.6715', 'loss_val: 0.6097', 'acc_val: 0.6616', 'time: 7868.7524s')\n",
      "('iter: 35201', 'loss_train: 1.2195', 'acc_train: 0.6731', 'loss_val: 0.6085', 'acc_val: 0.6627', 'time: 7895.6244s')\n",
      "('iter: 35301', 'loss_train: 1.2170', 'acc_train: 0.6750', 'loss_val: 0.6081', 'acc_val: 0.6633', 'time: 7922.1485s')\n",
      "('iter: 35401', 'loss_train: 1.2162', 'acc_train: 0.6748', 'loss_val: 0.6081', 'acc_val: 0.6632', 'time: 7946.4053s')\n",
      "('iter: 35501', 'loss_train: 1.2142', 'acc_train: 0.6767', 'loss_val: 0.6079', 'acc_val: 0.6632', 'time: 7971.6544s')\n",
      "('iter: 35601', 'loss_train: 1.2138', 'acc_train: 0.6758', 'loss_val: 0.6095', 'acc_val: 0.6613', 'time: 7995.8621s')\n",
      "('iter: 35701', 'loss_train: 1.2132', 'acc_train: 0.6755', 'loss_val: 0.6099', 'acc_val: 0.6608', 'time: 8020.0196s')\n",
      "('iter: 35801', 'loss_train: 1.2122', 'acc_train: 0.6770', 'loss_val: 0.6095', 'acc_val: 0.6614', 'time: 8044.3262s')\n",
      "('iter: 35901', 'loss_train: 1.2127', 'acc_train: 0.6761', 'loss_val: 0.6101', 'acc_val: 0.6612', 'time: 8068.4574s')\n",
      "('iter: 36001', 'loss_train: 1.2115', 'acc_train: 0.6762', 'loss_val: 0.6099', 'acc_val: 0.6610', 'time: 8092.6236s')\n",
      "('iter: 36101', 'loss_train: 1.2116', 'acc_train: 0.6768', 'loss_val: 0.6099', 'acc_val: 0.6606', 'time: 8116.7958s')\n",
      "('iter: 36201', 'loss_train: 1.2109', 'acc_train: 0.6771', 'loss_val: 0.6097', 'acc_val: 0.6602', 'time: 8141.0683s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: 36301', 'loss_train: 1.2110', 'acc_train: 0.6757', 'loss_val: 0.6102', 'acc_val: 0.6606', 'time: 8165.3133s')\n",
      "('iter: 36401', 'loss_train: 1.2109', 'acc_train: 0.6763', 'loss_val: 0.6102', 'acc_val: 0.6607', 'time: 8189.6493s')\n",
      "('iter: 36501', 'loss_train: 1.2114', 'acc_train: 0.6750', 'loss_val: 0.6094', 'acc_val: 0.6618', 'time: 8214.0180s')\n",
      "('iter: 36601', 'loss_train: 1.2104', 'acc_train: 0.6759', 'loss_val: 0.6086', 'acc_val: 0.6633', 'time: 8238.4001s')\n",
      "('iter: 36701', 'loss_train: 1.2095', 'acc_train: 0.6768', 'loss_val: 0.6075', 'acc_val: 0.6639', 'time: 8263.0336s')\n",
      "('iter: 36801', 'loss_train: 1.2090', 'acc_train: 0.6775', 'loss_val: 0.6069', 'acc_val: 0.6650', 'time: 8289.7904s')\n",
      "('iter: 36901', 'loss_train: 1.2088', 'acc_train: 0.6794', 'loss_val: 0.6072', 'acc_val: 0.6644', 'time: 8314.0491s')\n",
      "('iter: 37001', 'loss_train: 1.2075', 'acc_train: 0.6798', 'loss_val: 0.6054', 'acc_val: 0.6660', 'time: 8341.4827s')\n",
      "('iter: 37101', 'loss_train: 1.2072', 'acc_train: 0.6789', 'loss_val: 0.6050', 'acc_val: 0.6662', 'time: 8367.7204s')\n",
      "('iter: 37201', 'loss_train: 1.2069', 'acc_train: 0.6802', 'loss_val: 0.6050', 'acc_val: 0.6664', 'time: 8392.6791s')\n",
      "('iter: 37301', 'loss_train: 1.2059', 'acc_train: 0.6816', 'loss_val: 0.6053', 'acc_val: 0.6668', 'time: 8417.0902s')\n",
      "('iter: 37401', 'loss_train: 1.2046', 'acc_train: 0.6823', 'loss_val: 0.6058', 'acc_val: 0.6668', 'time: 8441.3935s')\n",
      "('iter: 37501', 'loss_train: 1.2051', 'acc_train: 0.6809', 'loss_val: 0.6053', 'acc_val: 0.6673', 'time: 8465.6830s')\n",
      "('iter: 37601', 'loss_train: 1.2052', 'acc_train: 0.6810', 'loss_val: 0.6055', 'acc_val: 0.6667', 'time: 8489.8744s')\n",
      "('iter: 37701', 'loss_train: 1.2043', 'acc_train: 0.6815', 'loss_val: 0.6045', 'acc_val: 0.6678', 'time: 8515.6663s')\n",
      "('iter: 37801', 'loss_train: 1.2040', 'acc_train: 0.6814', 'loss_val: 0.6039', 'acc_val: 0.6688', 'time: 8542.2321s')\n",
      "('iter: 37901', 'loss_train: 1.2038', 'acc_train: 0.6826', 'loss_val: 0.6032', 'acc_val: 0.6701', 'time: 8568.4825s')\n",
      "('iter: 38001', 'loss_train: 1.2035', 'acc_train: 0.6829', 'loss_val: 0.6037', 'acc_val: 0.6699', 'time: 8593.4562s')\n",
      "('iter: 38101', 'loss_train: 1.2038', 'acc_train: 0.6839', 'loss_val: 0.6035', 'acc_val: 0.6690', 'time: 8617.6796s')\n",
      "('iter: 38201', 'loss_train: 1.2041', 'acc_train: 0.6846', 'loss_val: 0.6039', 'acc_val: 0.6690', 'time: 8641.9085s')\n",
      "('iter: 38301', 'loss_train: 1.2039', 'acc_train: 0.6863', 'loss_val: 0.6024', 'acc_val: 0.6705', 'time: 8667.4316s')\n",
      "('iter: 38401', 'loss_train: 1.2037', 'acc_train: 0.6856', 'loss_val: 0.6018', 'acc_val: 0.6718', 'time: 8693.8435s')\n",
      "('iter: 38501', 'loss_train: 1.2032', 'acc_train: 0.6859', 'loss_val: 0.6021', 'acc_val: 0.6722', 'time: 8719.5339s')\n",
      "('iter: 38601', 'loss_train: 1.2026', 'acc_train: 0.6851', 'loss_val: 0.6021', 'acc_val: 0.6723', 'time: 8743.9277s')\n",
      "('iter: 38701', 'loss_train: 1.2016', 'acc_train: 0.6844', 'loss_val: 0.6018', 'acc_val: 0.6729', 'time: 8768.2383s')\n",
      "('iter: 38801', 'loss_train: 1.2000', 'acc_train: 0.6853', 'loss_val: 0.6007', 'acc_val: 0.6735', 'time: 8795.3904s')\n",
      "('iter: 38901', 'loss_train: 1.1999', 'acc_train: 0.6845', 'loss_val: 0.5995', 'acc_val: 0.6751', 'time: 8823.3644s')\n",
      "('iter: 39001', 'loss_train: 1.2002', 'acc_train: 0.6834', 'loss_val: 0.5995', 'acc_val: 0.6754', 'time: 8848.9017s')\n",
      "('iter: 39101', 'loss_train: 1.1995', 'acc_train: 0.6848', 'loss_val: 0.5995', 'acc_val: 0.6762', 'time: 8873.8523s')\n",
      "('iter: 39201', 'loss_train: 1.2005', 'acc_train: 0.6852', 'loss_val: 0.5993', 'acc_val: 0.6771', 'time: 8898.0130s')\n",
      "('iter: 39301', 'loss_train: 1.2008', 'acc_train: 0.6846', 'loss_val: 0.5979', 'acc_val: 0.6781', 'time: 8924.2187s')\n",
      "('iter: 39401', 'loss_train: 1.1991', 'acc_train: 0.6862', 'loss_val: 0.5987', 'acc_val: 0.6775', 'time: 8948.9376s')\n",
      "('iter: 39501', 'loss_train: 1.1982', 'acc_train: 0.6861', 'loss_val: 0.5984', 'acc_val: 0.6780', 'time: 8973.0660s')\n",
      "('iter: 39601', 'loss_train: 1.1988', 'acc_train: 0.6853', 'loss_val: 0.5977', 'acc_val: 0.6794', 'time: 8997.9332s')\n",
      "('iter: 39701', 'loss_train: 1.1996', 'acc_train: 0.6862', 'loss_val: 0.5982', 'acc_val: 0.6791', 'time: 9022.0798s')\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "def dump_log(model, n_iter, loss, acc, val_loss, val_acc, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f<split>%.5f<split>%.5f\\n' % (n_iter, loss, acc, val_loss, val_acc)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 100 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "\n",
    "acc_q = deque(maxlen=10000)\n",
    "loss_q = deque(maxlen=10000)\n",
    "val_acc_q = deque(maxlen=10000)\n",
    "val_loss_q = deque(maxlen=10000)\n",
    "criterion = nn.BCELoss()\n",
    "# \n",
    "model = net\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "#\n",
    "interval = 100\n",
    "t = time.time()\n",
    "print 'start training.'\n",
    "best_acc  = 0\n",
    "best_loss = float('inf')\n",
    "for i in range(1,1000000):\n",
    "    with open('log.txt', 'a') as f:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "    #     positive\n",
    "        q,k,q_f,k_f,q_w,k_w = next(pos_G)\n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "        q_w,k_w = torch.FloatTensor(q_w), torch.FloatTensor(k_w)\n",
    "        \n",
    "        output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda(), q_w.cuda(), k_w.cuda())\n",
    "        acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        pos_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "\n",
    "#         negative\n",
    "        q,k,q_f,k_f,q_w,k_w = next(neg_G)\n",
    "        \n",
    "        q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "        q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "        q_w,k_w = torch.FloatTensor(q_w), torch.FloatTensor(k_w)\n",
    "        \n",
    "        output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda(), q_w.cuda(), k_w.cuda())\n",
    "        \n",
    "        acc = 1 if output.flatten().item() < 0.5 else 0\n",
    "        acc_q.append(acc)\n",
    "        neg_loss = criterion(output, torch.FloatTensor([[0]]).cuda())\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss_q.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #     val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_i = i % val_Q.shape[0]\n",
    "            q,k = val_Q[val_i,:], val_K[val_i,:]\n",
    "            q_f,k_f = val_Q_fea[val_i,:], val_K_fea[val_i,:]\n",
    "            q_w,k_w = val_Q_w[val_i,:], val_K_w[val_i,:]\n",
    "            q,k = torch.LongTensor(q), torch.LongTensor(k)\n",
    "            q_f,k_f = torch.FloatTensor(q_f), torch.FloatTensor(k_f)\n",
    "            q_w,k_w = torch.FloatTensor(q_w), torch.FloatTensor(k_w)\n",
    "        \n",
    "            output = model(q.cuda(), k.cuda(), q_f.cuda(), k_f.cuda(), q_w.cuda(), k_w.cuda())\n",
    "            val_acc = 1 if output.flatten().item() > 0.5 else 0\n",
    "            val_acc_q.append(val_acc)\n",
    "\n",
    "            val_loss = criterion(output, torch.FloatTensor([[1]]).cuda() )\n",
    "            val_loss_q.append(val_loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        acc = float(np.mean(acc_q))\n",
    "        loss = float(np.mean(loss_q))\n",
    "        val_acc = float(np.mean(val_acc_q))\n",
    "        val_loss = float(np.mean(val_loss_q))\n",
    "\n",
    "        if i % interval == 0:\n",
    "            print('iter: {:04d}'.format(i+1),\n",
    "                  'loss_train: {:.4f}'.format(loss),\n",
    "                  'acc_train: {:.4f}'.format(acc),\n",
    "                  'loss_val: {:.4f}'.format(val_loss),\n",
    "                  'acc_val: {:.4f}'.format(val_acc),\n",
    "                  'time: {:.4f}s'.format((time.time() - t)))\n",
    "        if i > 100:\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model, './best_acc.pt')\n",
    "                with open('./best.txt', 'a') as g:\n",
    "                    g.write('best acc at %d with %.5f\\n' % (i+1, best_acc))\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model, './best_loss.pt')\n",
    "                with open('./best.txt', 'a') as g:\n",
    "                    g.write('best loss at %d with %.5f\\n' % (i+1, best_loss))\n",
    "            \n",
    "        dump_log(model, i+1, loss, acc, val_loss, val_acc, f, './tmp.pt')\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"Optimization Finished!\")\n",
    "# print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12(virtualenv)",
   "language": "python",
   "name": "python2.7.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
