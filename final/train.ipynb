{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "dir_path = './sdml_final_1'\n",
    "input_list  = ['prep_final_test_win_feature.pickle',\n",
    "               'prep_final_train_bid_data.pickle',\n",
    "               'prep_final_train_win_data.pickle']\n",
    "with open(join(dir_path, 'prep_final_train_win_data.pickle'), 'rb') as f:\n",
    "    win_dic = pickle.load(f)\n",
    "with open(join(dir_path, 'prep_final_train_bid_data.pickle'), 'rb') as f:\n",
    "    bid_dic = pickle.load(f)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trimming done\n"
     ]
    }
   ],
   "source": [
    "def trim_max(dic):\n",
    "    price = dic['price']\n",
    "    threshold = np.percentile(price, 80)\n",
    "#     threshold = 800\n",
    "#     print threshold\n",
    "    valid_idx = np.array([i for i in range(price.shape[0]) if price[i, 0] < threshold])\n",
    "    ret = {k: v[valid_idx, :] for k, v in dic.items()}\n",
    "    return ret\n",
    "\n",
    "win_dic = trim_max(win_dic)\n",
    "bid_dic = trim_max(bid_dic)\n",
    "print 'trimming done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Regression_model(nn.Module):\n",
    "#     def __init__(self, app_dim, device_dim, imp_dim, imp_posi_dim, dm1, dm2, drop, depth):\n",
    "#         super(Regression_model, self).__init__()\n",
    "#         self.app = nn.Embedding(app_dim, dm1)\n",
    "#         self.device = nn.Embedding(device_dim, dm1)\n",
    "#         self.imp = nn.Embedding(imp_dim, dm1)\n",
    "#         self.imp_posi = nn.Embedding(imp_posi_dim, dm1)\n",
    "#         self.weekdays = nn.Embedding(7, dm1)\n",
    "#         self.hours = nn.Embedding(24, dm1)\n",
    "#         self.linear = nn.Linear(6*dm1 + 2, dm2)\n",
    "#         self.emb_linears = Linear_model(dm2, drop, depth, False)\n",
    "#         self.price_linears = Linear_model(dm2, drop, depth, True)\n",
    "#         self.sigma_linears = Linear_model(dm2, drop, depth, True)\n",
    "#         self.drop = nn.Dropout(drop)\n",
    "        \n",
    "\n",
    "#     def forward(self, width, height, app, device, imp, imp_posi, weekdays, hours):\n",
    "#         app = self.app(app).squeeze(1)\n",
    "#         device = self.device(device).squeeze(1)\n",
    "#         imp = self.imp(imp).squeeze(1)\n",
    "#         imp_posi = self.imp_posi(imp_posi).squeeze(1)\n",
    "#         weekdays = self.weekdays(weekdays).squeeze(1)\n",
    "#         hours = self.hours(hours).squeeze(1)\n",
    "#         emb = torch.cat([width, height, app, device, imp, imp_posi, weekdays, hours], dim=-1)\n",
    "#         x = self.drop(emb)\n",
    "#         x = self.linear(x)\n",
    "#         x = self.emb_linears(x)\n",
    "#         price = self.price_linears(x)\n",
    "#         sigma = self.sigma_linears(x)\n",
    "#         sigma = F.relu(sigma)\n",
    "#         sigma = torch.clamp(sigma, 5, 50)\n",
    "#         return price, sigma, emb\n",
    "    \n",
    "# # class Linear_model(nn.Module):\n",
    "# #     def __init__(self, dm, drop, depth, with_out):\n",
    "# #         super(Linear_model, self).__init__()\n",
    "# #         self.linears = nn.ModuleList()\n",
    "# #         self.norms = nn.ModuleList()\n",
    "# #         self.drop = nn.Dropout(drop)\n",
    "# #         self.with_out = with_out\n",
    "# #         for i in range(depth):\n",
    "# #             linear = nn.Linear(dm, dm)\n",
    "# #             self.linears.append(linear)\n",
    "# #             self.norms.append(nn.BatchNorm1d(dm))\n",
    "# #         if with_out:\n",
    "# #             self.out = nn.Linear(dm, 1)\n",
    "        \n",
    "\n",
    "# #     def forward(self, x):\n",
    "# #         for norm, linear in zip(self.norms, self.linears):\n",
    "# #             x = F.relu(linear(x)) + x\n",
    "# #             x = norm(x)\n",
    "# #             x = self.drop(x)\n",
    "# #         if self.with_out:\n",
    "# #             x = F.relu(self.out(x))\n",
    "# #         return x\n",
    "# class Linear_model(nn.Module):\n",
    "#     def __init__(self, dm, drop, depth, with_out):\n",
    "#         super(Linear_model, self).__init__()\n",
    "#         if with_out:\n",
    "#             self.out = nn.Linear(dm, 1)\n",
    "#         else:\n",
    "#             self.linears = nn.ModuleList()\n",
    "#             self.norms = nn.ModuleList()\n",
    "#             self.drop = nn.Dropout(drop)\n",
    "#             for i in range(depth):\n",
    "#                 linear = nn.Linear(dm, dm)\n",
    "#                 self.linears.append(linear)\n",
    "#                 self.norms.append(nn.BatchNorm1d(dm))\n",
    "#         self.with_out = with_out\n",
    "        \n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.with_out:\n",
    "# #             x = F.relu(self.out(x))\n",
    "#             x = self.out(x)\n",
    "#         else:\n",
    "#             for norm, linear in zip(self.norms, self.linears):\n",
    "#                 x = F.relu(linear(x)) + x\n",
    "#                 x = norm(x)\n",
    "#                 x = self.drop(x)\n",
    "#         return x\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# eps = 10**-8\n",
    "eps = 10**-2\n",
    "\n",
    "class Regression_model(nn.Module):\n",
    "    def __init__(self, app_dim, device_dim, imp_dim, imp_posi_dim, dm1, dm2, drop):\n",
    "        super(Regression_model, self).__init__()\n",
    "        self.app = nn.Embedding(app_dim, dm1)\n",
    "        self.device = nn.Embedding(device_dim, dm1)\n",
    "        self.imp = nn.Embedding(imp_dim, dm1)\n",
    "        self.imp_posi = nn.Embedding(imp_posi_dim, dm1)\n",
    "        self.weekdays = nn.Embedding(7, dm1)\n",
    "        self.hours = nn.Embedding(24, dm1)\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                linear = nn.Linear(6*dm1 + 2, dm2)\n",
    "            else:\n",
    "                linear = nn.Linear(dm2, dm2)\n",
    "            self.linears.append(linear)\n",
    "            self.norms.append(nn.BatchNorm1d(dm2))\n",
    "        self.out = nn.Linear(dm2, 1)\n",
    "        self.sigma = nn.Linear(dm2, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, width, height, app, device, imp, imp_posi, weekdays, hours):\n",
    "        app = self.app(app).squeeze(1)\n",
    "        device = self.device(device).squeeze(1)\n",
    "        imp = self.imp(imp).squeeze(1)\n",
    "        imp_posi = self.imp_posi(imp_posi).squeeze(1)\n",
    "        weekdays = self.weekdays(weekdays).squeeze(1)\n",
    "        hours = self.hours(hours).squeeze(1)\n",
    "        emb = x = torch.cat([width, height, app, device, imp, imp_posi, weekdays, hours], dim=-1)\n",
    "        x = self.drop(x)\n",
    "        for i, (norm, linear) in enumerate(zip(self.norms, self.linears)):\n",
    "            if i == 0:\n",
    "                x = F.relu(linear(x))\n",
    "            else:\n",
    "                x = F.relu(linear(x)) + x\n",
    "            x = norm(x)\n",
    "            x = self.drop(x)\n",
    "        y = self.out(x)\n",
    "        sigma = F.relu(self.sigma(x))\n",
    "        sigma = torch.clamp(sigma, 5, 50)\n",
    "        return y, sigma, emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dic(rate, dic):\n",
    "    N = len(dic['price'])\n",
    "    \n",
    "    for k in dic.keys():\n",
    "        assert dic[k].shape[0] == N\n",
    "#         print 'categorical %s, dim size : %d' % (k, np.max(dic[k]+1))\n",
    "    idx = np.random.permutation(N)\n",
    "    c = int(N*rate)\n",
    "    print 'split to %d : %d' % (c, N-c)\n",
    "    train_idx, val_idx = idx[c:], idx[:c]\n",
    "    train_dic = {k: dic[k][train_idx, :] for k in dic.keys()}\n",
    "    val_dic = {k: dic[k][val_idx, :] for k in dic.keys()}\n",
    "    return train_dic, val_dic\n",
    "\n",
    "def permutation_generator(N):\n",
    "    while True:\n",
    "        rand_idx = np.random.permutation(N)\n",
    "        for i in rand_idx:\n",
    "            yield i\n",
    "            \n",
    "def batch_boostrap_generator(dic, batch):\n",
    "    N = len(dic['price'])\n",
    "    G = permutation_generator(N)\n",
    "    while True:\n",
    "        idx = np.array([next(G) for i in range(batch)])\n",
    "        app = dic['app_type'][idx, :]\n",
    "        device = dic['device_type'][idx, :]\n",
    "        imp = dic['imp_type'][idx, :]\n",
    "        imp_posi = dic['imp_position'][idx, :]\n",
    "        weekdays = dic['weekdays'][idx, :]\n",
    "        hours = dic['hours'][idx, :]\n",
    "        width = dic['width'][idx, :]\n",
    "        height = dic['height'][idx, :]\n",
    "        price = dic['price'][idx, :]\n",
    "        yield (width, height, app, device, imp, imp_posi, weekdays, hours, price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split to 743343 : 14123520\n",
      "split to 658152 : 12504888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "def win_loss(x, y, sigma, distribution):\n",
    "    if distribution is torch.distributions.gumbel.Gumbel:\n",
    "        z = (y-x) / sigma\n",
    "        loss = z+torch.clamp(torch.exp(-z), 10**-8, 10**8) + torch.log(sigma)\n",
    "#         print 'los', loss[0,0], z[0, 0], torch.clamp(torch.exp(-z), 10**-8, 10**8)[0, 0], torch.log(sigma)[0,0], x[0, 0]\n",
    "        return loss\n",
    "    else:\n",
    "        d = distribution(0, sigma)\n",
    "        loss = -d.log_prob(y-x)    \n",
    "        return loss\n",
    "def bid_loss(x, y, sigma, distribution):\n",
    "#     if distribution is torch.distributions.gumbel.Gumbel:\n",
    "#         z = (y-x) / sigma\n",
    "#         loss = -torch.exp(-z)\n",
    "#         return loss\n",
    "# #     else:\n",
    "    \n",
    "    d = distribution(0, sigma)\n",
    "    z = 1-d.cdf(y-x)\n",
    "    z = torch.clamp(z, 10**-8, 1.)\n",
    "    loss = -torch.log(z)\n",
    "#     print 'bid', loss[0,0]\n",
    "    return loss\n",
    "#     return 0\n",
    "def cuda_data(data):\n",
    "    data = list(data)\n",
    "    for i, v in enumerate(data):\n",
    "        if v.dtype == np.int32:\n",
    "            data[i] = torch.LongTensor(v)\n",
    "        elif v.dtype == np.float32:\n",
    "            data[i] = torch.FloatTensor(v)\n",
    "        if use_cuda:\n",
    "            data[i] = data[i].cuda()\n",
    "    return data\n",
    "\n",
    "def calc_train_loss(model, data, is_win, distribution, train_price, use_cuda, emb_loss_criterion):\n",
    "    if use_cuda:\n",
    "        data = cuda_data(data)\n",
    "    \n",
    "    width, height, app, device, imp, imp_posi, weekdays, hours, price = data\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out, sigma, emb = model(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "    model.train()\n",
    "    if train_price:\n",
    "        out, _, emb = model(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "    else:\n",
    "        _, sigma, emb = model(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "#     print out[0,0], sigma[0,0], price[0,0 ]\n",
    "    if is_win:\n",
    "        loss = win_loss(out, price, sigma, distribution)\n",
    "    else:\n",
    "        loss = bid_loss(out, price, sigma, distribution)\n",
    "    emb_loss = emb_loss_criterion(emb, torch.zeros_like(emb))\n",
    "    loss = loss + 0.001*emb_loss\n",
    "    return loss\n",
    "\n",
    "def calc_val_loss(model, data, is_win, distribution, use_cuda):\n",
    "    if use_cuda:\n",
    "        data = cuda_data(data)\n",
    "    width, height, app, device, imp, imp_posi, weekdays, hours, price = data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out, sigma, emb = model(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "        if is_win:\n",
    "            loss = win_loss(out, price, sigma, distribution)\n",
    "        else:\n",
    "            loss = bid_loss(out, price, sigma, distribution)\n",
    "    return loss\n",
    "\n",
    "def train(model, opt, train_g, val_g, distribution, train_price, use_cuda, emb_loss_criterion, alpha):\n",
    "    price_opt, sigma_opt = opt\n",
    "    train_opt = price_opt if train_price else sigma_opt\n",
    "    win_g, bid_g = train_g\n",
    "    win_data, bid_data = next(win_g), next(bid_g)\n",
    "    win_loss = calc_train_loss(model, win_data, True, distribution, train_price, use_cuda, emb_loss_criterion)\n",
    "    bid_loss = calc_train_loss(model, bid_data, False, distribution, train_price, use_cuda, emb_loss_criterion)\n",
    "    loss = torch.mean(win_loss + alpha*bid_loss)\n",
    "    train_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    train_opt.step()\n",
    "#     validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        win_g, bid_g = val_g\n",
    "        win_loss = calc_val_loss(model, next(win_g), True, distribution, use_cuda)\n",
    "        bid_loss = calc_val_loss(model, next(bid_g), False, distribution, use_cuda)\n",
    "        val_loss = torch.mean(win_loss + alpha*bid_loss)\n",
    "    return loss, val_loss\n",
    "    \n",
    "batch_size = 4096\n",
    "train_win_dic, val_win_dic = split_dic(0.05, win_dic)\n",
    "train_bid_dic, val_bid_dic = split_dic(0.05, bid_dic)\n",
    "\n",
    "win_g = batch_boostrap_generator(train_win_dic, batch_size)\n",
    "bid_g = batch_boostrap_generator(train_bid_dic, batch_size)\n",
    "train_g = (win_g, bid_g)\n",
    "\n",
    "win_g = batch_boostrap_generator(val_win_dic, batch_size)\n",
    "bid_g = batch_boostrap_generator(val_bid_dic, batch_size)\n",
    "val_g = (win_g, bid_g)\n",
    "\n",
    "\n",
    "dm1 = 64\n",
    "dm2 = 512\n",
    "drop = 0.15\n",
    "# model = Regression_model(3, 5, 3, 10, dm1, dm2, drop, depth=10)\n",
    "model = Regression_model(3, 5, 3, 10, dm1, dm2, drop)\n",
    "alpha = 1.\n",
    "price_params = []\n",
    "sigma_params = []\n",
    "for c in model.children():\n",
    "#     if c != model.price_linears:\n",
    "    if c != model.out:\n",
    "        for p in c.parameters():\n",
    "            sigma_params.append(p)\n",
    "#     if c != model.sigma_linears:\n",
    "    if c != model.sigma:\n",
    "        for p in c.parameters():\n",
    "            price_params.append(p)\n",
    "# price_opt = torch.optim.Adadelta(price_params)\n",
    "# sigma_opt = torch.optim.Adadelta(sigma_params)\n",
    "# price_opt = torch.optim.Adam(price_params)\n",
    "# sigma_opt = torch.optim.Adam(sigma_params)\n",
    "price_opt = torch.optim.Adam(model.parameters())\n",
    "sigma_opt = torch.optim.Adam(model.parameters())\n",
    "opt = price_opt, sigma_opt\n",
    "\n",
    "# distribution = torch.distributions.normal.Normal\n",
    "distribution = torch.distributions.gumbel.Gumbel\n",
    "emb_loss_criterion = nn.MSELoss(reduction='none')\n",
    "train_q = deque(maxlen=100)\n",
    "val_q = deque(maxlen=100)\n",
    "# train_q = deque(maxlen=10)\n",
    "# val_q = deque(maxlen=10)\n",
    "c = 0\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cencored  regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1725 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [04:03<00:00,  3.59it/s, loss : 14.59001, val loss : 14.10090] \n",
      "  0%|          | 1/1725 [00:00<03:56,  7.30it/s, loss : 14.58991, val loss : 14.10082]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [04:03<00:00,  4.29it/s, loss : 12.15655, val loss : 11.63768]\n",
      "  0%|          | 1/1725 [00:00<03:58,  7.22it/s, loss : 12.15623, val loss : 11.63589]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [04:03<00:00,  4.85it/s, loss : 11.57121, val loss : 11.00078]\n",
      "  0%|          | 1/1725 [00:00<03:56,  7.28it/s, loss : 11.56986, val loss : 11.00014]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1577/1725 [03:42<00:21,  6.96it/s, loss : 11.53289, val loss : 10.97717]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ac2ecb3e7e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                     loss, val_loss = train(model, opt, train_g, val_g, distribution,\n\u001b[1;32m     28\u001b[0m                                            \u001b[0mtrain_price\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                            emb_loss_criterion=emb_loss_criterion, alpha=alpha)\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-8599268f583b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, train_g, val_g, distribution, train_price, use_cuda, emb_loss_criterion, alpha)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mwin_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbid_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mwin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_train_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_loss_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mbid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_train_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_loss_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mtrain_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-8599268f583b>\u001b[0m in \u001b[0;36mcalc_train_loss\u001b[0;34m(model, data, is_win, distribution, train_price, use_cuda, emb_loss_criterion)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_price\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_posi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_posi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-738421104ea7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, width, height, app, device, imp, imp_posi, weekdays, hours)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_posi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def dump_log(model, n_iter, loss, val_loss, log_file_stream, tmp_model_path):\n",
    "    log_text = '%.7d<split>%.5f<split>%.5f\\n' % (n_iter, loss, val_loss)\n",
    "    log_file_stream.write(log_text)\n",
    "    if n_iter % 10 == 0 :\n",
    "        log_file_stream.flush()\n",
    "        torch.save(model, tmp_model_path)\n",
    "\n",
    "\n",
    "\n",
    "N = len(train_win_dic['price'])\n",
    "train_num = 1\n",
    "a = 2*train_num*batch_size\n",
    "ran = N // a + 1 if N % a != 0 else N // a\n",
    "pre_loss = 0\n",
    "pre_train = 0 \n",
    "model.train()\n",
    "it = 0\n",
    "with open('log-20.txt', 'w') as log_stream:\n",
    "    for epoch in count():\n",
    "        print 'epoch start : %d' % epoch\n",
    "        with tqdm(total=ran) as pbar:\n",
    "            for i in range(ran):\n",
    "                loss_list = []\n",
    "                val_loss_list = [] \n",
    "    #             price phase\n",
    "                for i in range(train_num):\n",
    "                    loss, val_loss = train(model, opt, train_g, val_g, distribution,\n",
    "                                           train_price=True, use_cuda=use_cuda, \n",
    "                                           emb_loss_criterion=emb_loss_criterion, alpha=alpha)\n",
    "                    loss_list.append(loss.item())\n",
    "                    val_loss_list.append(val_loss.item())\n",
    "\n",
    "    #             sigma phase\n",
    "                for i in range(train_num):\n",
    "                    loss, val_loss = train(model, opt, train_g, val_g, distribution,\n",
    "                                           train_price=False, use_cuda=use_cuda,\n",
    "                                           emb_loss_criterion=emb_loss_criterion, alpha=alpha)\n",
    "                    loss_list.append(loss.item())\n",
    "                    val_loss_list.append(val_loss.item())\n",
    "                loss = np.mean(loss_list)\n",
    "                val_loss = np.mean(val_loss_list)\n",
    "\n",
    "                train_q.append(loss)\n",
    "                val_q.append(val_loss)\n",
    "                loss = np.mean(train_q)\n",
    "                val_loss = np.mean(val_q)\n",
    "                pbar.set_postfix_str('loss : %.5f, val loss : %.5f' % (loss, val_loss))\n",
    "\n",
    "                pbar.update(1)\n",
    "                if i % 10 == 0:\n",
    "                    if val_loss > pre_loss and loss < pre_train:\n",
    "                        c += 1\n",
    "                    else:\n",
    "                        c = 0\n",
    "                    pre_loss = val_loss\n",
    "                    pre_train = loss\n",
    "#                     if c > 5 and val_loss < 50:\n",
    "#                         c = 0\n",
    "#                         print 'end of training'\n",
    "#                         torch.save(model, './best.tar')\n",
    "#                         weffwe\n",
    "    #             log\n",
    "                it += 1\n",
    "                dump_log(model, it, loss, val_loss, log_stream, 'tmp.tar')\n",
    "            \n",
    "        torch.save(model, './models/%d.tar' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './gumbel_100_trim.tar')\n",
    "# torch.save(model, './best_bak.tar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./tmp.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1233/1233 [04:54<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "def test_generator(dic, batch):\n",
    "    rand_idx = np.arange(len(dic['price']))\n",
    "    N = len(dic['price'])\n",
    "    ran = N // batch_size + 1 if N % batch_size != 0 else N // batch_size\n",
    "    for i in range(ran):\n",
    "        idx = rand_idx[i*batch: (i+1)*batch] if (i+1)*batch < len(rand_idx) \\\n",
    "        else rand_idx[i*batch:]\n",
    "        id = dic['id'][idx, :]\n",
    "        app = dic['app_type'][idx, :]\n",
    "        device = dic['device_type'][idx, :]\n",
    "        imp = dic['imp_type'][idx, :]\n",
    "        imp_posi = dic['imp_position'][idx, :]\n",
    "        weekdays = dic['weekdays'][idx, :]\n",
    "        hours = dic['hours'][idx, :]\n",
    "        width = dic['width'][idx, :]\n",
    "        height = dic['height'][idx, :]\n",
    "        price = dic['price'][idx, :]\n",
    "        yield (id, width, height, app, device, imp, imp_posi, weekdays, hours, price)\n",
    "        \n",
    "def test(model, data, use_cuda):\n",
    "    data = list(data)\n",
    "    for i, v in enumerate(data):\n",
    "        if v.dtype == np.int32:\n",
    "            data[i] = torch.LongTensor(v)\n",
    "        elif v.dtype == np.float32:\n",
    "            data[i] = torch.FloatTensor(v)\n",
    "        if use_cuda:\n",
    "            data[i] = data[i].cuda()\n",
    "        \n",
    "    id, width, height, app, device, imp, imp_posi, weekdays, hours, price = data\n",
    "    out, sigma, emb = model(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "    return id, out\n",
    "\n",
    "\n",
    "\n",
    "dir_path = './sdml_final_1'\n",
    "with open(join(dir_path, 'prep_final_test_win_feature.pickle'), 'rb') as f:\n",
    "    test_dic = pickle.load(f)\n",
    "batch_size = 8192\n",
    "N = len(test_dic['price'])\n",
    "ran = N // batch_size + 1 if N % batch_size != 0 else N // batch_size\n",
    "    \n",
    "test_g = test_generator(test_dic, batch_size)\n",
    "use_cuda = True\n",
    "model.eval()\n",
    "with open('./submission.csv', 'w') as f_out:\n",
    "    f_out.write('id,win_price\\n')\n",
    "    with tqdm(total=ran) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for i in range(ran):\n",
    "                data = next(test_g)\n",
    "                id, out = test(model, data, use_cuda)\n",
    "                for j in range(out.shape[0]):\n",
    "                    v = out[j,0].item()\n",
    "                    f_out.write('%d,%f\\n' % (id[j, 0].item(), v))\n",
    "                pbar.update(1)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comined Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "def test_generator(dic, batch):\n",
    "    rand_idx = np.arange(len(dic['price']))\n",
    "    N = len(dic['price'])\n",
    "    ran = N // batch_size + 1 if N % batch_size != 0 else N // batch_size\n",
    "    for i in range(ran):\n",
    "        idx = rand_idx[i*batch: (i+1)*batch] if (i+1)*batch < len(rand_idx) \\\n",
    "        else rand_idx[i*batch:]\n",
    "        id = dic['id'][idx, :]\n",
    "        app = dic['app_type'][idx, :]\n",
    "        device = dic['device_type'][idx, :]\n",
    "        imp = dic['imp_type'][idx, :]\n",
    "        imp_posi = dic['imp_position'][idx, :]\n",
    "        weekdays = dic['weekdays'][idx, :]\n",
    "        hours = dic['hours'][idx, :]\n",
    "        width = dic['width'][idx, :]\n",
    "        height = dic['height'][idx, :]\n",
    "        price = dic['price'][idx, :]\n",
    "        yield (id, width, height, app, device, imp, imp_posi, weekdays, hours, price)\n",
    "        \n",
    "def combined_test(m1, m2, data, use_cuda):\n",
    "    data = list(data)\n",
    "    for i, v in enumerate(data):\n",
    "        if v.dtype == np.int32:\n",
    "            data[i] = torch.LongTensor(v)\n",
    "        elif v.dtype == np.float32:\n",
    "            data[i] = torch.FloatTensor(v)\n",
    "        if use_cuda:\n",
    "            data[i] = data[i].cuda()\n",
    "        \n",
    "    id, width, height, app, device, imp, imp_posi, weekdays, hours, price = data\n",
    "    out1, sigma = m1(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "    out2, sigma = m2(width, height, app, device, imp, imp_posi, weekdays, hours)\n",
    "    out = out1*0.5 + out2*0.5\n",
    "    return id, out\n",
    "\n",
    "\n",
    "\n",
    "dir_path = './sdml_final_1'\n",
    "with open(join(dir_path, 'prep_final_test_win_feature.pickle'), 'rb') as f:\n",
    "    test_dic = pickle.load(f)\n",
    "batch_size = 8192\n",
    "N = len(test_dic['price'])\n",
    "ran = N // batch_size + 1 if N % batch_size != 0 else N // batch_size\n",
    "    \n",
    "test_g = test_generator(test_dic, batch_size)\n",
    "use_cuda = True\n",
    "m1 = torch.load('./best.tar')\n",
    "m2 = torch.load('./best_win.tar')\n",
    "m1.eval()\n",
    "m2.eval()\n",
    "with open('./submission.csv', 'w') as f_out:\n",
    "    f_out.write('id,win_price\\n')\n",
    "    with tqdm(total=ran) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for i in range(ran):\n",
    "                data = next(test_g)\n",
    "                id, out = combined_test(m1, m2, data, use_cuda)\n",
    "                for j in range(out.shape[0]):\n",
    "                    v = out[j,0].item()\n",
    "                    f_out.write('%d,%f\\n' % (id[j, 0].item(), v))\n",
    "                pbar.update(1)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(test_dic['price'])\n",
    "N = len(test_dic['price']) // batch_size\n",
    "print N\n",
    "print (N+1)*batch_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.14 (conda)",
   "language": "python",
   "name": "python-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
